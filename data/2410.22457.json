{
  "arxivId": "2410.22457",
  "title": "Advancing Agentic Systems: Dynamic Task Decomposition, Tool Integration and Evaluation using Novel Metrics and Dataset",
  "abstract": "Abstract\nThe rapid advancements in Large Language Models (LLMs) and their enhanced reasoning capabilities are opening new avenues for dynamic, context-aware task decomposition, and automated tool selection. These developments lay the groundwork for sophisticated autonomous agentic systems powered by LLMs, which hold significant potential for process automation across various industries. These systems demonstrate remarkable abilities in performing complex tasks, interacting with external systems to augment LLMs' knowledge, and executing actions autonomously. To address the challenges and harness the opportunities presented by these advances, this paper makes three key contributions. \n* We propose an advanced agentic framework designed to autonomously process multi-hop user queries by dynamically generating and executing task graphs, selecting appropriate tools, and adapting to real-time changes in task requirements or tool availability. \n* We introduce novel evaluation metrics tailored for assessing agentic frameworks across diverse domains and tasks, namely Node F1 Score, Structural Similarity Index, and Tool F1 Score.\n* We develop a specialized dataset based on the AsyncHow dataset to enable in-depth analysis of agentic behavior across varying task complexities. \nOur findings demonstrate that asynchronous and dynamic task graph decomposition significantly improves system responsiveness and scalability, particularly in handling complex, multi-step tasks. Through detailed analysis, we observe that structural and node-level metrics are more critical in sequential tasks, whereas tool-related metrics dominate in parallel tasks. In particular, the Structural Similarity Index (SSI) emerged as the most significant predictor of performance in sequential tasks, while Tool F1 Score proved essential in parallel tasks. These findings highlight the need for balanced evaluation methods that capture both structural and operational aspects of agentic systems. Our specialized dataset enables comprehensive evaluation of these behaviors, providing valuable insights into improving overall system performance, with the importance of both structural and tool-related metrics validated through empirical analysis and statistical testing.\nThe evaluation of agentic systems presents unique challenges due to the intricate relationships between task execution, tool usage, and goal achievement. Our evaluation framework, validated through empirical analysis, offers valuable insights for improving the adaptability and reliability of agentic systems in dynamic environments.",
  "summary": "This paper introduces a framework for building agentic systems that can dynamically decompose complex tasks, integrate external tools, and adapt to changing conditions.  It utilizes LLMs to process multi-hop queries, generate task graphs, select tools, and execute tasks (potentially in parallel).  Novel metrics, including Node F1 Score, Structural Similarity Index (SSI), and Tool F1 Score, are introduced for evaluating these systems, alongside a specialized dataset based on AsyncHow.  Results indicate that structural metrics like SSI are crucial for sequential tasks, while tool-related metrics dominate in parallel tasks. This research aims to improve the adaptability and reliability of agentic systems for process automation, especially for complex workflows.",
  "takeaways": "This research paper offers valuable insights for JavaScript developers working with LLM-based multi-agent systems in web applications.  Here's how you can apply these insights, with practical examples:\n\n**1. Dynamic Task Decomposition:**\n\n* **Concept:** Break down complex user requests (e.g., \"Book a flight and hotel for my trip to London\") into smaller, manageable subtasks (e.g., \"Find flights to London,\" \"Find hotels in London,\" \"Compare prices,\" \"Book selected options\").\n* **JavaScript Implementation:**  Use a task management library like `rxjs` or `async` to create and manage asynchronous task graphs. Define each subtask as an observable or promise, and use operators like `concatMap` or `Promise.all` to manage dependencies and parallel/sequential execution.\n* **Example:**\n\n```javascript\nimport { from, of } from 'rxjs';\nimport { concatMap } from 'rxjs/operators';\n\nconst findFlights = (destination) => from(fetchFlights(destination)); // Fetch flights asynchronously\nconst findHotels = (destination) => from(fetchHotels(destination));\n\nconst userRequest = \"Book a flight and hotel for my trip to London\";\nconst destination = extractDestination(userRequest); // Extract \"London\"\n\nfindFlights(destination).pipe(\n  concatMap(flights => findHotels(destination).pipe(\n    concatMap(hotels => compareAndBook(flights, hotels)) // Process flight and hotel data\n  ))\n).subscribe(bookingConfirmation => console.log(bookingConfirmation));\n```\n\n**2. Tool Integration (via Agents):**\n\n* **Concept:** Each agent specializes in a specific task and can utilize external tools (APIs, databases, other services) or LLMs.\n* **JavaScript Implementation:** Create separate agent modules, each encapsulating the logic for a subtask and its tool interaction. Use libraries like `axios` for API calls or database drivers for database access.\n* **Example:**  A `FlightAgent` could use a flight search API like Amadeus or Skyscanner.\n\n```javascript\nimport axios from 'axios';\n\nclass FlightAgent {\n  async findFlights(destination) {\n    const response = await axios.get(`https://flight-api.example.com/flights?destination=${destination}`);\n    return response.data.flights;\n  }\n}\n```\n\n**3. Task-Aware Semantic Tool Filtering:**\n\n* **Concept:** Select the most appropriate tool for a task based on semantic similarity. This avoids overwhelming the system with all available tools.\n* **JavaScript Implementation:**  Use a vector database (e.g., Pinecone, Weaviate, Qdrant) to store embeddings of tool descriptions. When a task is generated, embed its description and query the vector database to find semantically similar tools.\n* **Example (using a hypothetical embedding library):**\n\n```javascript\nconst taskDescription = \"Find the cheapest flight to London\";\nconst taskEmbedding = embed(taskDescription);\n\nconst similarTools = await vectorDB.query(taskEmbedding, topK=3); // Get top 3 similar tools\nconst flightApiTool = similarTools[0]; // Select the most similar tool\n```\n\n\n**4. Evaluation Metrics:**\n\n* **Concept:** Evaluate your system's performance using metrics proposed in the paper.\n* **JavaScript Implementation:** Log intermediate task results, tool usage, and final outputs. Implement custom JavaScript functions to calculate Node F1 Score, Structural Similarity Index (SSI), and Tool F1 Score based on the logged data and expected outcomes.  Use libraries like `jest` for testing.\n\n\n**5. Dataset Creation (for testing):**\n\n* **Concept:**  Create a dataset of user requests, expected task graphs, and appropriate tools.\n* **JavaScript Implementation:**  Represent your dataset as JSON files.  Develop scripts to generate synthetic data or collect real-world user interactions.\n\n\n**6. Asynchronous and Dynamic Task Graphs (Advanced):**\n\n* **Concept:** Modify task graphs in real-time based on tool availability or changing requirements.\n* **JavaScript Implementation:** Use `rxjs` or similar reactive libraries to dynamically create and modify observables/promises based on real-time events.\n\n\nBy combining these concepts and using suitable JavaScript libraries, you can build robust and adaptable LLM-based multi-agent web applications. The paper's emphasis on evaluation, task decomposition strategies, and tool selection provides a strong framework for developing efficient and scalable systems. Remember to focus on modular design and testing to ensure the reliability and maintainability of your application.",
  "pseudocode": "```javascript\nfunction createSeqTaskGraph(edges, nodeDescriptions) {\n  /**\n   * Creates a sequential task graph based on edges and node descriptions.\n   * Removes 'Start' and 'End' nodes, maps tasks to unique IDs.\n   *\n   * @param {Array<[string, string]>} edges - List of edges as (from_node, to_node) tuples.\n   * @param {Array<string>} nodeDescriptions - List of task descriptions.\n   * @returns {Object} - Task graph with nodes and edges.\n   */\n  const taskMap = {};\n  const nodeList = [];\n  let currentTaskId = 1;\n\n  for (const [i, description] of nodeDescriptions.entries()) {\n    if (description !== \"Start\" && description !== \"End\") {\n      const taskId = `task_${currentTaskId}`;\n      taskMap[String(i + 1)] = taskId;\n      nodeList.push({ id: taskId, label: description });\n      currentTaskId++;\n    }\n  }\n\n  const edgeList = [];\n  for (const [fromNode, toNode] of edges) {\n    if (taskMap[fromNode] && taskMap[toNode]) {\n      edgeList.push({ from: taskMap[fromNode], to: taskMap[toNode] });\n    }\n  }\n\n  return { task_graph: { nodes: nodeList, edges: edgeList } };\n}\n\n\nfunction createParallelGraph(edges, tools) {\n    /**\n     * Creates a parallel task graph based on a list of tools.\n     * No edges are added, assuming all tasks run concurrently.\n     * \n     * @param {Array<[string, string]>} edges - Not used in this implementation.\n     * @param {Array<string>} tools - List of tool names.\n     * @returns {Object} - Task graph with nodes and edges (edges empty for pure parallel).\n     */\n    const taskGraph = {\n        task_graph: {\n            nodes: [],\n            edges: []\n        }\n    };\n\n    for (const [i, tool] of tools.entries()) {\n        const taskId = i + 1;\n        taskGraph.task_graph.nodes.push({id: taskId, label: tool});\n    }\n    return taskGraph;\n}\n\n\nfunction createAsyncGraph(edges, nodeDescriptions) {\n    /**\n     * Creates an asynchronous task graph.\n     *\n     * @param {Array<[string, string]>} edges - List of edges as (from_node, to_node) tuples.\n     * @param {Array<string>} nodeDescriptions - List of task descriptions.\n     * @returns {Object} - Task graph with nodes and edges.\n     */\n    const taskGraph = {\n        task_graph: {\n            nodes: [],\n            edges: []\n        }\n    };\n\n\n    for (let i = 0; i < nodeDescriptions.length; i++) {\n        taskGraph.task_graph.nodes.push({ id: i + 1, label: nodeDescriptions[i] });\n    }\n\n    for (const [fromNode, toNode] of edges) {\n        taskGraph.task_graph.edges.push({ from: fromNode, to: toNode });\n    }\n\n    return taskGraph;\n}\n\n\n\nfunction removeSemanticDuplicates(folderPath, similarityThreshold = 0.8) {\n  // Requires sentence-transformers: npm install sentence-transformers\n  const { SentenceTransformer, util } = require('sentence-transformers');\n\n  /**\n   * Removes semantically similar duplicates from folder names using sentence embeddings.\n   *\n   * @param {string} folderPath - Path to the folder.\n   * @param {number} similarityThreshold - Cosine similarity threshold.\n   * @returns {Promise<Array<string>>} - List of unique folder names.\n   */\n  const fs = require('node:fs/promises'); // Use promises for async\n  const path = require('node:path');\n\n  const model = new SentenceTransformer('all-MiniLM-L6-v2');\n\n  async function getUniqueSubfolders() {\n\n    try {\n        const subfolderNames = (await fs.readdir(folderPath, { withFileTypes: true}))\n                              .filter(dirent => dirent.isDirectory())\n                              .map(dirent => dirent.name);\n\n      const embeddings = await model.encode(subfolderNames);\n      const uniqueSubfolders = [];\n\n      for (let i = 0; i < subfolderNames.length; i++) {\n        let isDuplicate = false;\n        for (let j = 0; j < i; j++) {\n          if (util.cosSim(embeddings[i], embeddings[j]) > similarityThreshold) {\n            isDuplicate = true;\n            break;\n          }\n        }\n        if (!isDuplicate) {\n          uniqueSubfolders.push(subfolderNames[i]);\n        }\n      }\n\n      return uniqueSubfolders;\n  } catch(err) {\n      console.error(\"Error reading directory:\", err);\n      return []; // or handle the error differently\n    }\n  }\n  return getUniqueSubfolders();\n\n}\n\n\n\nasync function generateFunctions(data, folder) {\n    /**\n     * Generates Python functions based on descriptions.\n     * This simplified version creates JS functions instead. Adapting for Python requires a Python code generation library.\n     *\n     * @param {Object} data - Contains function names and code templates.\n     * @param {string} folder - Output folder.\n     */\n\n    const fs = require('fs/promises');\n    const path = require('path');\n    const baseDirectory = path.join(process.cwd(), folder); // Current working directory\n    \n    try {\n        await fs.mkdir(baseDirectory, { recursive: true }); // Ensure directory exists\n        for (const [i, functionName] of data.function_names.entries()) {\n            const functionCode = data.functions[i]; // Get the corresponding function code.\n            const functionDirectory = path.join(baseDirectory, functionName);\n            await fs.mkdir(functionDirectory, { recursive: true }); // Ensure function dir exists\n            const filePath = path.join(functionDirectory, `${functionName}.js`);\n            // Adapt functionCode for JavaScript (if it was a Python template)\n            const jsFunctionCode = `// Auto-generated from description\\n${functionCode}\\n\\nmodule.exports = ${functionName};`;\n\n            await fs.writeFile(filePath, jsFunctionCode);\n            console.log(`Created ${filePath}`);\n\n        }\n    } catch (err) {\n        console.error(\"Error generating functions:\", err);\n    }\n\n}\n\n\n```\n\n**Explanation of the Functions:**\n\n1. **`createSeqTaskGraph(edges, nodeDescriptions)`:** This function constructs a sequential task graph. It takes a list of edges (representing dependencies between tasks) and a list of node descriptions (representing the tasks themselves) as input. It outputs a dictionary representing the task graph, where nodes are tasks and edges represent the order of execution.  The \"Start\" and \"End\" nodes from the original AsyncHow dataset are removed, and task IDs are assigned sequentially.\n\n2. **`createParallelGraph(edges, tools)`:**  Constructs a graph for parallel task execution. It takes a list of `tools` and creates nodes for each tool. The `edges` argument is present for consistency with other graph creation functions, but not actually used, because in a purely parallel graph, there are no dependencies between tasks. Therefore the `edges` array in the output will be empty.\n\n3. **`createAsyncGraph(edges, nodeDescriptions)`:** This function creates a task graph where tasks can potentially run asynchronously. It's more general than `createSeqTaskGraph`. It takes `edges` to define dependencies and `nodeDescriptions`.  Unlike the sequential version, node IDs are assigned directly from the input order (plus 1).  This function would be used for scenarios where the execution order is not strictly sequential but determined by dependencies.\n\n4. **`removeSemanticDuplicates(folderPath, similarityThreshold)`:** This function addresses the problem of redundant tools or tasks. It uses sentence embeddings from the `sentence-transformers` library to calculate the cosine similarity between tool/task descriptions.  If the similarity between two descriptions exceeds the `similarityThreshold`, one of them is considered a duplicate and removed. This ensures diversity in the dataset.  The implementation provided is JavaScript, and would require a similar sentence embedding library for Python if used in a Python implementation. The function also uses `fs.promises` to handle directory reading asynchronously to avoid blocking the main thread.\n\n\n5. **`generateFunctions(data, folder)`:** This function takes tool/task descriptions and generates Python functions (in the Python pseudocode) or JavaScript function stubs (in the JavaScript conversion provided here) that simulate the behavior of real-world tools.  This is a crucial step in creating a realistic evaluation environment. In the paper's original implementation, an LLM would generate the Python function code; here, it's simplified to demonstrate the basic file writing operation, assuming `data.functions` already contains the JavaScript code (or placeholders). The actual generation of Python function code from a natural language description using an LLM requires a Python code generation library, which adds complexity to this example.  The main purpose is to demonstrate how to generate and save those functions to files.\n\n\n\nThese JavaScript conversions maintain the core logic of the original pseudocode, making them ready to be integrated into a JavaScript-based multi-agent system development project.  They provide developers with practical tools for task decomposition, graph creation, duplicate removal, and tool generation, essential components for building and evaluating multi-agent systems, inspired by the original paper's framework.",
  "simpleQuestion": "How to best evaluate LLM-powered agents?",
  "timestamp": "2024-10-31T06:01:44.955Z"
}