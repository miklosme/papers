{
  "arxivId": "2503.05347",
  "title": "GEMA-Score: Granular Explainable Multi-Agent Score for Radiology Report Evaluation",
  "abstract": "Abstract. Automatic medical report generation supports clinical diagnosis, reduces the workload of radiologists, and holds the promise of improving diagnosis consistency. However, existing evaluation metrics primarily assess the accuracy of key medical information coverage in generated reports compared to human-written reports, while overlooking crucial details such as the location and certainty of reported abnormalities. These limitations hinder the comprehensive assessment of the reliability of generated reports and pose risks in their selection for clinical use. Therefore, we propose a Granular Explainable Multi-Agent Score (GEMA-Score) in this paper, which conducts both objective quantification and subjective evaluation through a large language model-based multi-agent workflow. Our GEMA-Score parses structured reports and employs NER-F1 calculations through interactive exchanges of information among agents to assess disease diagnosis, location, severity, and uncertainty. Additionally, an LLM-based scoring agent evaluates completeness, readability, and clinical terminology while providing explanatory feedback. Extensive experiments validate that GEMA-Score achieves the highest correlation with human expert evaluations on a public dataset, demonstrating its effectiveness in clinical scoring (Kendall coefficient = 0.70 for Rexval dataset and Kendall coefficient = 0.54 for RadEvalX dataset). The anonymous project demo is available at: https://github.com/Zhenxuan-Zhang/GEMA_score",
  "summary": "This paper introduces GEMA-Score, a new metric for evaluating the quality of AI-generated medical reports, specifically radiology reports.  It addresses the limitations of existing metrics by considering both the accuracy of medical information and the quality of the language used.\n\nGEMA-Score uses a multi-agent system powered by LLMs. Each agent has a specific role: extracting medical entities, calculating objective accuracy scores, assessing subjective aspects like readability, and combining these into a final score with explanations. This approach allows for a more granular and interpretable evaluation compared to single LLM or traditional NLP-based methods.  The multi-agent workflow and reliance on LLMs make it relevant to developers exploring similar architectures for complex evaluation tasks in other domains.",
  "takeaways": "This paper introduces GEMA-Score, a multi-agent system for evaluating LLM-generated radiology reports. Here's how a JavaScript developer can apply its insights to LLM-based multi-agent web applications:\n\n**1. Building Specialized Agents:**\n\n* **Entity Extraction Agent:**  Use JavaScript NLP libraries like Compromise, Natural, or spaCy's web-based interface to extract key entities (disease, location, severity, uncertainty) from the LLM-generated text.  Store these entities in a structured JSON format for later processing. Example using Compromise:\n\n```javascript\nconst nlp = require('compromise');\n\nconst reportText = \"Mild consolidation in the right lower lobe, possibly pneumonia.\";\nconst doc = nlp(reportText);\n\nconst entities = {\n  disease: doc.nouns().toSingular().out('array'), // [\"consolidation\", \"pneumonia\"]\n  location: doc.match('#Adjective+ #Noun+').out('array'), // [\"right lower lobe\"]\n  severity: doc.match('#Adverb+').out('array'),  // [\"mild\"]\n  uncertainty: doc.match('possibly').out('array')  // [\"possibly\"]\n};\n\nconsole.log(JSON.stringify(entities, null, 2));\n```\n\n* **Objective Scoring Agent:**  Implement the NER-F1 calculation in JavaScript, comparing the extracted entities from the LLM output with a ground truth. Libraries like mathjs can be helpful for calculations.\n\n```javascript\nfunction calculateF1(precision, recall) {\n  if (precision + recall === 0) return 0;\n  return (2 * precision * recall) / (precision + recall);\n}\n```\n\n* **Subjective Scoring Agent:** Create a scoring interface in your web application (using React, Vue, or Angular) allowing human evaluators to rate LLM output on completeness, readability, and clinical terminology.\n\n**2. Multi-Agent Interaction:**\n\n* **Message Passing:** Implement a message-passing system between agents using libraries like Socket.IO or a simple publish-subscribe pattern. Agents can exchange information (extracted entities, scores) asynchronously.\n\n```javascript\n// Example using a simplified pub/sub pattern\nconst events = {};\n\nfunction subscribe(eventName, callback) {\n  if (!events[eventName]) events[eventName] = [];\n  events[eventName].push(callback);\n}\n\nfunction publish(eventName, data) {\n  if (events[eventName]) {\n    events[eventName].forEach(callback => callback(data));\n  }\n}\n\n// Entity Extraction Agent publishes extracted entities\npublish('entitiesExtracted', entities);\n\n// Objective Scoring Agent subscribes to receive entities\nsubscribe('entitiesExtracted', (entities) => {\n  // Perform NER-F1 calculation\n});\n```\n\n* **Workflow Orchestration:** Define a clear workflow (e.g., using a state machine) to coordinate agent actions.  Libraries like XState can be used for complex workflows.\n\n**3. Web Application Integration:**\n\n* **Visualization:** Display the GEMA-Score and its components (NER-F1, subjective scores) in a user-friendly dashboard within your web application. Use charting libraries like Chart.js or D3.js.\n* **Feedback Loop:** Integrate user feedback into the system.  If human evaluators disagree with the GEMA-Score, allow them to provide corrections, which can be used to refine the LLM or scoring agents.\n\n**4. Experimentation beyond Radiology:**\n\n* Adapt the GEMA-Score concept for other domains. For instance, evaluate LLM-generated legal documents, code, or marketing copy by defining relevant entities and scoring criteria.  The multi-agent architecture provides flexibility to customize the evaluation process for various applications.\n\n**Example Scenario:** Building a web application for generating product descriptions.\n\n* **Entity Extraction Agent:** Extracts product features, benefits, and target audience from LLM output.\n* **Objective Scoring Agent:** Calculates an F1 score based on a predefined list of essential features and correct target audience identification.\n* **Subjective Scoring Agent:** Allows human evaluators to rate the descriptions on persuasiveness, clarity, and brand alignment.\n\nBy adapting the principles of GEMA-Score and leveraging JavaScript tools, developers can create more robust and reliable multi-agent systems that incorporate human expertise for evaluation and feedback, ultimately leading to higher quality LLM applications.",
  "pseudocode": "The paper \"GEMA-Score: Granular Explainable Multi-Agent Score for Radiology Report Evaluation\" doesn't contain explicit pseudocode blocks.  While it describes algorithms and processes, these are expressed in natural language and mathematical formulas rather than structured pseudocode.  Thus, there's no pseudocode to convert to JavaScript.\n\nNo pseudocode block found.",
  "simpleQuestion": "How can LLMs improve medical report scoring?",
  "timestamp": "2025-03-10T06:06:34.179Z"
}