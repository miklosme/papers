{
  "arxivId": "2502.06976",
  "title": "Who is Helping Whom? Analyzing Inter-dependencies to Evaluate Cooperation in Human-AI Teaming",
  "abstract": "The long-standing research challenges of Human-AI Teaming (HAT) and Zero-shot Cooperation (ZSC) have been tackled by applying multi-agent reinforcement learning (MARL) to train an agent by optimizing the environment reward function and evaluating their performance through task performance metrics such as task reward. However, such evaluation focuses only on task completion, while being agnostic to 'how' the two agents work with each other. Specifically, we are interested in understanding the cooperation arising within the team when trained agents are paired with humans. To formally address this problem, we propose the concept of interdependence - measuring how much agents rely on each other's actions to achieve the shared goal - as a key metric for evaluating cooperation in human-agent teams. Towards this, we ground this concept through a symbolic formalism and define evaluation metrics that allow us to assess the degree of reliance between the agents' actions. We pair state-of-the-art agents trained through MARL for HAT, with learned human models for the popular Overcooked domain, and evaluate the team performance for these human-agent teams. Our results demonstrate that trained agents are not able to induce cooperative behavior, reporting very low levels of interdependence across all the teams. We also report that teaming performance of a team is not necessarily correlated with the task reward.",
  "summary": "This paper explores how to effectively measure cooperation in human-AI teams, especially where the AI is trained using Multi-Agent Reinforcement Learning (MARL).  Current metrics focus on task completion, ignoring *how* the team interacts. The researchers propose \"interdependence\" – the degree to which agents rely on each other's actions – as a better measure of cooperation.  They use a symbolic representation of the environment and actions to track and quantify interdependencies.  Experiments with state-of-the-art MARL agents in the Overcooked game environment, paired with a learned human model, reveal that these agents don't cooperate effectively with humans, even when achieving high task performance.  This highlights a misalignment between current MARL training and true cooperation, suggesting a need for new training paradigms and more complex environments to evaluate multi-agent systems.\n\nKey points for LLM-based multi-agent systems:  This work emphasizes the need for better evaluation metrics beyond simple task success, which is especially critical with LLMs. The concept of \"interdependence\" offers a valuable perspective for assessing LLM agent collaboration.  The use of symbolic representations to analyze agent interactions could be adapted to LLMs, providing insights into the reasoning behind cooperative or non-cooperative behaviors.  Finally, the findings highlight the current limitations of MARL training for fostering true cooperation, a challenge that also applies to LLM-based multi-agent systems.  This suggests a need for research on training paradigms that explicitly incentivize interdependent behaviors in LLM agents.",
  "takeaways": "This paper introduces the concept of \"interdependence\" as a metric for evaluating cooperation in multi-agent systems, particularly relevant for human-AI teaming scenarios. Let's translate these insights into practical examples for a JavaScript developer working with LLM-based multi-agent web apps:\n\n**1.  Modeling Interdependencies in a Collaborative Writing App:**\n\n*   **Scenario:** Imagine building a collaborative writing app where multiple users (humans and LLMs) contribute to a single document. You want to understand how effectively they are working together.\n*   **Implementation:**  Each user's action (adding text, editing, suggesting changes) can be logged as an \"event.\"  Using a JavaScript library like LangChain or a custom solution, these events can be analyzed for interdependencies. For example:\n    *   **Trigger Action:** An LLM suggests a rephrased sentence.\n    *   **Accept Action:**  A human user accepts the suggestion.\n    *   **Interdependency:** The LLM's suggestion triggered the human's acceptance, showing collaboration.\n*   **Visualization:** Visualize these interdependencies using a JavaScript charting library like Chart.js or D3.js.  This allows you to see which agents are initiating more collaborations, which are accepting, and identify potential bottlenecks.\n\n**2. Building a Multi-Agent Chatbot System for Customer Support:**\n\n*   **Scenario:**  You have a system where multiple specialized chatbots (e.g., order status, billing, technical support) handle different aspects of customer inquiries. An LLM orchestrates the interaction.\n*   **Implementation:** Similar to the writing app, log each chatbot's actions (asking questions, providing information, transferring the chat).  Track when one chatbot's action triggers another's, indicating interdependency.  For example:\n    *   **Trigger Action:** The order status bot identifies a delayed shipment.\n    *   **Accept Action:** The technical support bot proactively offers to troubleshoot potential delivery issues.\n*   **Optimization:** The LLM orchestrator can use the interdependence data to improve its routing decisions.  If it sees a low level of interdependency between certain bots, it can adjust its logic to promote collaboration.\n\n**3. Developing a Multi-Agent Game with LLMs and Human Players:**\n\n*   **Scenario:** Create a web-based game where human players and LLM-controlled characters collaborate to achieve a common goal.\n*   **Implementation:**  Log each player and character's actions in the game.  Analyze these actions for interdependencies. For instance:\n    *   **Trigger Action:** An LLM-controlled character heals a human player.\n    *   **Accept Action:** The human player continues fighting, demonstrating reliance on the character's action.\n*   **Evaluation and Tuning:** Use the interdependence data to evaluate different LLM prompting strategies or reward functions.  Strategies that promote higher interdependency likely lead to better team performance.\n\n**JavaScript Tools and Frameworks:**\n\n*   **LangChain:** Simplifies LLM integration and provides tools for managing conversations, chains, and agents.  You can extend it to track and analyze interdependencies.\n*   **Chart.js/D3.js:**  Visualize the interdependency data for easier interpretation and debugging.\n*   **Node.js with Socket.IO:**  Build real-time, multiplayer web applications, essential for multi-agent systems.\n\n**Key Takeaways for JavaScript Developers:**\n\n*   **Shift Focus from Task Completion to Collaboration:** Don't just measure whether the task is completed, but *how* the agents are working together.\n*   **Log and Analyze Agent Actions:** Capture granular event data to identify trigger and accept actions.\n*   **Visualize Interdependencies:**  Make the collaboration patterns visible to understand team dynamics.\n*   **Use Interdependence Data for Optimization:**  Tune LLM prompting, reward functions, and agent coordination logic based on the interdependence analysis.\n\n\nBy applying these ideas, JavaScript developers can leverage the insights from this research paper to build more effective and cooperative LLM-based multi-agent web applications.  This approach opens up new possibilities for enhancing user experience, automating complex tasks, and creating more engaging interactive applications.",
  "pseudocode": "```javascript\nfunction evaluateInterdependencies(trajectory, numAgents) {\n  // Initialize giver and receiver lists for each agent\n  const giverLists = new Array(numAgents).fill(null).map(() => new Set());\n  const receiverLists = new Array(numAgents).fill(null).map(() => new Set());\n  const addLists = new Array(numAgents).fill(null).map(() => new Set());\n\n\n  // Iterate through the trajectory (timesteps)\n  for (let t = 0; t < trajectory.length; t++) {\n    const jointAction = trajectory[t]; // Joint action at timestep t\n\n\n    for (let i = 0; i < numAgents; i++) {\n      const action = jointAction[i];\n      const preconditions = action.preconditions;\n      const addEffects = action.addEffects;\n      const deleteEffects = action.deleteEffects;\n\n\n\n\n      addLists[i] = new Set([...addLists[i], ...preconditions]);\n\n\n      for (let j = 0; j < numAgents; j++) {\n        if (i !== j) {\n\n\n          const intersection = new Set([...preconditions].filter(x => addLists[j].has(x)));\n          if (intersection.size >0){\n             for (const precondition of intersection){\n                receiverLists[i].add(precondition);\n                giverLists[j].add(precondition);\n                addLists[j].delete(precondition);\n             }\n\n\n          }\n\n\n        }\n\n\n      }\n\n\n    }\n  }\n    return [giverLists, receiverLists];\n}\n\n\n/*\nExplanation:\n\n\n\nThis function analyzes a multi-agent solution trajectory to identify interdependencies between agents' actions.\n\n\nPurpose:\n\n\n\nQuantify cooperation by identifying how often one agent's action sets up the preconditions for another agent's subsequent action. This helps measure \"teamwork\" beyond just overall task success.\n\n\n\nAlgorithm:\n\n\n\nInitialization: Creates empty giver and receiver lists for each agent, representing interdependencies given and received.\n\n\nTrajectory Iteration: Loops through each timestep of the provided trajectory.\n\n\nJoint Action Processing: Examines the joint action of all agents at each timestep.\n\n\nIndividual Agent Action Analysis: For each agent's action:\n\n\nExtract preconditions and add effects.\n\n\nInterdependency Check: For each other agent, checks if the current agent's add effects fulfill any of the other agent's preconditions from the current timestep.\n\n\n\nUpdate Lists: If an interdependency is found (intersection), update giver and receiver lists accordingly.\n\n\n\nReturn: Returns the giver and receiver lists for analysis and further metric calculations.\n\n\n\n*/\n\n\n// Example usage (assuming a trajectory and actions with preconditions and addEffects are defined)\nconst trajectory = [\n  [{ preconditions: ['A'], addEffects: ['B'] }, { preconditions: ['C'], addEffects: ['D'] }],\n  [{ preconditions: ['B'], addEffects: ['E'] }, { preconditions: ['F'], addEffects: ['G'] }],\n];\nconst numAgents = 2;\nconst [giverList, receiverList] = evaluateInterdependencies(trajectory, numAgents);\n\n\nconsole.log(\"Giver Lists:\", giverList);\nconsole.log(\"Receiver Lists:\", receiverList);\n\n```\n\n**Explanation of the Algorithm and its Purpose:**\n\nThe JavaScript code implements Algorithm 1 from the research paper, which analyzes interdependencies in a multi-agent solution trajectory.  Its purpose is to quantify cooperation between agents by identifying instances where one agent's action facilitates another agent's subsequent action.  This goes beyond simply measuring overall task success and delves into how well the agents work together as a team.\n\nThe algorithm iterates through a \"trajectory,\" which is a sequence of joint actions taken by all agents.  For each joint action, it examines the individual actions of each agent.  Specifically, it looks at the *preconditions* required for an agent's action to be executed and the *add effects* that result from the action.\n\nAn interdependency occurs when one agent's *add effects* satisfy the *preconditions* of another agent's later action.  The algorithm keeps track of these interdependencies using \"giver\" and \"receiver\" lists.  The agent whose action enabled another agent's action is the \"giver,\" and the agent whose action was enabled is the \"receiver.\"\n\nBy analyzing these giver and receiver lists, researchers can gain insights into the level and nature of cooperation between agents.  This can inform the development of more effective multi-agent learning algorithms that promote collaboration.",
  "simpleQuestion": "How can we measure AI-human teamwork effectiveness?",
  "timestamp": "2025-02-12T06:07:11.158Z"
}