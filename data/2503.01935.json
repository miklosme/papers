{
  "arxivId": "2503.01935",
  "title": "MultiAgentBench: Evaluating the Collaboration and Competition of LLM agents",
  "abstract": "Large Language Models (LLMs) have shown remarkable capabilities as autonomous agents; yet existing benchmarks either focus on single-agent tasks or are confined to narrow domains, failing to capture the dynamics of multi-agent coordination and competition. In this paper, we introduce MultiAgentBench, a comprehensive benchmark designed to evaluate LLM-based multi-agent systems across diverse, interactive scenarios. Our framework measures not only task completion but also the quality of collaboration and competition using novel, milestone-based key performance indicators. Moreover, we evaluate various coordination protocols (including star, chain, tree, and graph topologies) and innovative strategies such as group discussion and cognitive planning. Notably, gpt-4o-mini reaches the average highest task score, graph structure performs the best among coordination protocols in the research scenario, and cognitive planning improves milestone achievement rates by 3%. Code and datasets are publicavailable at https://github.com/MultiagentBench/MARBLE.",
  "summary": "This paper introduces MultiAgentBench, a benchmark for evaluating how well multiple AI agents based on Large Language Models (LLMs) can work together or compete in various tasks. Key points for LLM-based multi-agent systems include: MultiAgentBench tests collaboration and competition across different domains (research, coding, gaming, negotiations);  it uses new ways to measure how well the agents coordinate, communicate, and plan; the study found that a good LLM is crucial for success, but coordination also matters; agents can show emergent behaviors like strategic information sharing and adapting their roles during tasks; and while better LLMs lead to better performance, effective collaboration is still key, even against weaker opponents.",
  "takeaways": "The MultiAgentBench paper provides valuable insights for JavaScript developers venturing into LLM-based multi-agent applications, particularly in web development.  Here's how a JavaScript developer can apply the research findings:\n\n**1. Structuring Communication & Coordination:**\n\n* **Agent Graph Implementation:**  The paper's emphasis on structured communication via an Agent Graph translates directly to JavaScript development. You can represent the graph using a JavaScript object or utilize graph libraries like `vis-network` or `Cytoscape.js`. This structure defines communication pathways and helps avoid the \"bad communication\" scenarios highlighted in the paper (e.g., endless repetition, stalled progress).\n\n```javascript\n// Example using a simple JavaScript object\nconst agentGraph = {\n  agent1: { neighbors: ['agent2', 'agent3'], role: 'planner' },\n  agent2: { neighbors: ['agent1'], role: 'actor' },\n  agent3: { neighbors: ['agent1'], role: 'actor' },\n};\n\n// Function to send a message based on the graph structure\nfunction sendMessage(sender, recipient, message) {\n  if (agentGraph[sender].neighbors.includes(recipient)) {\n    // Implement message passing logic (e.g., using WebSockets)\n    console.log(`${sender} sent \"${message}\" to ${recipient}`);\n  } else {\n    console.log(`Communication not allowed between ${sender} and ${recipient}`);\n  }\n}\n```\n* **Coordination Protocols:**  Implement coordination protocols (star, chain, graph) in your JavaScript code. For a star topology, a central agent (implemented as a JavaScript class) would manage tasks and communication. For a graph-mesh, use a distributed approach with peer-to-peer communication (e.g. via WebRTC).\n\n\n**2. Milestone-Based Progress Tracking:**\n\n* **Frontend Visualization:**  Visualize milestones on the frontend using frameworks like React, Vue, or Angular. As agents complete milestones, update the UI in real-time. This gives users visibility into progress and facilitates debugging.\n\n```javascript\n// Example using React\nimport React, { useState } from 'react';\n\nfunction MilestoneTracker({ milestones }) {\n  const [completedMilestones, setCompletedMilestones] = useState([]);\n\n  // Function to update completed milestones (called when an agent reports progress)\n  const markMilestoneComplete = (milestoneId) => {\n    setCompletedMilestones([...completedMilestones, milestoneId]);\n  };\n\n\n  return (\n    <ul>\n      {milestones.map((milestone) => (\n        <li key={milestone.id} style={{ textDecoration: completedMilestones.includes(milestone.id) ? 'line-through' : 'none' }}>\n          {milestone.name}\n        </li>\n      ))}\n    </ul>\n  );\n}\n```\n* **Backend Tracking:** Implement milestone tracking logic on the backend (e.g., Node.js). Store milestone status and contributing agents in a database (e.g. MongoDB) and provide APIs for agents to report progress and retrieve current status.\n\n**3. Implementing Planning Strategies:**\n\n* **Prompt Engineering in JavaScript:** The paper highlights various planning strategies.  Translate these to JavaScript by dynamically constructing prompts for your LLM using template literals or string manipulation. Incorporate Chain-of-Thought (CoT) by generating intermediate reasoning steps within the prompt.\n\n```javascript\n// Example of dynamic prompt construction for a \"research task\"\nfunction generateResearchPrompt(agentProfile, previousSummary, task) {\n  return `\n    Agent Profile: ${JSON.stringify(agentProfile)}\n    Previous Summary: ${previousSummary}\n    Task: ${task}\n    Think step by step.  First, analyze the problem... Then, propose a research direction... Finally, outline the expected outcomes...\n    Now, generate the 5q research proposal...\n  `;\n}\n\n```\n* **Cognitive Planning Loop:**  Create a JavaScript loop that implements the cognitive planning approach: generate a plan, execute, evaluate against expected outcomes, refine plan. Use JavaScript's asynchronous capabilities (async/await) to handle interactions with the LLM.\n\n**4. Evaluation and Metrics:**\n\n* **JavaScript-based Metric Calculation:**  Implement metric calculation logic in JavaScript. For example, calculate KPI by tracking completed milestones and individual contributions. Use JavaScript libraries for data analysis and visualization (e.g., `D3.js`, `Chart.js`) to visualize evaluation results.\n\n\n**Example Web Development Scenario:**\n\nImagine building a collaborative code editor where multiple LLM agents assist developers.  The agents could specialize in code generation, debugging, testing, and documentation. You would use the Agent Graph to structure communication, visualize milestones (e.g., \"feature implemented,\" \"tests passed\") using React, implement planning strategies via dynamic prompt engineering, and track metrics to evaluate the agent's effectiveness.  \n\nBy translating the MultiAgentBench concepts into JavaScript code and utilizing relevant web development technologies, developers can create innovative and practical multi-agent web applications that leverage the power of LLMs for enhanced user experiences and increased productivity.",
  "pseudocode": "No pseudocode block found.",
  "simpleQuestion": "How can I best benchmark LLM agent collaboration and competition?",
  "timestamp": "2025-03-05T06:04:10.212Z"
}