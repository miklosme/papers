{
  "arxivId": "2503.12613",
  "title": "Negotiative Alignment: Embracing Disagreement to Achieve Fairer Outcomes – Insights from Urban Studies",
  "abstract": "Cities are not monolithic; they are arenas of negotiation among groups that hold varying needs, values, and experiences. Conventional methods of urban assessment—from standardized surveys to AI-driven evaluations—frequently rely on a single consensus metric (e.g., an average measure of inclusivity or safety). Although such aggregations simplify design decisions, they risk obscuring the distinct perspectives of marginalized populations. In this paper, we present findings from a community-centered study in Montreal involving 35 residents with diverse demographic and social identities, particularly wheelchair users, seniors, and LGBTQIA2+ individuals. Using rating and ranking tasks on 20 urban sites, we observe that disagreements are systematic rather than random, reflecting structural inequalities, differing cultural values, and personal experiences of safety and accessibility. Based on these empirical insights, we propose negotiative alignment, an AI framework that treats disagreement as an essential input to be preserved, analyzed, and addressed. Negotiative alignment builds on pluralistic models by dynamically updating stakeholder preferences through multi-agent negotiation mechanisms, ensuring no single perspective is marginalized. We outline how this framework can be integrated into urban analytics—and other decision-making contexts—to retain minority viewpoints, adapt to changing stakeholder concerns, and enhance fairness and accountability. The study demonstrates that preserving and engaging with disagreement, rather than striving for an artificial consensus, can produce more equitable and responsive AI-driven outcomes in urban design.",
  "summary": "This paper proposes \"negotiative alignment,\" a multi-agent AI framework for fairer decision-making in scenarios with diverse stakeholder preferences. It uses urban design evaluations as a case study, finding that averaging opinions obscures minority viewpoints.\n\nKey points for LLM-based multi-agent systems:\n\n* **Preserve disagreement:** Instead of seeking consensus, the framework treats disagreement as valuable input.  This is relevant to LLMs by offering a way to represent and manage conflicting information or preferences generated by different agents or retrieved from external sources.\n* **Dynamically update preferences:** Agent weights and preference distributions are updated iteratively through negotiation. This could be applied to LLMs by dynamically adjusting the importance given to different agent prompts or data sources based on evolving circumstances and feedback.\n* **Identity preservation:**  A metric is proposed to ensure that minority preferences aren't erased.  LLMs could incorporate similar principles by prioritizing underrepresented viewpoints or fairness constraints during generation and decision-making.\n* **Negotiation operator:** A core component of the framework is a negotiation operator that uses bargaining rules to find solutions.  This could be implemented in LLMs by incorporating similar rules or mechanisms to resolve conflicts and generate compromises between competing agent goals.\n* **Iterative refinement:** The iterative nature of the approach allows the system to adapt to changing needs and feedback. LLMs can benefit from similar principles by iteratively refining their outputs or strategies based on ongoing dialogue or feedback from multiple agents.",
  "takeaways": "This paper introduces \"Negotiative Alignment,\" a fascinating concept for building fairer multi-agent systems by embracing and addressing disagreements rather than seeking a single consensus.  Let's translate this into practical JavaScript examples for LLM-based multi-agent web applications:\n\n**Scenario 1: Collaborative Writing Tool**\n\nImagine building a collaborative document editor where multiple LLM agents assist users in writing. Each agent could specialize in a different aspect, like grammar, style, tone, or fact-checking.  Negotiative alignment can help resolve conflicts between agent suggestions.\n\n```javascript\n// Simplified example using a hypothetical LLM agent interaction library\nimport * as llmAgent from 'llm-agent-library';\n\n// Agents\nconst grammarAgent = llmAgent.createAgent('grammar');\nconst styleAgent = llmAgent.createAgent('style');\n\n// User input\nconst userText = \"This sentence is good, but could be better.\";\n\n// Agent suggestions\nconst grammarSuggestions = await grammarAgent.suggest(userText); // e.g., \"This sentence is good, but it could be better.\"\nconst styleSuggestions = await styleAgent.suggest(userText); // e.g., \"This sentence is adequate, but could be more impactful.\"\n\n\n// Negotiative Alignment Logic (Simplified)\nfunction negotiate(suggestions) {\n  // 1. Identify Conflicts:  Compare suggestions for overlapping changes.\n  const conflictingChanges = findConflicts(suggestions);\n\n\n  // 2. Negotiate:  Use a negotiation strategy.\n  //    Simple strategy: Choose the suggestion with higher confidence score.\n  //    Advanced strategy:  Prompt a meta-LLM agent to resolve the conflict by considering agent specializations and user preferences.  \n  const resolvedSuggestions = resolveConflicts(conflictingChanges, suggestions);\n\n\n  // 3. Apply Resolved Changes:  Update user text with the resolved suggestions.\n  const finalText = applyChanges(userText, resolvedSuggestions);\n\n\n  return finalText;\n}\n\n// ... (Implementation of findConflicts, resolveConflicts, applyChanges, etc.)\n\nconst finalText = negotiate([grammarSuggestions, styleSuggestions]);\nconsole.log(finalText); // Output a resolved version of the text\n```\n\n**Scenario 2:  Personalized Recommendation System**\n\nConsider a multi-agent recommendation system for e-commerce. Agents might specialize in different product categories or user demographics.  Negotiative alignment can be used to balance diverse recommendations and avoid bias.\n\n```javascript\n// Simplified example using Node.js and Express\nconst express = require('express');\nconst app = express();\n\n// ... (LLM agent setup for different categories - books, electronics, etc.)\n\n\napp.get('/recommendations', async (req, res) => {\n  const userId = req.query.userId;\n\n  // Get recommendations from different agents.\n  const bookRecommendations = await bookAgent.recommend(userId); \n  const electronicsRecommendations = await electronicsAgent.recommend(userId); \n\n\n  // Negotiative Alignment Logic: \n  //    Strategy: Allocate a percentage of the recommendation slots to each category \n  //              based on user history, diversity goals, or even a negotiation process between agents.\n\n\n  const recommendations = combineRecommendations(bookRecommendations, electronicsRecommendations, userId);\n\n  res.json(recommendations);\n});\n\n// ... (Implementation of combineRecommendations)\n```\n\n**Key JavaScript Libraries and Technologies:**\n\n* **LLM Interaction Libraries:** LangChain is gaining popularity for connecting to various LLM providers. You can use these libraries to build your custom multi-agent systems.\n* **Frontend Frameworks:** React, Vue, or Angular can be used to build interactive user interfaces for multi-agent applications.\n* **Backend Frameworks:**  Node.js with Express or NestJS can provide the server-side logic for agent management and negotiation.\n* **Message Queues:** Redis or RabbitMQ can facilitate communication between agents.\n\n\n**Key Implementation Considerations:**\n\n* **Conflict Detection:** How will your system identify disagreements between agents? This could involve comparing output text, evaluating confidence scores, or semantic analysis.\n* **Negotiation Strategies:** Implement simple voting schemes, weighted averages, or sophisticated negotiation protocols inspired by game theory.\n* **Preference Representation:** Store user preferences and agent specializations in a structured format (JSON, database) to use during negotiation.\n* **Evaluation:** Implement metrics like the paper's DCR and IPI (in JavaScript) to monitor fairness and identify potential biases.\n\n\nBy incorporating the concepts of \"negotiative alignment\" into your LLM-based multi-agent systems, you can create web applications that are more equitable, responsive, and capable of representing diverse perspectives.  Remember to prioritize transparency and accountability in the design and implementation of the negotiation mechanisms.",
  "pseudocode": "```javascript\nfunction oneHot(rating) {\n  // Converts a scalar rating (1-5) to a one-hot vector.\n  // Ratings outside the range are clipped to the nearest bound.\n  const ratingBin = Math.max(1, Math.min(5, Math.round(rating)));\n  const vec = new Array(5).fill(0);\n  vec[ratingBin - 1] = 1.0;\n  return vec;\n}\n\nfunction negotiationOperator(P, lambdas, gamma) {\n  // Negotiation operator that updates consensus and stakeholder weights.\n  // P: Array of group ratings (P_g)\n  // lambdas: Current weights for each stakeholder group\n  // gamma: Step size for weight update (0 < gamma <= 1)\n\n  // 1. Compute the consensus (x*) as the weighted average of P.\n  const xStar = math.dot(lambdas, P); // Using math.js for dot product\n\n  // 2. Compute the disagreement Delta for each group.\n  const Delta = P.map(p => Math.abs(p - xStar));\n\n  // 3. Normalize disagreements (uniform if total disagreement is zero).\n  let disagreementNormalized;\n  if (math.sum(Delta) === 0) {\n    disagreementNormalized = Delta.map(() => 1 / Delta.length);\n  } else {\n    disagreementNormalized = Delta.map(d => d / math.sum(Delta));\n  }\n\n\n  // 4. Update weights via linear interpolation.\n  const lambdasOld = lambdas.slice(); // Create a copy for NPM\n  const lambdasNew = lambdas.map((lambda, i) => (1 - gamma) * lambda + gamma * disagreementNormalized[i]);\n\n\n  // 5. Normalize the new weights.\n  const sumLambdasNew = math.sum(lambdasNew);\n  const normalizedLambdasNew = lambdasNew.map(l => l / sumLambdasNew);\n\n  return [xStar, Delta, normalizedLambdasNew, lambdasOld];\n}\n\n\nfunction updateIdentityPreservation(piCurrent, xStar, Delta, maxDelta = 4.0) {\n  // Updates each group's preference distribution (pi) to preserve\n  // its identity when disagreement is high.\n\n  const consensusVec = oneHot(xStar);\n  const piNew = piCurrent.map((piG, g) => {\n    const beta = Math.min(Delta[g] / maxDelta, 1); // Disagreement-dependent blending\n    const updatedPiG = piG.map((val, i) => beta * val + (1 - beta) * consensusVec[i]);\n    const sumUpdatedPiG = math.sum(updatedPiG);\n    return updatedPiG.map(val => val / sumUpdatedPiG); // Normalize\n  });\n  return piNew;\n}\n\nfunction computeIPI(piOrig, piCurrent) {\n  // Computes the Identity Preservation Index (IPI) for each group.\n  // Jensen-Shannon divergence squared (base 2)\n  const jsd = jensenshannon(piOrig, piCurrent, 2)**2;\n  return 1 - jsd;\n}\n\n// Example usage (similar to Python prototype)\nconst P = [3.0, 2.0, 1.7, 2.0, 2.0, 1.7];\nconst G = P.length;\nlet lambdas = Array(G).fill(1 / G); // Initial weights\nlet piCurrent = P.map(oneHot); // Initial preference distributions\nconst piOrig = piCurrent.slice(); // Save original preferences for IPI\nconst gamma = 0.5;\nconst epsilon = 0.01;\nconst maxIterations = 10;\nconst deltaThreshold = 0.45;\nconst results = [];\n\n\nfor (let t = 0; t <= maxIterations; t++) {\n\n  let [xStar, Delta, lambdasNew, lambdasOld] = negotiationOperator(P, lambdas, gamma);\n\n\n\n  // Fairness Metrics\n  const DCR = (Delta.filter(d => d >= deltaThreshold).length / G) * 100;\n  const NPM = t === 0 ? 0 : math.mean(math.abs(math.subtract(lambdasNew, lambdasOld)));\n\n  // Update identity preservation\n  piCurrent = updateIdentityPreservation(piCurrent, xStar, Delta);\n\n  // IPI calculation\n  const IPIVals = piOrig.map((orig, g) => computeIPI(orig, piCurrent[g]));\n  const avgIPI = math.mean(IPIVals) * 100;\n\n\n  results.push({\n    Iteration: t,\n    \"Consensus (x*)\": xStar.toFixed(3),\n    Weights: lambdasNew.map(w => w.toFixed(3)),\n    \"DCR (%)\": DCR.toFixed(1),\n    NPM: NPM.toFixed(3),\n    \"Avg IPI (%)\": avgIPI.toFixed(1),\n  });\n\n  lambdas = lambdasNew;\n\n  if (t > 0 && Math.max(...math.abs(math.subtract(lambdas, lambdasOld))) < epsilon) break;\n\n}\nconsole.table(results);\n\n\n```\n\n\n**Explanation of Algorithms and Purpose:**\n\n1. **`oneHot(rating)`:** This function takes a scalar rating value (between 1 and 5) and converts it into a one-hot vector.  One-hot encoding is a common technique in machine learning where a categorical value is represented as a binary vector with only one element set to 1 (indicating the active category) and all others set to 0.  This function ensures that the input rating is within the valid range (1 to 5) by rounding and clipping it. The purpose is to prepare the rating data for use in the multi-agent negotiation process.\n\n\n2. **`negotiationOperator(P, lambdas, gamma)`:** This is the core function of the negotiative alignment algorithm. It simulates a single round of negotiation between different stakeholder groups.\n    - **Input:**\n        - `P`: An array of ratings for an urban space, with each element representing a rating from a different group.\n        - `lambdas`: An array representing the current weights assigned to each stakeholder group.  These weights reflect the influence of each group in the overall evaluation.\n        - `gamma`: A step-size parameter (between 0 and 1) controlling how much the weights are updated in each iteration.  A larger gamma means more aggressive adjustments.\n    - **Process:**\n        - **Consensus Calculation:**  The function first calculates a consensus rating (`xStar`) as the weighted average of the group ratings, using the current `lambdas`.\n        - **Disagreement Calculation:** It then computes the absolute difference between each group's rating and the consensus, representing the level of disagreement (`Delta`).\n        - **Weight Update:** The weights (`lambdas`) are updated based on the normalized disagreement values.  Groups with higher disagreement are given more weight in the next round of negotiation.\n    - **Output:** The function returns the updated consensus, the disagreement values, the new stakeholder weights (`lambdasNew`), and the previous weights (`lambdasOld`).\n\n\n3. **`updateIdentityPreservation(piCurrent, xStar, Delta, maxDelta)`:** This function updates the preference distribution of each stakeholder group to preserve their original preferences when disagreement is high.\n    - **Input:**\n        - `piCurrent`: The current preference distributions for each group (represented as probability distributions).\n        - `xStar`: The current consensus rating.\n        - `Delta`: The disagreement values for each group.\n        - `maxDelta`: The maximum possible disagreement (used for normalization).\n    - **Process:**\n        - The function calculates a blending factor (`beta`) based on the level of disagreement for each group. Higher disagreement leads to a higher `beta`, which means that the current preference distribution is preserved more strongly.  If there is no disagreement, it blends more to consensus\n        - It then updates each group's preference distribution by blending the current distribution with a one-hot vector representing the consensus rating, using the calculated `beta`.\n    - **Output:** The function returns the updated preference distributions (`piNew`).\n\n4. **`computeIPI(piOrig, piCurrent)`:** This function computes the Identity Preservation Index (IPI) for each group.\n    - **Input:**\n        - `piOrig`: The original preference distributions for each group.\n        - `piCurrent`: The current preference distributions for each group.\n    - **Process:**\n        - The function calculates the Jensen-Shannon divergence (JSD) between the original and current preference distributions for each group.  JSD is a measure of the similarity between two probability distributions.\n        - The IPI is calculated as 1 - JSD². A higher IPI indicates that the group's current preferences are closer to its original preferences (i.e., its identity is better preserved).\n    - **Output:** The function returns an array of IPI values, one for each stakeholder group.\n\n\nThe overall purpose of this JavaScript code is to implement a simplified prototype of the negotiative alignment framework described in the research paper. This framework aims to incorporate disagreement into AI decision-making processes, especially in domains like urban planning where diverse stakeholder preferences need to be considered fairly.  By iteratively updating stakeholder weights and preference distributions based on negotiation outcomes, the framework seeks to achieve more equitable and representative solutions.",
  "simpleQuestion": "Can diverse opinions improve AI urban planning?",
  "timestamp": "2025-03-18T06:04:29.517Z"
}