{
  "arxivId": "2502.11705",
  "title": "LLM Agents Making Agent Tools",
  "abstract": "Tool use has turned large language models (LLMs) into powerful agents that can perform complex multi-step tasks by dynamically utilising external software components. However, these tools must be implemented in advance by human developers, hindering the applicability of LLM agents in domains which demand large numbers of highly specialised tools, like in life sciences and medicine. Motivated by the growing trend of scientific studies accompanied by public code repositories, we propose TOOLMAKER, a novel agentic framework that autonomously transforms papers with code into LLM-compatible tools. Given a short task description and a repository URL, TOOLMAKER autonomously installs required dependencies and generates code to perform the task, using a closed-loop self-correction mechanism to iteratively diagnose and rectify errors. To evaluate our approach, we introduce a benchmark comprising 15 diverse and complex computational tasks spanning both medical and non-medical domains with over 100 unit tests to objectively assess tool correctness and robustness. TOOLMAKER correctly implements 80% of the tasks, substantially outperforming current state-of-the-art software engineering agents. TOOLMAKER therefore is a step towards fully autonomous agent-based scientific workflows.",
  "summary": "This paper introduces TOOLMAKER, an AI agent that automatically transforms code from research papers into tools usable by other LLM-based agents.  This addresses the limitation of current LLM agents that rely on pre-defined tools, thereby expanding their potential for complex, multi-step scientific tasks.  A new benchmark, TM-BENCH, was also created to evaluate the effectiveness of these automatically generated tools.  TOOLMAKER successfully implemented 80% of the benchmark tasks, outperforming existing methods. This signifies a step towards fully autonomous, agent-driven scientific workflows.",
  "takeaways": "This paper introduces TOOLMAKER, an AI agent that automatically creates tools from research papers and code repositories, enabling other LLM agents to perform complex, multi-step scientific tasks. Here's how JavaScript developers can apply these insights to LLM-based multi-agent app development:\n\n**1. Dynamic Tool Creation and Integration:**\n\n* **Concept:** TOOLMAKER dynamically creates tools.  Imagine a multi-agent web app where agents need to access different APIs or perform various data processing tasks. Instead of pre-defining all possible tools, an agent like TOOLMAKER could create or adapt tools at runtime.\n* **JavaScript Application:**\n    * **LangChain.js:** Use LangChain.js to manage your LLM interactions and tool usage. Define a \"TOOLMAKER agent\" that uses LangChain's tool creation capabilities. This agent could receive prompts describing a needed tool, and dynamically generate JavaScript code (or utilize existing npm packages) to create that tool.\n    * **Dynamic Module Loading:** JavaScript's dynamic `import()` syntax allows loading modules (your created tools) at runtime.  The TOOLMAKER agent could generate the import statement and execute it, making the new tool immediately available.\n    * **Example:**  A user asks your web app to analyze data from a specific social media API. The TOOLMAKER agent creates a JavaScript module that handles authentication and data fetching from that API. This module is dynamically loaded and becomes a tool accessible to other agents in your app.\n\n\n**2. Agent-Based Workflows in Web Apps:**\n\n* **Concept:** TOOLMAKER enables multi-step computational workflows handled by agents. This can be applied to complex web app tasks that require coordination between different functionalities.\n* **JavaScript Application:**\n    * **Agent Framework:** Consider a framework like the Agents.js library (though it's not specifically designed for LLMs, it could be adapted).  Each agent would be responsible for a part of the workflow (e.g., UI interaction, data fetching, LLM interaction, result presentation).\n    * **Message Passing:** Agents could communicate through a message bus (e.g., using Node.js's `EventEmitter` or libraries like `mitt`). The TOOLMAKER agent would listen for messages requesting new tools or services.\n    * **Example:**  Building an interactive writing assistant. One agent handles user input, another interacts with the LLM for text generation, and a TOOLMAKER agent creates tools for specific tasks (e.g., grammar checking, plagiarism detection, fact verification) as needed by the workflow.\n\n\n\n**3. Decentralized Web Application Logic:**\n\n* **Concept:**  The multi-agent nature of TOOLMAKER points towards more decentralized web applications.\n* **JavaScript Application:**\n    * **Microservices Architecture:** TOOLMAKER could create tools as individual microservices, accessible through APIs. This promotes modularity and scalability.\n    * **Web Workers:**  Use Web Workers to encapsulate agent logic and tool execution in separate threads, preventing blocking the main thread and improving UI responsiveness.\n    * **Example:**  A multi-agent e-commerce app.  One agent handles product recommendations, another manages the shopping cart, and a TOOLMAKER agent creates tools for dynamic pricing, inventory management, or shipping calculations, each as a separate microservice.\n\n\n**4. Serverless Functions for Tool Execution:**\n\n* **Concept:** The generated tools can be efficiently deployed and executed.\n* **JavaScript Application:**\n    * **Serverless Frameworks:** Deploy TOOLMAKER-created tools as serverless functions (e.g., using AWS Lambda, Google Cloud Functions, or Vercel Functions) for on-demand execution, reducing server management overhead.\n    * **Example:** An image editing web app. A TOOLMAKER agent creates tools for specific image processing tasks (e.g., resizing, filtering, object detection) and deploys them as serverless functions.\n\n\n**Example using LangChain.js (conceptual):**\n\n```javascript\nimport { OpenAI } from \"langchain/llms/openai\";\nimport { initializeAgentExecutorWithOptions } from \"langchain/agents\";\n\nconst model = new OpenAI({ temperature: 0 });\nconst tools = []; // Initially empty\n\n// TOOLMAKER agent (simplified)\nasync function createTool(toolDescription) {\n  // Use LLM (model) to generate JavaScript code for the tool\n  const toolCode = await model.call(`Write JavaScript code for: ${toolDescription}`);\n\n  // ... (Dynamically load the toolCode as a module) ...\n  tools.push(newTool); // Add the new tool\n}\n\nconst executor = await initializeAgentExecutorWithOptions(tools, model, {\n  agentType: \"zero-shot-react-description\",\n});\n\n// ... (User interaction triggers a request for a new tool) ...\nawait createTool(\"A tool to get the current weather in London.\");\n\n// ... (Now other agents can use the new weather tool) ...\nconst result = await executor.call({ input: \"What's the weather like in London?\" });\nconsole.log(result.output);\n```\n\nThis conceptual example demonstrates the core idea.  Developing robust solutions requires further refinement, focusing on security, error handling, and testing the generated code. This translation focuses on providing practical, actionable insights for JavaScript developers, emphasizing the potential impact of TOOLMAKER-like concepts on web application development. Remember to consider the ethical implications and safety measures discussed in the paper when implementing such systems.",
  "pseudocode": "```javascript\n// TOOLMAKER Workflow (JavaScript Adaptation)\n\nasync function toolmakerWorkflow(toolDefinition, initialEnvironment) {\n  let conversationHistory = [toolDefinition];\n  let environment = initialEnvironment; // e.g., Docker container instance\n\n  // Install repository and get snapshot\n  let [updatedHistory, updatedEnvironment, installResult] = await installRepositoryAgent(conversationHistory, environment);\n  let installedEnvSnapshot = updatedEnvironment.snapshot();\n\n  // Explore the repository and create plan\n  let [exploreHistory, , exploreResult] = await exploreAgent(updatedHistory, installedEnvSnapshot);\n  let [planHistory, , planResult] = await planLLM(exploreHistory);\n  let [implementHistory, , implementResult] = await implementLLM(planHistory);\n  let code = implementResult;\n\n\n  let summaries = [];\n  let success = false;\n\n  while (!success) {\n\n    updatedEnvironment.restore(installedEnvSnapshot);\n    conversationHistory = planHistory.concat([code]); //Restore history and add code\n\n    // Run implementation in the environment and assess\n    let [runResult, output] = await runImplementation(updatedEnvironment, code, toolDefinition.example);\n    let assessResult = await assessToolOutputLLM(conversationHistory, output, toolDefinition);\n\n\n\n    if (assessResult.success) {\n        success = true;\n      return [updatedEnvironment, code];\n    }\n\n\n    //Diagnose error, re-implement and summarise\n    let [diagnoseHistory, , diagnoseResult] = await diagnoseErrorAgent(conversationHistory, updatedEnvironment, output);\n    let [reimplementHistory, , reimplementResult] = await reimplementLLM(diagnoseHistory, code, diagnoseResult);\n    code = reimplementResult;\n    let [summariseHistory, , summariseResult] = await summariseLLM(reimplementHistory);\n\n    summaries.push(summariseResult); //Add summary to list\n\n    conversationHistory = summariseHistory;\n\n  }\n}\n\n// Placeholder functions (replace with actual implementations)\n\nasync function installRepositoryAgent(h,e){ /*...*/ return [h, e, {}]; }\nfunction exploreAgent(h, e) { /*...*/ return [h,e,{}];}\nfunction planLLM(h){ /*...*/ return [h, {}, {}]; }\nfunction implementLLM(h){/*...*/ return [h, {}, {}]; }\nasync function runImplementation(e, code, example) { /*...*/ return [{},{}]; }\nfunction assessToolOutputLLM(h, output, toolDefinition){/*...*/ return {}; }\nfunction diagnoseErrorAgent(h, e, output){ /*...*/ return [h, e, {}]; }\nfunction reimplementLLM(h, code, diagnoseResult){ /*...*/ return [h, {}, {}]; }\nfunction summariseLLM(h){ /*...*/ return [h,{},{}]; }\n\n\n\n\n```\n\n**Explanation and Purpose:**\n\nThe provided JavaScript code is a structural adaptation of the TOOLMAKER workflow described in the research paper. Its purpose is to automate the creation of tools from scientific code repositories for use with LLM agents. \n\nThe `toolmakerWorkflow` function takes a `toolDefinition` (containing task description, repository URL, arguments, etc.) and an `initialEnvironment` (e.g., a Docker container instance) as input.  It then proceeds through the following stages:\n\n1. **Installation:** The `installRepositoryAgent` clones the specified repository and installs dependencies.  A snapshot of the installed environment is taken for reproducibility.\n\n2. **Exploration and Planning:** The `exploreAgent` gathers information from the repository, and the `planLLM` generates a high-level plan for implementing the tool.\n\n3. **Implementation:** The `implementLLM` generates the Python code for the tool based on the plan.\n\n4. **Closed-loop Self-Improvement:** This is the core iterative process. The `runImplementation` function executes the generated code in the Docker container. The `assessToolOutputLLM` evaluates the results using unit tests. If successful, the loop terminates. Otherwise, the `diagnoseErrorAgent` analyzes the error, and `reimplementLLM` generates a revised implementation. The `summariseLLM` function summarizes each attempt for context, guiding future iterations.  This process repeats until a successful implementation is created.\n\nThe placeholder functions represent the core actions and LLM calls in the workflow.  These need to be replaced with actual implementations using appropriate JavaScript libraries and LLM APIs (e.g., the OpenAI API) to create a functional TOOLMAKER system.  The code structure reflects the iterative and self-correcting nature of the tool creation process.\n\n\n\nImportant aspects from the paper not fully addressed in this adapted code (but essential to consider during implementation):\n\n* **Environment Interactions:** The adapted code abstracts environment interactions. In a real implementation, you would need to define functions to execute bash commands, read/write files, and manage the Docker container state.\n* **Tool Use and API Calls:**  Specific details on using OpenAI's function calling and structured output APIs are omitted.  You'll need to integrate them for interacting with the LLMs and handling tool calls correctly.\n* **Error Handling and Logging:** Robust error handling and logging (as emphasized in the paper) are crucial for diagnosing and fixing issues during tool creation.\n\nThis JavaScript adaptation provides a starting point for implementing TOOLMAKER.  Replacing placeholders, integrating with external services, and implementing robust error handling are essential for a fully functional system.",
  "simpleQuestion": "Can LLMs build their own tools?",
  "timestamp": "2025-02-18T06:08:37.694Z"
}