{
  "arxivId": "2412.04056",
  "title": "Prompt Engineering Guidance for Conceptual Agent-based Model Extraction using Large Language Models",
  "abstract": "This document contains detailed information about the prompts used in the experimental process discussed in the article \"Toward Automating Agent-based Model Generation: A Benchmark for Model Extraction using Question-Answering Techniques‚Äù. The article aims to utilize Question-answering (QA) models to extract the necessary information to implement Agent-based Modeling (ABM) from conceptual models. It presents the extracted information in formats that can be read by both humans and computers (i.e., JavaScript Object Notation (JSON)), enabling manual use by humans and auto-code generation by Large Language Models (LLM).",
  "summary": "This paper explores using Large Language Models (LLMs) to automatically extract information from conceptual descriptions of Agent-Based Models (ABMs) and translate that information into executable code, specifically JSON for human readability and potential LLM-driven code generation. It focuses on prompt engineering techniques to effectively query LLMs for extracting specific model components, such as agent characteristics, environment variables, and execution parameters.  The structured JSON output facilitates automated code generation or manual implementation by developers.  This approach addresses the complexity and labor-intensive process of translating ABM designs into working simulations.  A key finding is that complex nested prompts are less effective than a sequence of simpler, more focused prompts when querying current LLMs for accurate model extraction.",
  "takeaways": "This paper provides a structured approach to extracting information from conceptual descriptions of Agent-Based Models (ABMs) using Large Language Models (LLMs) and structuring it into JSON, ready for implementation. This is extremely valuable for JavaScript developers building LLM-powered multi-agent web applications.  Here's how a JavaScript developer can apply these insights:\n\n**1. Building a Multi-Agent Simulation in the Browser:**\n\nImagine building a simulation of a marketplace with buyers and sellers, entirely within a web browser.  This paper's prompt engineering techniques can be instrumental:\n\n* **Conceptual Model to JSON:** You can describe your marketplace ABM in natural language, detailing the agents (buyers, sellers), their properties (budget, inventory), and the environment (market prices).  Using an LLM and the provided prompts, you can extract this information into a structured JSON format.\n* **JavaScript Implementation with Libraries like Langchain:**  Langchain is a particularly suitable library to manage LLM interactions, orchestration, and data handling. You can use the generated JSON to instantiate agent objects in JavaScript. Libraries like `d3.js` or `PixiJS` can be used for visualization.\n* **LLM-Driven Agent Behavior:** You can use the extracted \"equation\" and \"update function\" fields from the JSON to define the logic of each agent's actions (e.g., a buyer agent's decision to purchase based on price and budget, formulated as a prompt template for the LLM).\n* **Dynamic Interactions and Updates:** The \"frequency\" and \"order_of_execution\" fields guide the simulation's timeline. You can use JavaScript's `setInterval` or similar functions to trigger agent actions at the specified frequencies. The environment variables, updated similarly, can influence agent behavior (e.g., market prices fluctuating).\n\n**2. Creating a Collaborative Multi-Agent Web App:**\n\nConsider a collaborative design tool where multiple users (represented as agents) interact in real-time.\n\n* **User Profiles as Agent Definitions:** Each user's profile information (preferences, design skills) can be treated as agent properties, extracted and structured using the described prompts and an LLM.\n* **Real-time Interaction with WebSockets:** WebSockets facilitate communication between agents (users) in the browser. The LLM can use the extracted JSON to generate responses for each agent based on the current state of the environment (the shared design space) and interactions with other agents.\n* **Conflict Resolution with LLM-Mediated Negotiation:**  The LLM can be prompted to mediate design conflicts between agents (users), using extracted rules and objectives to guide the negotiation process. The extracted JSON provides a structured representation of the constraints and goals.\n\n**3. Building a Multi-Agent Chatbot System:**\n\nImagine a website with multiple specialized chatbots working together.\n\n* **Chatbot Roles and Expertise:** Each chatbot's area of expertise (e.g., customer service, technical support) is defined as an agent role and extracted with the provided prompts.\n* **LLM-Powered Dialogue Management:** Each agent uses an LLM for natural language understanding and generation. They communicate with each other and the user based on the current state, their individual roles, and objectives extracted from the JSON.\n* **Task Delegation and Collaboration:** Based on the user's query, the initial chatbot can delegate the task to a more appropriate agent, resulting in a seamless multi-agent interaction managed by clear rules and data represented in JSON.  Langchain's agent functionalities can be extremely useful here.\n\n**Key JavaScript Frameworks/Libraries:**\n\n* **Langchain.js:** For LLM interaction, prompt management, and agent orchestration.\n* **WebSockets:**  For real-time communication in multi-agent web apps.\n* **D3.js/PixiJS/Three.js:** For visualizing agent-based simulations in the browser.\n* **React/Vue/Angular:** For building dynamic and interactive front-end interfaces.\n* **Node.js with Express:** For backend API development and communication with LLMs.\n\nBy applying the structured approach from the paper and utilizing these JavaScript tools, developers can efficiently build and manage complex multi-agent systems in web applications, leveraging the power of LLMs for agent behavior, communication, and decision-making. This translates complex research into directly actionable implementation steps for web developers.",
  "pseudocode": "No pseudocode block found. The paper focuses on prompt engineering for extracting information from text describing Agent-Based Models (ABMs), not on the algorithms for the ABMs themselves.  The output is structured JSON data intended for human interpretation or use by LLMs for code generation, but the paper doesn't present any algorithms for processing that data.",
  "simpleQuestion": "How can LLMs extract ABM code from prompts?",
  "timestamp": "2024-12-06T06:01:36.787Z"
}