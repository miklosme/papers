{
  "arxivId": "2502.02533",
  "title": "Multi-Agent Design: Optimizing Agents with Better Prompts and Topologies",
  "abstract": "Large language models, employed as multiple agents that interact and collaborate with each other, have excelled at solving complex tasks. The agents are programmed with prompts that declare their functionality, along with the topologies that orchestrate interactions across agents. Designing prompts and topologies for multi-agent systems (MAS) is inherently complex. To automate the entire design process, we first conduct an in-depth analysis of the design space aiming to understand the factors behind building effective MAS. We reveal that prompts together with topologies play critical roles in enabling more effective MAS design. Based on the insights, we propose Multi-Agent System Search (MASS), a MAS optimization framework that efficiently exploits the complex MAS design space by interleaving its optimization stages, from local to global, from prompts to topologies, over three stages: 1) block-level (local) prompt optimization; 2) workflow topology optimization; 3) workflow-level (global) prompt optimization, where each stage is conditioned on the iteratively optimized prompts/topologies from former stages. We show that Mass-optimized multi-agent systems outperform a spectrum of existing alternatives by a substantial margin. Based on the Mass-found systems, we finally propose design principles behind building effective multi-agent systems.",
  "summary": "This paper explores the automated design of multi-agent systems (MAS) driven by large language models (LLMs).  It aims to optimize both the individual agent prompts (instructions) and the overall system topology (how agents interact) for better performance.\n\nKey points for LLM-based multi-agent systems:\n\n* **Prompt optimization is crucial:**  Optimizing individual agent prompts is more effective than simply scaling the number of agents with default prompts.  Local prompt optimization (per agent) should be done before optimizing the overall system.  A final workflow-level prompt optimization further refines the system after the topology is determined.\n* **Topology matters, but not all topologies are equal:** Some agent interaction structures are more beneficial than others. The research introduces a method to identify and focus on the most influential topologies, simplifying the search for optimal designs.\n* **Automated design outperforms manual design:** The proposed multi-stage optimization framework (MASS) automatically finds better-performing multi-agent system designs than manually crafted or other existing automated approaches. MASS interleaves prompt and topology optimization in multiple stages.\n* **Guidelines for effective MAS design:**  The research suggests prioritizing individual agent prompt optimization, focusing on influential topologies, and considering the interdependence between agents when designing multi-agent systems.",
  "takeaways": "This paper introduces Multi-Agent System Search (MASS), a framework for optimizing the design of multi-agent systems powered by Large Language Models (LLMs).  Here's how a JavaScript developer can apply its insights to LLM-based multi-agent projects, focusing on web development scenarios:\n\n**1. Block-Level Prompt Optimization:**\n\n* **Scenario:** Imagine building a collaborative writing web app where multiple LLM agents contribute to a document. Each agent has a specific role: idea generation, grammar correction, style refinement, etc.\n* **Application:**  Use a JavaScript library like `langchain.js` to interface with your chosen LLM. Implement prompt optimization techniques inspired by MASS. For instance, systematically test variations of prompts for each agent role (e.g., \"Refine the following text for clarity and conciseness\" vs. \"Improve the readability of this paragraph\").  Evaluate the quality of each agent's output using metrics like perplexity, sentiment analysis, or even human evaluation through a user interface built with React or Vue.js. Store and compare results to identify the most effective prompts.\n\n**2. Workflow Topology Optimization:**\n\n* **Scenario:**  Develop a customer service chatbot system where multiple LLM agents handle different aspects of customer queries. One agent might specialize in product information, another in order tracking, and a third in technical support.\n* **Application:** Experiment with different interaction topologies.  MASS suggests topologies like \"Aggregate\" (parallel agents followed by consolidation), \"Reflect\" (agents review and improve each other's work), and \"Debate\" (agents argue to reach a consensus). Using Node.js, you can create a system where agents communicate through message queues (e.g., RabbitMQ, Kafka) or a real-time framework like Socket.IO. Log the conversation flow and customer satisfaction to identify which topology performs best.\n\n**3. Workflow-Level Prompt Optimization:**\n\n* **Scenario:**  Create a multi-agent system for e-commerce product recommendation. Agents analyze user browsing history, compare products, and generate personalized recommendations.\n* **Application:** Once you've chosen an optimal topology, fine-tune prompts at the workflow level. For example, if using an \"Aggregate\" topology, experiment with prompts that encourage agents to provide diverse recommendations (e.g., \"Suggest three products the user might like, focusing on different aspects like price, features, and popularity\"). Track click-through rates and conversion rates to measure the effectiveness of the optimized workflow prompts.\n\n\n**4.  Influence-Weighted Design Space:**\n\n* **Scenario:** Building a multi-agent system for news summarization where agents identify key facts, extract quotes, and generate concise summaries.\n* **Application:** MASS highlights the concept of an \"influence-weighted\" design space. This means focusing on topologies and prompt elements that are most likely to improve performance. In the news summarization example, you might prioritize optimizing the agent responsible for identifying key facts, as its output significantly impacts the other agents. Use A/B testing within your JavaScript front-end to compare the impact of different prompt changes.\n\n**5. Practical JavaScript Libraries & Frameworks:**\n\n* **Langchain.js:** For interfacing with LLMs and managing prompts.\n* **Node.js with message queues (RabbitMQ, Kafka) or Socket.IO:** To orchestrate agent communication.\n* **React or Vue.js:** To build user interfaces for prompt evaluation and system monitoring.\n* **TensorFlow.js or WebDNN:** To integrate any custom machine learning models for prompt optimization or output evaluation.\n\n**Example Code Snippet (Conceptual):**\n\n```javascript\n// Using langchain.js to manage agents and prompts\nimport { LLMChain, PromptTemplate } from \"langchain\";\n\nconst promptTemplate = new PromptTemplate({\n  template: \"Refine the following text: {text}\",\n  inputVariables: [\"text\"],\n});\n\nconst llmChain = new LLMChain({ llm: myLLM, prompt: promptTemplate });\n\n// Orchestrating agent communication with Socket.IO\nio.on(\"connection\", (socket) => {\n  socket.on(\"agentMessage\", (message) => {\n    // Route messages between agents based on topology\n  });\n});\n```\n\nBy combining these concepts with available JavaScript tools, developers can create more sophisticated and effective LLM-based multi-agent applications for the web. Remember that these are just starting points; the key is to experiment and iterate to discover what works best for your specific project.  Focus on measurable outcomes and user experience to validate the impact of MASS-inspired optimizations.",
  "pseudocode": "```javascript\n// MASS: Multi-Agent System Search (Algorithm 1)\nasync function mass(agenticModules, initialWorkflow, promptOptimizer, evaluator, validationSet, temperature, numCandidates, budget) {\n\n  // 1. Block-level Prompt Optimization\n  let optimizedPrompts = {};\n  let initialPredictor = agenticModules.find(module => module.name === 'Predictor'); // Assuming 'Predictor' is the initial agent\n  optimizedPrompts[initialPredictor.name] = await promptOptimizer.optimize(initialPredictor.prompt, validationSet); \n\n  let incrementalInfluence = {};\n  for (const module of agenticModules) {\n      if (module.name !== initialPredictor.name) {\n          optimizedPrompts[module.name] = await promptOptimizer.optimize(module.prompt, validationSet, optimizedPrompts[initialPredictor.name]);\n          // Placeholder for influence calculation (requires a workflow evaluation function)\n          incrementalInfluence[module.name] = await evaluator.evaluateInfluence(module, initialWorkflow, optimizedPrompts, validationSet);\n      }\n  }\n\n  // 2. Workflow Topology Optimization\n  let selectionProbability = softmax(Object.values(incrementalInfluence), temperature); // Placeholder for softmax function\n  let bestWorkflow = initialWorkflow;\n  let bestEvalScore = await evaluator.evaluate(initialWorkflow, optimizedPrompts, validationSet);\n  for (let i=0; i < numCandidates; i++) {\n      let candidateWorkflow = generateWorkflow(agenticModules, selectionProbability, budget);\n      if (candidateWorkflow){  //If valid candidate Workflow exists\n         let evalScore = await evaluator.evaluate(candidateWorkflow, optimizedPrompts, validationSet); \n         if (evalScore > bestEvalScore) {\n              bestEvalScore = evalScore;\n              bestWorkflow = candidateWorkflow;\n         }\n      }\n  }\n  \n  // 3. Workflow-level Prompt Optimization\n  for (const moduleName in bestWorkflow.modules) { // Iterate and optimize prompts based on best Workflow\n    optimizedPrompts[moduleName] = await promptOptimizer.optimize(bestWorkflow.modules[moduleName].prompt, validationSet, optimizedPrompts); \n  }\n\n\n\n  return { workflow: bestWorkflow, prompts: optimizedPrompts};\n\n  // Helper function (Placeholder) : To create a workflow structure based on agentic modules and selection probability, taking into consideration the budget\n  function generateWorkflow(modules, probabilities, budget){ \n    // Implementation would involve creating workflow structure by picking modules probabilistically (Pa > U(0,1)), \n    // concatenating and verifying correctness with constraints like max budget on number of agents, and validity of workflow structure\n\n    return null; // Placeholder return\n\n  }\n\n\n    // Helper function (Placeholder) : Softmax implementation\n    function softmax(arr, temp){\n        // Softmax calculation to generate probabilities for each element in arr\n        // temp is temperature to control exploration\n\n        return null; // Placeholder return\n    }\n\n}\n```\n\n\n\n**Explanation of MASS Algorithm and its purpose:**\n\nThe Multi-Agent System Search (MASS) algorithm aims to automatically design and optimize multi-agent systems driven by Large Language Models (LLMs).  It addresses the challenge of finding the best combination of individual agent prompts (instructions for LLMs) and the overall workflow (how agents interact).  The algorithm proceeds in three stages:\n\n1. **Block-level Prompt Optimization:** This stage focuses on optimizing the prompts for each individual agent type (e.g., \"Predictor,\" \"Reflector,\" \"Debator\"). It starts by optimizing the initial agent's prompt and then iteratively optimizes other agent prompts, potentially conditioned on the optimized prompt of the initial agent.  The influence of each agent is also estimated during this phase (though the provided code has a placeholder implementation for this evaluation).\n\n\n2. **Workflow Topology Optimization:**  This stage explores different ways to connect the agents (the \"topology\"). It uses the influence scores from the previous stage to create a probability distribution for selecting different agent types and connections. The goal is to find the workflow topology that leads to the best overall performance, considering constraints like the maximum number of agents (budget). The provided code includes placeholder implementations for workflow generation and probability calculation (softmax). Rejection sampling is employed to select valid workflow structures from this topology space.\n\n\n3. **Workflow-level Prompt Optimization:** After identifying the best workflow structure, this stage fine-tunes the prompts of all the agents within that workflow.  This is crucial because the optimal prompts for individual agents might change depending on how they interact with other agents in the overall system.  The provided code iterates through the modules in the best workflow and calls the `optimize` function again.\n\n\n\nThis multi-stage approach allows MASS to efficiently explore the complex design space of multi-agent systems. By optimizing at both the individual agent and system levels, it achieves better performance compared to manually designed or simpler automated methods.  The provided JavaScript code is a simplified representation of the algorithm and would need more detailed implementations of the helper functions and prompt optimization logic for practical use.",
  "simpleQuestion": "How to best design prompts and topologies for effective LLMs?",
  "timestamp": "2025-02-05T06:04:01.075Z"
}