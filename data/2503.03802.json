{
  "arxivId": "2503.03802",
  "title": "RiskAgent: Autonomous Medical AI Copilot for Generalist Risk Prediction",
  "abstract": "The application of Large Language Models (LLMs) to various clinical applications has attracted growing research attention. LLMs currently achieve competitive results compared to human experts in examinations. However, real-world clinical decision-making differs significantly from the standardized, exam-style scenarios commonly used in current efforts. It therefore remains a challenge to apply LLMs to complex medical tasks that require a deep understanding of medical knowledge. A common approach is to fine-tune LLMs for target tasks, which, however, not only requires substantial data and computational resources but is also still prone to generating 'hallucinations'. In this paper, we present the RiskAgent system to perform a broad range of medical risk predictions, covering over 387 risk scenarios across diverse complex diseases, e.g., cardiovascular disease and cancer. RiskAgent is designed to collaborate with hundreds of clinical decision tools, i.e., risk calculators and scoring systems that are supported by evidence-based medicine. To evaluate our method, we have built the first benchmark MedRisk specialized for risk prediction, including 12,352 questions spanning 154 diseases, 86 symptoms, 50 specialties, and 24 organ systems. The results show that our RiskAgent, with 8 billion model parameters, achieves 76.33% accuracy, outperforming the most recent commercial LLMs, 01, 03-mini, and GPT-4.5, and doubling the 38.39% accuracy of GPT-40. On rare diseases, e.g., Idiopathic Pulmonary Fibrosis (IPF), RiskAgent outperforms o1 and GPT-4.5 by 27.27% and 45.46% accuracy, respectively. Finally, we further conduct a generalization evaluation on an external evidence-based diagnosis benchmark and show that our RiskAgent achieves the best results. These encouraging results demonstrate the great potential of our solution for diverse diagnosis domains. For example, instead of extensively fine-tuning LLMs for different medical tasks, our method, which collaborates with and utilizes existing evidence-based medical tools, not only achieves trustworthy results but also reduces resource costs, thus making LLMs accessible to resource-limited clinical applications. To improve the adaptability of our model in different scenarios, we have built and open-sourced a family of models ranging from 1 billion to 70 billion parameters. Our code, data, and models are all available at https://github.com/AI-in-Health/RiskAgent.",
  "summary": "This paper introduces RiskAgent, a multi-agent LLM system designed for medical risk prediction. It collaborates with existing clinical decision tools (risk calculators) rather than being trained on massive datasets.  RiskAgent utilizes three agents: a Decider to select appropriate tools, an Executor to run them and format results, and a Reviewer to evaluate the process.  Key points for multi-agent LLM systems include the efficiency gained by delegating tasks to specialized agents, the improved accuracy and transparency from leveraging existing tools, and the potential for reduced privacy concerns by using smaller, open-source LLMs.  The modular, tool-based approach also shows promise for adaptability and generalization across various medical tasks.",
  "takeaways": "This paper introduces RiskAgent, a multi-agent system designed to enhance LLM performance in medical risk prediction by collaborating with existing medical tools.  Here's how a JavaScript developer can apply these insights to LLM-based multi-agent AI projects in web development:\n\n**1. Decoupling Agent Responsibilities (Decider, Executor, Reviewer):**\n\n* **Scenario:** Building a multi-agent system for personalized travel planning.\n* **JavaScript Implementation:**\n    * **Decider (Langchain, LlamaIndex):**  Uses an LLM to analyze user preferences (e.g., budget, travel style) and decides which APIs to call (e.g., flight search, hotel booking, weather).  LlamaIndex and Langchain provide tools for structuring this decision-making process.\n    * **Executor (Axios, Node-fetch):** Makes API calls using libraries like `axios` or `node-fetch`. Processes and structures the API responses into a format understandable by the Decider and Reviewer.\n    * **Reviewer (Langchain, custom logic):**  Evaluates the plan generated by the Decider based on constraints and criteria. This could involve custom JavaScript logic or using another LLM within Langchain to assess coherence and feasibility.  Provides feedback to the Decider if needed.\n\n```javascript\n// Simplified example using Langchain\nconst { LLMChain, PromptTemplate } = require(\"langchain\");\n// ... other imports\n\n// Decider logic (simplified)\nconst deciderChain = new LLMChain({\n  llm, // Your LLM\n  prompt: new PromptTemplate({\n    template: \"Given user preferences: {preferences}, decide which APIs to call.\",\n    inputVariables: [\"preferences\"],\n  }),\n});\n\n// Executor logic (simplified)\nasync function executeApis(apiCalls) {\n  // ... use axios/node-fetch to make API calls\n}\n\n// Reviewer logic (simplified)\nasync function reviewPlan(plan) {\n  // ... custom logic or LLM call to assess the plan\n}\n```\n\n**2. Utilizing Existing Tools/APIs (Environment):**\n\n* **Scenario:** Creating a customer support chatbot that integrates with a knowledge base and CRM.\n* **JavaScript Implementation:**  Instead of fine-tuning a massive LLM to handle everything, utilize existing APIs.\n    * **Knowledge Base API:** Use a library like `axios` to interact with the knowledge base API to retrieve relevant articles based on user queries.\n    * **CRM API:** Interact with the CRM API to retrieve customer-specific information (e.g., order history) to personalize responses.\n    * **Langchain Tools:**  Langchain provides a framework for creating and managing tools that agents can use. These tools can encapsulate interactions with external APIs or databases.\n\n**3. Addressing Hallucinations (Reviewer, Environment):**\n\n* **Scenario:** Building an LLM-powered research assistant that generates summaries of scientific papers.\n* **JavaScript Implementation:**\n    * **Fact Verification Agent:** Integrate an agent that uses a fact-verification API (e.g., Google Fact Check API, or a custom solution) to verify claims made by the main LLM.\n    * **Source Tracking:** Keep meticulous track of sources used by the LLM. This can be implemented using Langchain's callback functionalities. Display sources alongside generated text.\n    * **Reviewer Agent:** Use a separate LLM (or custom logic) to assess the coherence and consistency of generated summaries, flagging potential hallucinations based on inconsistencies or contradictions with source materials.\n\n**4. Building with JavaScript Frameworks:**\n\n* **Langchain.js:** Facilitates building LLM applications by providing modular components for chains, agents, and memory.  Ideal for implementing the Decider, Executor, and Reviewer agents.\n* **LlamaIndex.js:** Simplifies the process of connecting LLMs to external data sources, vital for creating tools and environments.\n* **Web Workers:** Useful for offloading computationally intensive LLM interactions to separate threads to maintain UI responsiveness.\n\n**5. Experimentation Ideas:**\n\n* **E-commerce Agent:** Build a multi-agent system for personalized product recommendations.  One agent could analyze user browsing history, another could interact with product APIs, and a reviewer could ensure recommendations are relevant and diverse.\n* **Content Creation Agent:** Develop a system for generating blog posts or articles. One agent could brainstorm topics, another could research and gather information, and a reviewer could refine the generated content for style and accuracy.\n\n\nBy adopting these strategies, JavaScript developers can leverage the insights of the RiskAgent paper to build more robust, reliable, and efficient multi-agent AI systems for a wide range of web applications. Remember that the key is to think modularly, leverage existing resources, and prioritize the validation of LLM outputs.",
  "pseudocode": "No pseudocode block found. However, several algorithmic components are described in the text, most notably the embedding-based retrieval-ranking algorithm used in Environment 1. Here's a JavaScript representation along with an explanation:\n\n```javascript\nasync function selectTool(patientInfo, question, availableTools) {\n  // 1. Embedding Generation\n  const patientEmbedding = await generateEmbedding(patientInfo + question);\n  const toolEmbeddings = await Promise.all(\n    availableTools.map(tool => generateEmbedding(tool.name + tool.description))\n  );\n\n\n  // 2. Similarity Calculation\n  const similarities = toolEmbeddings.map(toolEmbedding => {\n    return cosineSimilarity(patientEmbedding, toolEmbedding);\n  });\n\n  // 3. Ranking and Selection\n  const rankedTools = availableTools\n    .map((tool, index) => ({ tool, similarity: similarities[index] }))\n    .sort((a, b) => b.similarity - a.similarity);\n\n  const topTools = rankedTools.slice(0, 5); // Select top 5 tools\n\n  // Further processing by the 'Decider' agent (not implemented here)\n  const selectedTool = await deciderAgent(topTools, patientInfo, question);\n\n  return selectedTool;\n}\n\n\nasync function generateEmbedding(text) {\n  // Replace with actual embedding generation logic, e.g. using a library or API call\n  // Example using a hypothetical 'embeddingAPI'\n  const response = await fetch('embeddingAPI', {\n    method: 'POST',\n    body: JSON.stringify({ text }),\n  });\n  const data = await response.json();\n  return data.embedding;\n}\n\nfunction cosineSimilarity(a, b) {\n  const dotProduct = a.reduce((sum, val, index) => sum + val * b[index], 0);\n  const magnitudeA = Math.sqrt(a.reduce((sum, val) => sum + val * val, 0));\n  const magnitudeB = Math.sqrt(b.reduce((sum, val) => sum + val * val, 0));\n  return dotProduct / (magnitudeA * magnitudeB);\n}\n\n\nasync function deciderAgent(topTools, patientInfo, question) {\n    // Placeholder for Decider Agent logic.  This would involve further analysis \n    // and selection from the topTools based on other criteria.\n    // In a real implementation, this might involve another LLM call.\n    //  This is a simplified example returning the tool with highest similarity.\n    return topTools[0].tool;\n}\n\n\n\n// Example Usage (replace with actual data):\nconst patientInfo = \"Age: 65, Gender: Male, History of Heart Disease\";\nconst question = \"What is the risk of stroke?\";\nconst availableTools = [\n    {name: \"Framingham Risk Score\", description:\"Predicts 10-year cardiovascular risk\"},\n    {name: \"CHADS2 Score\", description:\"Stroke risk in atrial fibrillation\"},\n    {name: \"ASCVD Risk Estimator\", description: \"Estimates risk of atherosclerotic cardiovascular disease\"}\n    // ... other tools\n];\n\nselectTool(patientInfo, question, availableTools)\n  .then(selectedTool => console.log(\"Selected Tool:\", selectedTool))\n  .catch(error => console.error(\"Error:\", error));\n\n\n```\n\n\n**Explanation:**\n\n1. **Embedding Generation:** This function takes text (patient information, question, and tool metadata) as input and generates embeddings. The paper mentions using `text-embedding-ada-002`.  In a real-world application, you'd use a service like OpenAI's embeddings API, or a local embedding model library.\n\n\n2. **Similarity Calculation:**  The `cosineSimilarity` function calculates the cosine similarity between the patient's embedding and each tool's embedding.\n\n\n3. **Ranking and Selection:** The code sorts the tools based on similarity scores and selects the top `N` (in this case, 5) most similar tools.  These are then passed to a simulated `deciderAgent` function.\n\n\n\n4. **Decider Agent (Placeholder):**  The `deciderAgent` function is a placeholder representing the next stage of processing. In the RiskAgent architecture, the \"Decider\" LLM agent would take these top tools and make the final selection based on further analysis. This placeholder simply returns the tool with the highest similarity.\n\n\n**Purpose:** The purpose of the embedding-based retrieval-ranking algorithm is to efficiently narrow down the large set of available medical tools to a smaller subset of the most relevant tools for a given patient's case and question.  This simplifies the subsequent task of the Decider agent in making the final tool selection.",
  "simpleQuestion": "Can LLMs reliably predict medical risks?",
  "timestamp": "2025-03-07T06:02:40.470Z"
}