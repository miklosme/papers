{
  "arxivId": "2501.13333",
  "title": "AgentRec: Agent Recommendation Using Sentence Embeddings Aligned to Human Feedback",
  "abstract": "Multi-agent systems must decide which agent is the most appropriate for a given task. We propose a novel architecture for recommending which LLM agent out of many should perform a task given a natural language prompt by extending the Sentence-BERT (SBERT) encoder model. On test data, we are able to achieve a top-1 accuracy of 92.2% with each classification taking less than 300 milliseconds. In contrast to traditional classification methods, our architecture is computationally cheap, adaptive to new classes, interpretable, and controllable with arbitrary metrics through reinforcement learning. By encoding natural language prompts into sentence embeddings, our model captures the semantic content relevant to recommending an agent. The distance between sentence embeddings that belong to the same agent is then minimized through fine-tuning and aligned to human values through reinforcement learning from human feedback. This allows the classification of natural language prompts based on their nearest neighbors by measuring the cosine similarity between embeddings. This work is made possible through the generation of a synthetic dataset for agent recommendation, which we have open-sourced to the public along with the code for AgentRec recommendation system at https://github.com/joshprk/agentrec.",
  "summary": "This paper introduces AgentRec, a system for efficiently selecting the most appropriate Large Language Model (LLM) agent for a given task based on a natural language prompt. It uses sentence embeddings and a scoring mechanism based on cosine similarity and generalized p-means to recommend agents, achieving 92.2% accuracy on a synthetic dataset.  \n\nKey points for LLM-based multi-agent systems:\n\n* **Agent Selection:**  Addresses the challenge of dynamically choosing the right agent from a pool of specialized LLMs for a given user request.\n* **Sentence Embeddings:** Leverages sentence embeddings to capture the semantic meaning of prompts and match them to the expertise of different agents.\n* **Reinforcement Learning from Human Feedback (RLHF):**  Uses RLHF to align the agent recommendation system with human expectations and values.\n* **Performance:**  Demonstrates fast agent selection (under 300ms) suitable for real-time applications.\n* **Synthetic Data Generation:** Introduces a method for generating synthetic data to train the system, addressing the scarcity of real-world multi-agent datasets.\n* **Open Source:** Code and data are publicly available for experimentation and further development.",
  "takeaways": "This paper presents AgentRec, a system for dynamically selecting the most appropriate LLM agent for a given task based on a natural language prompt.  Let's translate these insights into practical JavaScript examples for web developers building LLM-powered multi-agent applications:\n\n**1. Building an Agent Recommendation System:**\n\nImagine a website with multiple specialized LLM agents: a coding assistant, a customer support bot, and a creative writing partner.  AgentRec's principles can be used to route user queries to the correct agent.\n\n```javascript\n// Simplified example using a fictional sentence embedding library\nimport { SentenceTransformer } from 'fictional-sentence-transformer';\n\nconst model = new SentenceTransformer('all-mpnet-base-v2'); // Or a finetuned model\n\nconst agentCorpora = {\n  codingAgent: await model.encode(['write python code', 'debug javascript', ...]), // Pre-computed embeddings\n  supportAgent: await model.encode(['I need help with my order', 'What are your refund policies', ...]),\n  writingAgent: await model.encode(['write a poem', 'create a short story', ...]),\n};\n\nasync function recommendAgent(userPrompt) {\n  const promptEmbedding = await model.encode(userPrompt);\n\n  const agentScores = {};\n  for (const agent in agentCorpora) {\n    // Calculate generalized p-means (simplified for illustration)\n    let sumSimilarity = 0;\n    for (const corpusEmbedding of agentCorpora[agent]) {\n        sumSimilarity += cosineSimilarity(promptEmbedding, corpusEmbedding); // Assuming you have a cosineSimilarity function\n    }\n    agentScores[agent] = Math.log(sumSimilarity / agentCorpora[agent].length)\n  }\n\n  // Find agent with highest score\n  return Object.entries(agentScores).sort(([,a],[,b]) => b-a)[0][0]\n\n\n}\n\n\n// Example usage\nconst recommendedAgent = await recommendAgent(\"Write a function to sort an array in JavaScript.\");\nconsole.log(\"Recommended Agent:\", recommendedAgent); // Expected: codingAgent\n```\n\n* **Sentence Embeddings:**  Use a JavaScript-compatible sentence embedding library like `@sentence-transformers/all-mpnet-base-v2` (using the `node-fetch` polyfill and a bundler that supports web workers).\n* **Agent Corpora:** Pre-compute sentence embeddings for a representative set of prompts each agent can handle. Store these embeddings in a data structure like the `agentCorpora` object.\n* **Cosine Similarity:**  Calculate the cosine similarity between the user prompt embedding and each embedding in the agent corpora.  You can implement this yourself or use a library.\n* **Generalized p-means:** Implement the scoring function (though a simpler average might work for initial experimentation).\n* **Recommendation:** Select the agent with the highest score.\n\n**2. Integrating with Web Frameworks:**\n\nYou can integrate this agent recommendation logic into popular JavaScript frameworks:\n\n* **React:** Create a custom hook for agent recommendation and use it within your components.\n* **Node.js/Express:** Implement the logic as a middleware or within a service layer.\n* **Serverless Functions:** Deploy the agent recommendation function as a serverless function for scalability and cost-effectiveness.\n\n**3. Addressing Limitations:**\n\n* **Single Sentence Limitation:** The paper primarily uses single-sentence prompts.  For longer queries, consider techniques like splitting into sentences or summarizing before passing to the recommendation system.  Alternatively, use embedding models trained specifically for longer text.\n* **RLHF:** Implementing RLHF in JavaScript is complex. Start with simpler approaches and consider cloud-based RLHF services if needed.\n* **Real-World Data:**  The paper uses synthetic data. Gather real-world user queries to improve the accuracy and relevance of your agent recommendations.\n\n\n**4.  Experimentation:**\n\n* **Dataset Generation:**  Experiment with different methods for generating synthetic data using LLMs within JavaScript environments. Libraries like `langchain` offer tools for managing LLM interactions.\n* **Model Finetuning:** Explore fine-tuning sentence embedding models with JavaScript using TensorFlow.js or similar libraries.\n* **Visualization:** Use JavaScript libraries like Chart.js or D3.js to visualize embeddings and clusters for better understanding and debugging.\n\n**Key Takeaways for JavaScript Developers:**\n\n* **Dynamic Agent Selection:**  Move beyond static agent assignments to a more flexible and intelligent approach using sentence embeddings.\n* **Improved User Experience:** Route user requests to the most appropriate agent, leading to more accurate and relevant responses.\n* **Scalability:** Use pre-computed embeddings and efficient scoring functions for a performant agent recommendation system.\n* **Experimentation:** Leverage JavaScript libraries and frameworks to experiment with multi-agent AI concepts and advance web development practices.\n\nBy combining the insights from this paper with JavaScript tools and techniques, you can build next-generation web applications with powerful multi-agent AI capabilities. Remember to start simple, iterate, and focus on real-world user needs.",
  "pseudocode": "The paper doesn't contain explicit pseudocode blocks. However, several key formulas and algorithmic steps are described in mathematical notation and plain text, which can be translated into JavaScript.  Let's convert those:\n\n**1. Top-k Sampling:**\n\n```javascript\nfunction topKSampling(probabilities, k) {\n  // probabilities: array of probabilities for each token\n  // k: number of top tokens to consider\n\n  const sortedIndices = probabilities\n    .map((prob, index) => ({ prob, index }))\n    .sort((a, b) => b.prob - a.prob)\n    .slice(0, k)\n    .map((item) => item.index);\n\n  let newProbabilities = new Array(probabilities.length).fill(0);\n  let sum = 0;\n\n  for (const index of sortedIndices) {\n    sum += probabilities[index];\n  }\n\n\n  for (const index of sortedIndices) {\n      newProbabilities[index] = probabilities[index] / sum;\n  }\n\n  return newProbabilities;\n}\n```\n\n*Explanation:* This function implements top-k sampling for generating text. It takes an array of token probabilities and a value 'k'. It selects the indices of the top 'k' probabilities, sets the probability of all other tokens to zero, and rescales the top 'k' probabilities to sum to 1. This encourages the model to sample from more likely tokens while still allowing for some diversity.\n\n**2. Nucleus Sampling (Top-p):**\n\n```javascript\nfunction nucleusSampling(probabilities, p) {\n  // probabilities: array of probabilities for each token\n  // p: nucleus probability\n\n  const sortedProbs = probabilities\n    .map((prob, index) => ({ prob, index }))\n    .sort((a, b) => b.prob - a.prob);\n\n  let newProbabilities = new Array(probabilities.length).fill(0);\n  let cumulativeProb = 0;\n\n  for (const item of sortedProbs) {\n    if (cumulativeProb < p) {\n      newProbabilities[item.index] = item.prob;\n      cumulativeProb += item.prob;\n    } else {\n      break; // Stop once cumulative probability exceeds p\n    }\n  }\n\n  // Renormalize probabilities to sum to 1 within the nucleus.\n\n   let nucleusSum = newProbabilities.reduce((acc, prob) => acc + prob, 0);\n\n   if(nucleusSum > 0){  // Avoid division by zero if the nucleus is empty\n    for(let i = 0; i < newProbabilities.length; i++){\n      if(newProbabilities[i] > 0){\n          newProbabilities[i] = newProbabilities[i]/nucleusSum;\n      }\n    }\n\n   }\n\n  return newProbabilities;\n}\n\n```\n\n*Explanation:* This function filters and renormalizes token probabilities based on the cumulative probability 'p'.  It sorts the probabilities, adds them cumulatively, and keeps only the tokens whose cumulative probability remains below 'p'.  It then renormalizes the selected probabilities to sum to 1. This method constrains the sampling to the most likely tokens while ensuring diversity within a defined probability mass.\n\n**3. Cosine Similarity:**\n\n```javascript\nfunction cosineSimilarity(vectorA, vectorB) {\n  // vectorA, vectorB: arrays representing embedding vectors\n\n  let dotProduct = 0;\n  let magnitudeA = 0;\n  let magnitudeB = 0;\n\n  for (let i = 0; i < vectorA.length; i++) {\n    dotProduct += vectorA[i] * vectorB[i];\n    magnitudeA += vectorA[i] * vectorA[i];\n    magnitudeB += vectorB[i] * vectorB[i];\n  }\n\n  magnitudeA = Math.sqrt(magnitudeA);\n  magnitudeB = Math.sqrt(magnitudeB);\n\n  if (magnitudeA === 0 || magnitudeB === 0) return 0; // Handle zero-magnitude vectors\n\n  return dotProduct / (magnitudeA * magnitudeB);\n}\n```\n\n*Explanation:* This function calculates the cosine similarity between two vectors, a measure used to compare the similarity of text embeddings.\n\n**4. Generalized p-means Scoring:**\n\n```javascript\nfunction generalizedPMeans(cosSimilarities, p) {\n  // cosSimilarities: array of cosine similarity scores\n  // p: value for generalized p-means\n\n  let sum = 0;\n  for (const sim of cosSimilarities) {\n    sum += Math.pow(sim, p); // Using exponentiation for p-means\n  }\n\n\n  return Math.pow(sum/ cosSimilarities.length, 1/p); //Return raw value before logarithm\n}\n\n\nfunction scoreAgent(userPromptEmbedding, agentCorpus, p){\n let cosSims = [];\n\n agentCorpus.forEach(agentEmbedding => {\n   cosSims.push(cosineSimilarity(userPromptEmbedding, agentEmbedding));\n });\n\n return Math.log(generalizedPMeans(cosSims, p)); // Apply logarithm for final score\n}\n\n\n```\n\n*Explanation:* This function calculates the generalized p-means score of an agent's similarity to the user prompt based on the provided cosine similarities. Higher `p` values emphasize larger cosine similarity scores, and lower values give more weight to smaller scores. The logarithm helps to stabilize the values and accentuate differences.\n\n\nThese JavaScript implementations provide a practical basis for JavaScript developers to start experimenting with the multi-agent recommendation concepts presented in the paper.  Remember that this is a simplified translation. Real-world implementations may require additional considerations like error handling, asynchronous operations, and integration with specific LLM and embedding APIs.",
  "simpleQuestion": "How can I pick the best LLM agent for a task?",
  "timestamp": "2025-01-24T06:03:01.701Z"
}