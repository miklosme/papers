{
  "arxivId": "2504.06135",
  "title": "Decentralizing AI Memory: SHIMI, a Semantic Hierarchical Memory Index for Scalable Agent Reasoning",
  "abstract": "Abstract. Retrieval-Augmented Generation (RAG) and vector-based search have become foundational tools for memory in AI systems, yet they struggle with abstraction, scalability, and semantic precision-especially in decentralized environments. We present SHIMI (Semantic Hierarchical Memory Index), a unified architecture that models knowledge as a dynamically structured hierarchy of concepts, enabling agents to retrieve information based on meaning rather than surface similarity. SHIMI organizes memory into layered semantic nodes and supports top-down traversal from abstract intent to specific entities, offering more precise and explainable retrieval. Critically, SHIMI is natively designed for decentralized ecosystems, where agents maintain local memory trees and synchronize them asynchronously across networks. We introduce a lightweight sync protocol that leverages Merkle-DAG summaries, Bloom filters, and CRDT-style conflict resolution to enable partial synchronization with minimal overhead. Through benchmark experiments and use cases involving decentralized agent collaboration, we demonstrate SHIMI's advantages in retrieval accuracy, semantic fidelity, and scalability-positioning it as a core infrastructure layer for decentralized cognitive systems.",
  "summary": "SHIMI (Semantic Hierarchical Memory Index) is a new way to organize and share memory in decentralized AI systems. It uses a tree-like structure of concepts instead of flat embeddings, making retrieval more accurate and easier to understand.\n\nFor LLM-based multi-agent systems, SHIMI offers several benefits:\n\n* **Meaning-based retrieval:** Uses semantic similarity instead of just keyword matching, crucial for LLMs to understand context.\n* **Decentralized synchronization:** Agents can share memory efficiently without a central server, ideal for multi-agent collaboration.\n* **Explainability:** The hierarchical structure makes it easier to trace how information is retrieved, important for understanding LLM decisions.\n* **Scalability:** Handles large memory graphs efficiently, essential for complex multi-agent systems.\n* **Abstraction:** Organizes knowledge by abstraction levels, aiding LLM reasoning and generalization.",
  "takeaways": "This paper introduces SHIMI, a decentralized, semantically-rich hierarchical memory system for multi-agent AI, offering significant advantages over traditional vector-based approaches. Here's how a JavaScript developer can apply these insights to LLM-based multi-agent projects in web development:\n\n**1. Building a Decentralized Knowledge Base for a Multi-Agent Application:**\n\n* **Scenario:** Imagine building a collaborative web application where multiple LLM-powered agents contribute to a shared knowledge base (e.g., a decentralized Wikipedia).\n* **SHIMI Application:** Instead of a central database, use SHIMI's principles to create a distributed knowledge tree. Each agent maintains a local branch of the tree, synchronizing updates using a library like `Yjs` or `Automerge` for CRDT-like functionality. This improves resilience, reduces server load, and respects user privacy.\n* **Implementation (Conceptual):**\n\n```javascript\n// Agent's local SHIMI tree (using a simplified tree structure)\nconst shimiTree = new Tree();\n\n// Function to add a new knowledge entry (entity)\nasync function addKnowledge(concept, explanation) {\n  const semanticSummary = await generateSummary(explanation); // Use LLM for summarization\n  shimiTree.insert(concept, semanticSummary, explanation);\n  syncWithPeers(shimiTree); // Synchronization logic using Yjs/Automerge\n}\n\n// Function to retrieve knowledge based on a query\nasync function getKnowledge(query) {\n  const semanticMatches = await shimiTree.search(query); // Semantic search logic\n  return semanticMatches.map(node => node.explanation);\n}\n\n// Example usage:\naddKnowledge(\"JavaScript Frameworks\", \"React, Angular, Vue.js are popular JavaScript frameworks.\");\nconst results = await getKnowledge(\"Frontend Frameworks\");\nconsole.log(results); // Expected output: [\"React, Angular, Vue.js are popular JavaScript frameworks.\"]\n\n// Synchronization logic (using Yjs as an example):\nconst ydoc = new Y.Doc();\nconst ytree = ydoc.get('shimiTree', Y.Map);\n\nfunction syncWithPeers(shimiTree) {\n  // Convert shimiTree to a format compatible with Yjs and update ytree\n  // ...\n  ydoc.on('update', update => {\n    Y.applyUpdate(ydoc, update); // Apply updates received from peers\n    // Convert ytree back to shimiTree format\n    // ...\n  });\n}\n```\n\n\n**2. Enhancing Agent Communication with Semantic Messaging:**\n\n* **Scenario:**  A group of LLM-powered chatbots on a website collaborates to answer user questions, needing to exchange context effectively.\n* **SHIMI Application:** Use SHIMI's semantic summaries in messages passed between agents.  Instead of raw text, agents exchange structured messages with semantic summaries generated by the LLM. This allows agents to quickly understand the context of each other's messages without parsing large texts, enhancing communication efficiency.\n* **Implementation (Conceptual):**\n\n```javascript\n// Agent sends a message\nfunction sendMessage(messageText) {\n  const semanticSummary = await generateSummary(messageText); // Use LLM for summarization\n  const message = { text: messageText, summary: semanticSummary };\n  // Send the message object to other agents (using WebSockets, for example)\n}\n\n// Agent receives a message\nfunction receiveMessage(message) {\n  // Use the semantic summary for faster context understanding\n  const relevance = await compareSummaries(currentContextSummary, message.summary);\n  if (relevance > threshold) {\n     // Process message\n  }\n}\n```\n\n\n**3. Building Explainable AI Features:**\n\n* **Scenario:**  An LLM-powered agent recommends products on an e-commerce site. Users want to understand the reasoning behind the recommendations.\n* **SHIMI Application:**  Store the reasoning process in SHIMI's hierarchical structure, linking the recommendation to various product features and user preferences. This transparency builds trust and improves user experience.\n* **Implementation (Conceptual):**\n\n```javascript\n// Store recommendation rationale in SHIMI\nfunction storeRationale(product, rationale) {\n  shimiTree.insert(product.id, rationaleSummary, rationaleDetails);\n}\n\n// Retrieve rationale for a given recommendation\nfunction explainRecommendation(product) {\n  const rationale = shimiTree.get(product.id);\n  return rationale; // Display the rationale to the user\n}\n```\n\n\n**Key JavaScript Libraries and Frameworks:**\n\n* **`Yjs` / `Automerge`:** For implementing CRDTs and enabling decentralized data synchronization.\n* **`Langchain.js` / `LlamaIndex`:** For interfacing with LLMs and generating embeddings or summaries.\n* **`Vis.js` / `D3.js`:** For visualizing the SHIMI tree structure, helping developers debug and understand its evolution.\n\n\nBy incorporating SHIMI's principles, JavaScript developers can create more robust, efficient, and explainable LLM-powered multi-agent applications, pushing the boundaries of web development. This allows for exploring new web application architectures and functionalities previously challenging to implement due to limitations in centralized or vector-based memory systems. Remember that these are simplified examples, and implementing a full-fledged SHIMI system requires careful consideration of data structures, synchronization protocols, and efficient LLM integration.  The key takeaway is understanding the core principles of semantic hierarchies and decentralized synchronization and applying them creatively in web development contexts.",
  "pseudocode": "```javascript\n// Algorithm 1: AddEntity\nfunction addEntity(entity) {\n  // entity: { concept: string, explanation: string }\n\n  // 1. Identify candidate root buckets\n  const rootBuckets = matchToBucket(entity);\n\n  // 2. Descend tree\n  const ancestorPath = descendTree(rootBuckets, entity.explanation);\n\n\n  // 3-8. Add node to relevant parents and update entity sets.\n  ancestorPath.forEach(parent => {\n    const newNode = new Node(entity); // Assumes a Node class is defined\n    addNode(newNode, parent); //addNode() updates the tree structure to include newNode as a child of parent.\n\n    if (!parent.entities.includes(entity)) {\n      parent.entities.push(entity);\n    }\n  });\n\n}\n\n\n// Helper functions (placeholders - need implementation based on LLM and similarity metrics):\n\nfunction matchToBucket(entity) {\n  // Uses an LLM or other method to find initial matching nodes in the tree.\n  // Returns an array of root nodes that are semantically related to the entity.\n  // Placeholder implementation:\n  return [rootNode]; //  replace with actual logic\n}\n\n\n\nfunction descendTree(nodes, explanation) {\n    let currentLevelNodes = nodes;\n    const ancestorPath = [];\n\n\n  while(currentLevelNodes.length>0) {\n      const nextLevelNodes = [];\n\n      currentLevelNodes.forEach(node => {\n           ancestorPath.push(node);\n\n           let mostSimilarChild = null;\n           let maxSimilarity = -1;\n\n          node.children.forEach(child => {\n              const similarity = getRelation(node.summary, child.summary) // Assumes LLM-based similarity function\n\n              if(similarity > maxSimilarity && similarity > 0.8){\n                  mostSimilarChild = child;\n                  maxSimilarity = similarity;\n              }\n\n\n          });\n\n          if (mostSimilarChild) {\n              nextLevelNodes.push(mostSimilarChild);\n          }\n\n      });\n\n\n      currentLevelNodes = nextLevelNodes;\n\n\n  }\n  return ancestorPath;\n\n}\n\n\n\nfunction getRelation(summaryA, summaryB) {\n // Placeholder - needs LLM implementation\n // Returns a similarity score between -1 and 1\n // 1: ancestor, 0: equivalent, -1: unrelated\n return Math.random() *2 -1 // Replace with an actual LLM or similarity comparison\n}\n\n\nfunction addNode(newNode, parent){\n  // Add to tree logic\n    if(!parent.children) {\n        parent.children = [];\n    }\n\n    parent.children.push(newNode);\n\n    if (parent.children.length > treeBranchingFactor) {\n      mergeChildren(parent); // Implementation not provided in the paper\n    }\n\n\n}\n\n\n\nfunction mergeConcepts(summary1, summary2, parentSummary){\n     // Logic not fully specified. Merges two node concepts.\n     // Returns merged concept or null if merging fails.\n     // Placeholder implementation\n\n     return \"mergedConcept\"; // Placeholder. Actual implementation would leverage LLM.\n\n\n}\n\n\n\n\n\n\n// Algorithm 2: RetrieveEntities\nfunction retrieveEntities(query, similarityThreshold) {\n  let result = [];\n  let frontier = [rootNode]; // Start at root\n\n  while (frontier.length > 0) {\n    const nextLevel = [];\n\n    frontier.forEach(node => {\n      if (sim(query, node.summary) >= similarityThreshold) {\n        if (!node.children || node.children.length === 0) {  //is leaf node\n          result = result.concat(node.entities);\n        } else {\n          nextLevel = nextLevel.concat(node.children);\n        }\n      }\n    });\n    frontier = nextLevel;\n  }\n  return result.sort(rankingFunction) .slice(0,k) // rankingFunction & k not defined.\n}\n\n\n\nfunction sim(a,b){\n\n// Placeholder LLM or similarity function\n    return  Math.random();// Placeholder\n}\n\n\nfunction rankingFunction(a,b){\n    // Ranking logic based on frequency, recency, or proximity to query\n    // Needs to be defined.\n     return 0; //Placeholder\n}\n\n\n\n\n// Algorithm 3: SHIMI_PartialSync. Note this pseudocode was incomplete.\n// It omitted the logic for recursively identifying the divergent subtree.\n// JavaScript implementation will be similarly incomplete without providing this missing logic.\nasync function SHIMI_PartialSync(localTree, remotePeer) {\n\n    const localHash = merkleHash(localTree);\n\n    const [remoteHash] = await Promise.all([remotePeer.getHash()]);\n\n\n  if (localHash !== remoteHash) {\n        //  Find Divergent Subtree (Logic NOT provided in paper)\n        const divergentSubtree = findDiff(localTree, remotePeer);  // Implementation of findDiff needs to be determined based on specific data structure being used and the hashing method.\n\n\n\n       const bloomFilter = bloomFilter(divergentSubtree);\n\n        const addedOrChangedNodes = await remotePeer.getMissingNodes(bloomFilter);\n\n        addedOrChangedNodes.forEach(remoteNode => {\n\n             const localNode = findNode(localTree,remoteNode.id);\n\n             if(localNode) {\n               const mergedNode = merge(localNode, remoteNode);\n               replaceNode(localTree, localNode, mergedNode);\n             } else {\n               addNodeToTree(localTree,remoteNode);\n\n             }\n\n        });\n\n\n\n  }\n\n\n\n  return localTree;\n}\n\n\n\n// Placeholder functions - Need implementation according to paper's description\n\nfunction merkleHash(tree){\n\n   return \"hash\"; // Placeholder\n}\n\nfunction findDiff(tree1,tree2){\n    // This function needs to be defined according to how the Merkle tree is structured\n    // And how you want to recursively compute the difference.\n    return {}; // Placeholder\n}\n\n\n\n\nfunction bloomFilter(subtree){\n    // Needs bloom filter implementation\n\n\n     return \"bloom\"; // placeholder\n}\n\nfunction merge(node1, node2) {\n // CRDT-style merge logic as defined in section 3.2\n // Placeholder:\n\n const mergedNode = {...node1, ...node2};  // Simple example. Actual implementation would depend on the CRDT definition.\n return mergedNode;\n}\n```\n\n**Algorithm 1: `addEntity`**\n\n* **Purpose:** Inserts a new entity (concept and explanation) into the SHIMI tree.  It leverages semantic similarity to find the appropriate location within the tree's hierarchy, creating new abstraction nodes if needed.  It enforces a branching factor and triggers merging when that factor is exceeded.\n\n* **Explanation:**  The core idea is to traverse the tree, guided by semantic similarity between the entity and the existing nodes' summaries. If no similar nodes are found at a given level, a new abstraction node is created.  If too many sibling nodes exist, a merging operation is triggered to maintain the tree's structure.\n\n**Algorithm 2: `retrieveEntities`**\n\n* **Purpose:** Retrieves entities from the SHIMI tree relevant to a given query and similarity threshold.\n\n* **Explanation:** This algorithm explores the tree from the root downwards.  At each level, it checks the semantic similarity between the query and each node's summary.  If the similarity is above the threshold, the algorithm either adds the entities at that node (if it's a leaf) to the result set or continues to the next level of the tree. This targeted traversal allows for efficient pruning of irrelevant branches.\n\n**Algorithm 3: `SHIMI_PartialSync`**\n\n* **Purpose:** Synchronizes SHIMI trees between distributed peers efficiently. This avoids transmitting the entire tree, reducing bandwidth consumption.\n\n* **Explanation:** The algorithm uses Merkle hashes to detect if trees have diverged.  If a difference is found, Bloom filters identify the specific parts of the tree that are different, then those specific subtrees are used with a  CRDT-style merge to ensure eventual consistency across all trees without needing a central authority.  This approach minimizes data transfer, enabling efficient synchronization in distributed environments. This implementation is incomplete as the paper does not detail findDiff().\n\n\n\n**Key Improvements and Considerations**:\n\n* **Semantic Reasoning:**  Instead of relying solely on keyword matching or simple embedding similarity, SHIMI incorporates semantic reasoning through LLM calls, enabling more nuanced and accurate retrieval and placement of information.\n\n* **Decentralization:** SHIMI's synchronization mechanism is designed for decentralized operation, enabling efficient updates and eventual consistency across multiple agents without a central server.\n\n* **LLM Dependency:** SHIMI heavily relies on LLMs for similarity comparisons and abstraction generation. The performance and quality of these LLM calls directly affect SHIMI's effectiveness.\n\n* **Complexity:** Implementing the `mergeConcepts` and sync functions requires careful consideration of data structures, conflict resolution strategies, and the nuances of LLM interactions. These aspects were not fully detailed in the pseudocode and will need to be fleshed out for a complete implementation.",
  "simpleQuestion": "How can I build a scalable, decentralized memory for LLM agents?",
  "timestamp": "2025-04-09T05:05:40.396Z"
}