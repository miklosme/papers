{
  "arxivId": "2412.11430",
  "title": "Efficient Multiagent Planning via Shared Action Suggestions",
  "abstract": "Decentralized partially observable Markov decision processes with communication (Dec-POMDP-Com) provide a framework for multiagent decision making under uncertainty, but the NEXP-complete complexity renders solutions intractable in general. While sharing actions and observations can reduce the complexity to PSPACE-complete, we propose an approach that bridges POMDPs and Dec-POMDPs by communicating only suggested joint actions, eliminating the need to share observations while maintaining performance comparable to fully centralized planning and execution. Our algorithm estimates joint beliefs using shared actions to prune infeasible beliefs. Each agent maintains possible belief sets for other agents, pruning them based on suggested actions to form an estimated joint belief usable with any centralized policy. This approach requires solving a POMDP for each agent, reducing computational complexity while preserving performance. We demonstrate its effectiveness on several Dec-POMDP benchmarks showing performance comparable to centralized methods when shared actions enable effective belief pruning. This action-based communication framework offers a natural avenue for integrating human-agent cooperation, opening new directions for scalable multiagent planning under uncertainty, with applications in both autonomous systems and human-agent teams.",
  "summary": "This paper proposes a novel approach to multi-agent planning under uncertainty where agents communicate suggested actions instead of sharing all observations and beliefs, reducing complexity while maintaining performance comparable to centralized planning.  The algorithm estimates joint beliefs by pruning infeasible beliefs based on received action suggestions, mirroring how humans often collaborate.\n\nThis approach is relevant to LLM-based multi-agent systems as it provides a more efficient communication mechanism compared to full belief sharing.  By inferring beliefs from suggested actions, similar to interpreting natural language instructions, it offers a path toward scalable multi-agent coordination, especially when using pre-trained, computationally expensive LLMs where frequent communication or extensive prompt engineering is undesirable.  The method's alignment with human communication patterns also suggests its potential for human-agent teaming scenarios involving LLMs.",
  "takeaways": "This paper presents a novel approach to multi-agent planning under uncertainty, particularly relevant for JavaScript developers working with LLM-based agents in web applications. The core idea, Multiagent Control via Action Suggestions (MCAS), simplifies coordination by focusing communication on suggested actions rather than complex belief states. This is highly practical for web applications due to bandwidth and latency constraints.\n\nHere are some practical examples illustrating how JavaScript developers can apply MCAS insights to LLM-based multi-agent projects:\n\n**1. Collaborative Document Editing:**\n\nImagine a collaborative document editor where multiple LLM-based agents assist users with writing, grammar, style, and fact-checking.  Instead of each agent sharing its complete analysis of the document (which would be computationally expensive and create network overhead), they could suggest specific actions:\n\n* **Agent 1 (Grammar):** suggests \"Change 'their' to 'there' in line 5.\"\n* **Agent 2 (Style):** suggests \"Rephrase the sentence starting on line 10 for conciseness.\"\n* **Agent 3 (Fact-checking):** suggests \"Add a citation for the statistic mentioned in line 15.\"\n\nA coordinating agent can then consolidate these suggestions, resolving potential conflicts and presenting the user with a unified set of recommendations.  This can be implemented using a JavaScript framework like React or Vue.js, with a central component managing agent communication and a message queue handling asynchronous suggestions. Libraries like Socket.io can facilitate real-time communication between agents.\n\n**2. E-commerce Recommender Systems:**\n\nConsider an e-commerce site where multiple LLM-based agents personalize product recommendations. One agent might focus on past purchases, another on browsing history, and a third on current trends. With MCAS, each agent suggests products or product categories instead of sharing their complete user model.\n\n* **Agent 1 (Purchase History):** suggests \"Recommend items similar to previously purchased shoes.\"\n* **Agent 2 (Browsing History):** suggests \"Show products related to recently viewed winter coats.\"\n* **Agent 3 (Trending Products):** suggests \"Highlight popular items in the user's preferred color.\"\n\nA coordinating agent combines these suggestions, prioritizing and filtering to present a concise list of relevant recommendations. This can be achieved using Node.js on the server-side, with client-side JavaScript handling dynamic updates of the product display using libraries like Preact or Inferno for optimal rendering performance.\n\n**3. Interactive Storytelling:**\n\nIn an interactive storytelling application, multiple LLM-based agents could represent different characters, each with its own motivations and beliefs. Instead of sharing their internal states, these agents suggest actions within the narrative:\n\n* **Agent 1 (Protagonist):** suggests \"Attempt to open the locked door.\"\n* **Agent 2 (Antagonist):** suggests \"Hide in the shadows.\"\n* **Agent 3 (Supporting Character):** suggests \"Offer the protagonist a helpful clue.\"\n\nA coordinating agent or a game engine then resolves these suggestions, determining the outcome and advancing the story. This can be implemented using JavaScript game engines like Phaser or Babylon.js, with agents communicating through a central event system.\n\n**Key Implementation Considerations:**\n\n* **Action Representation:** Define a clear format for representing agent actions in JavaScript objects or JSON. This structure should include the action type, target, and relevant parameters.\n* **Conflict Resolution:** Implement a conflict resolution strategy within the coordinating agent to handle contradictory suggestions. This could involve priority rules, voting mechanisms, or negotiation protocols.\n* **Asynchronous Communication:** Design the system for asynchronous communication using Promises, async/await, or message queues to avoid blocking operations and ensure responsiveness.\n* **Belief Subspace Representation (Advanced):** For more complex scenarios, consider representing belief subspaces as JavaScript arrays of objects, each defining a constraint on the agent's belief.\n\nBy adopting MCAS principles, JavaScript developers can build more efficient and scalable LLM-based multi-agent applications. The focus on action suggestions simplifies communication, reduces overhead, and enables more responsive web experiences. This approach is particularly well-suited for complex web applications where multiple agents interact to achieve a common goal.",
  "pseudocode": "```javascript\n// Algorithm 1: Multiagent Control via Action Suggestions (MCAS)\n\nfunction mcas(n, P, pi, jointP, jointPi, similarityThresholds, Bmax) {\n  // n: Number of agents\n  // P: Array of agents' MPOMDPs (P[i] for agent i+1)\n  // pi: Array of agents' policies (pi[i] for agent i+1)\n  // jointP: Joint MPOMDP\n  // jointPi: Joint policy\n  // similarityThresholds:  { single: number, joint: number} \n  // Bmax: Maximum number of estimated beliefs\n\n  let b1 = initializeBelief(); // Initialize belief for agent 1\n  let B = [];\n  let w = [];\n  for (let j = 2; j <= n; j++) {\n    B[j] = [b1]; // Initialize surrogate belief sets for other agents\n    w[j] = [1.0]; // Initialize weights for each belief\n  }\n\n\n  while (!isDone()) { // Main loop\n    let sigma = receiveMessages(n);  // Receive messages from other agents\n\n    for (let j = 2; j <= n; j++) {\n      B[j] = pruneBeliefs(pi[j-1], B[j], sigma[j-1]);\n      reduceToMaxLimit(B[j], w[j], Bmax, similarityThresholds.single);\n    }\n\n    let bJoint = selectJointBelief(B, w, b1, similarityThresholds.joint);\n    let a = jointPi(bJoint); // Joint action based on estimated joint belief\n\n    broadcast(a, n);  // Send selected joint action to all agents\n\n    let o1 = execute(a[0]);  // Agent 1 executes its part of the joint action\n    b1 = update(P[0], b1, a, o1); // Agent 1 updates its belief\n\n    for (let j = 2; j <= n; j++) {\n      [B[j], w[j]] = updateEstimatedBeliefs(j, P[j-1], B[j], w[j], a, similarityThresholds.single);\n    }\n  }\n}\n\n\n\nfunction pruneBeliefs(policy, beliefs, message) {\n  return beliefs.filter(b => policy(b) === message);\n}\n\n\nfunction reduceToMaxLimit(beliefs, weights, limit, threshold) {\n  while(beliefs.length > limit){\n\n    let minDist = Infinity;\n    let minPair = [-1,-1]\n\n    for (let i = 0; i < beliefs.length; i++){\n        for(let j = i + 1; j < beliefs.length; j++){\n            let dist = l1Norm(beliefs[i], beliefs[j]);\n\n            if (dist < minDist){\n                minDist = dist;\n                minPair = [i, j];\n            }\n        }\n    }\n\n    if(minPair[0] !== -1){\n        let removeIndex = weights[minPair[0]] < weights[minPair[1]] ? minPair[0] : minPair[1];\n        let keepIndex = weights[minPair[0]] < weights[minPair[1]] ? minPair[1] : minPair[0];\n\n        weights[keepIndex] += weights[removeIndex];\n\n        beliefs.splice(removeIndex, 1);\n        weights.splice(removeIndex, 1);\n\n\n    } else {\n        // No beliefs within similarity threshold, remove lowest-weight belief\n        let minWeightIndex = weights.indexOf(Math.min(...weights));\n        beliefs.splice(minWeightIndex, 1);\n        weights.splice(minWeightIndex, 1);\n    }\n\n  }\n}\n\nfunction selectJointBelief(B, w, b1, threshold) {\n\n  let combinedBeliefs = [];\n  let combinedWeights = [];\n\n  let cartesianProduct = B.slice(2).reduce((a, b) => a.flatMap(d => b.map(e => [d, e].flat())), [[]]);\n\n\n  for(const product of cartesianProduct) {\n    let bCombined = combineBeliefs(b1, ...product);\n    let wCombined = product.reduce((acc, b, index) => acc * w[index+2][B[index + 2].indexOf(b)], 1);\n\n    let similarBeliefIndex = combinedBeliefs.findIndex(cb => l1Norm(cb, bCombined) <= threshold);\n\n    if (similarBeliefIndex !== -1){\n        combinedWeights[similarBeliefIndex] += wCombined;\n    } else {\n      combinedBeliefs.push(bCombined);\n      combinedWeights.push(wCombined);\n    }\n  }\n\n\n  let normalizedWeights = combinedWeights.map(weight => weight/combinedWeights.reduce((a,b) => a + b));\n\n  let maxWeightIndex = normalizedWeights.indexOf(Math.max(...normalizedWeights));\n  return combinedBeliefs[maxWeightIndex];\n}\n\n\nfunction updateEstimatedBeliefs(j, P, beliefs, weights, a, threshold) {\n\n  let newBeliefs = [];\n  let newWeights = [];\n\n\n  for(let i = 0; i < beliefs.length; i++){\n    let b = beliefs[i];\n    for (let o of observations){\n      let nextB = update(P, b, a, o);\n      let nextW = weights[i] * observationProbability(o, b, a);\n\n      let similarBeliefIndex = newBeliefs.findIndex(nb => l1Norm(nb, nextB) <= threshold);\n\n      if (similarBeliefIndex !== -1){\n        newWeights[similarBeliefIndex] += nextW;\n      } else {\n        newBeliefs.push(nextB);\n        newWeights.push(nextW);\n      }\n    }\n\n  }\n\n  return [newBeliefs, newWeights];\n}\n\n\n\n// Helper functions (placeholders - replace with actual implementations)\nfunction initializeBelief() { /* ... */ }\nfunction isDone() { /* ... */ }\nfunction receiveMessages(n) { /* ... */ }\nfunction broadcast(a, n) { /* ... */ }\nfunction execute(action) { /* ... */ }\nfunction update(P, b, a, o) { /* ... */ }\nfunction combineBeliefs(...beliefs) { /* ... */ }  // Use conflation or other suitable method\nfunction observationProbability(o,b,a) { /* ... */}\nfunction l1Norm(b1, b2){ /* ... */}\n// ... other helper functions as needed (e.g., for updating beliefs, L1 distance, etc)\n\n\n```\n\n**Explanation:**\n\nThe MCAS algorithm aims to enable effective multi-agent coordination in partially observable environments, mirroring human collaborative decision-making using action suggestions. \n\n**Purpose:**\n\nInstead of sharing full observations or beliefs, agents communicate suggested actions. This information allows agents to infer each other's beliefs and construct an estimated joint belief, which can then be used with a policy assuming centralized execution.\n\n**Algorithm Breakdown:**\n\n1. **Initialization:** Each agent maintains a belief about the environment and a set of estimated beliefs for each other agent.\n\n2. **Message Exchange:** Agents share their individually optimal actions (suggestions).\n\n3. **Belief Pruning:** Based on the received action suggestions, prune unreachable beliefs from each agent's set of estimated beliefs for other agents. \n\n4. **Joint Belief Estimation:** Combine estimated beliefs with the agent's own belief to form an estimated joint belief. There are multiple methods to combine beliefs. One option is conflation, shown as `combineBeliefs` which takes any number of beliefs as arguments.\n\n5. **Action Selection:** Select a joint action using a centralized policy based on the estimated joint belief.\n\n6. **Execution and Observation:** All agents execute their part of the joint action and update their individual beliefs based on the resulting local observations.\n\n7. **Estimated Belief Update:** Each agent updates its set of estimated beliefs for all other agents, considering all possible actions and observations by the other agents and incorporating the received action messages.\n\n8. **Loop:**  Repeat steps 2-7 until a termination condition is met.\n\n\n**Key Improvements over other Multi-Agent Planning Algorithms:**\n\n* **Reduced Communication:** Only action suggestions are exchanged, not full beliefs or observations, reducing communication overhead.\n* **Efficient Computation:** The algorithm reduces the computational complexity compared to solving Dec-POMDPs directly.\n* **Natural for Human-Agent Teaming:**  Action suggestions align with how humans collaborate, making this approach applicable to human-agent teams.",
  "simpleQuestion": "How can shared action suggestions improve multi-agent planning efficiency?",
  "timestamp": "2024-12-17T06:04:32.355Z"
}