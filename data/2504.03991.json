{
  "arxivId": "2504.03991",
  "title": "Algorithmic Prompt Generation for Diverse Human-like Teaming and Communication with Large Language Models",
  "abstract": "Understanding how humans collaborate and communicate in teams is essential for improving human-agent teaming and AI-assisted decision-making. However, relying solely on data from large-scale user studies is impractical due to logistical, ethical, and practical constraints, necessitating synthetic models of multiple diverse human behaviors. Recently, agents powered by Large Language Models (LLMs) have been shown to emulate human-like behavior in social settings. But, obtaining a large set of diverse behaviors requires manual effort in the form of designing prompts. On the other hand, Quality Diversity (QD) optimization has been shown to be capable of generating diverse Reinforcement Learning (RL) agent behavior. In this work, we combine QD optimization with LLM-powered agents to iteratively search for prompts that generate diverse team behavior in a long-horizon, multi-step collaborative environment. We first show, through a human-subjects experiment (n = 54 participants), that humans exhibit diverse coordination and communication behavior in this domain. We then show that our approach can effectively replicate trends from human teaming data and also capture behaviors that are not easily observed without collecting large amounts of data. Our findings highlight the combination of QD and LLM-powered agents as an effective tool for studying teaming and communication strategies in multi-agent collaboration.",
  "summary": "This paper explores generating diverse and effective teaming behaviors in multi-agent systems, particularly those powered by Large Language Models (LLMs), without relying on extensive human data collection.  It introduces PLAN-QD, a framework that combines LLM-driven agents with Quality Diversity (QD) optimization. QD guides prompt generation and mutation, leading to LLMs exhibiting diverse communication and collaboration strategies. The research validates the approach through a human study and simulated \"Steakhouse\" environment, showing that PLAN-QD generates broader behavioral diversity than baseline methods and replicates communication-influenced trends observed in human teams. Key to LLM-based multi-agent systems is the algorithmic prompt generation method that automates the process of personality prompt design, allowing diverse agent behaviors to emerge without manual intervention.  The research demonstrates the potential of combining LLMs with QD for exploring complex multi-agent interactions.",
  "takeaways": "This paper presents exciting opportunities for JavaScript developers working with LLMs in multi-agent web applications. Here's how you can apply its insights:\n\n**1. Diverse Agent Behaviors in Interactive Narratives:**\n\n* **Scenario:** Imagine building a collaborative, interactive storytelling web app. Users and LLM-powered agents co-create a story, with agents playing diverse characters.\n* **Application:** Use PLAN-QD principles to generate diverse character prompts for the LLMs. Your measure functions could be narrative elements like character assertiveness, cooperation level, or plot contribution.  A higher assertiveness measure would prompt the LLM to generate text where the character takes initiative, drives the plot forward, and expresses strong opinions. A higher cooperation measure would prompt the LLM to generate text where the character actively collaborates with others, works towards common goals, and builds alliances. A higher plot contribution measure could prompt the LLM to generate text that significantly advances the storyline, introduces conflicts or resolutions, or reveals important information.\n* **JavaScript Implementation:**\n    * **Langchain.js:** Use Langchain to manage LLM interactions and incorporate the generated character prompts into your narrative generation pipeline.  This would allow you to integrate a variety of language models easily.\n    * **Frontend Framework (React, Vue, etc.):** Use a frontend framework to manage the user interface and display the evolving narrative. You can create interactive elements to allow users to influence the story and observe the diverse reactions of the LLM-driven characters.\n\n**2. Personalized Assistants in Collaborative Workspaces:**\n\n* **Scenario:** Develop a collaborative project management tool with LLM-powered assistants assigned to individual users.\n* **Application:**  Use QD optimization to create prompts that personalize the assistant's behavior, making them more proactive, reactive, supportive, or analytical based on individual user preferences and project needs. For instance, measure functions for proactivity would result in the LLM generating prompts to anticipate user needs and offer assistance preemptively, such as suggesting task deadlines or proactively scheduling meetings. Measure functions for reactivity would result in prompts that generate quick and relevant responses to user input or changing circumstances, like generating meeting summaries or highlighting critical task updates. Measure functions for support would generate prompts that offer encouragement, provide helpful resources, and facilitate collaboration with other users or agents. Measure functions for analytical style would prompt the LLM to be more analytical, focusing on data analysis, providing insightful reports, and identifying potential issues in user plans.\n* **JavaScript Implementation:**\n    * **Node.js & WebSockets:**  Use Node.js to manage the backend server and WebSockets for real-time communication between users and their personalized assistants.\n    * **Langchain.js:** Use Langchain.js to integrate and manage the interactions between users and their language models.\n\n**3. Dynamic Content Generation for Educational Games:**\n\n* **Scenario:** Create an educational game where LLM-agents provide hints, feedback, or generate adaptive challenges.\n* **Application:** Use PLAN-QD to generate prompts that create diverse pedagogical styles for the LLM-agents. Measure functions could include hint frequency, feedback detail, or challenge complexity. For example, having a feedback detail measure function might prompt the LLM to generate more verbose, positive or constructive feedback based on the user input and game scenario.\n* **JavaScript Implementation:**\n    * **Phaser.js or Babylon.js:** Utilize JavaScript game libraries to create the game environment.\n    * **Langchain.js:** Manage prompt engineering and LLM queries for dynamic content within the game.\n\n\n**Key Considerations for JavaScript Developers:**\n\n* **Prompt Engineering:** Experimenting with different prompt templates and measure functions is crucial for achieving the desired agent behavior.\n* **LLM Selection:** Consider the strengths and weaknesses of different LLM providers for your specific application.\n* **Evaluation Metrics:** Carefully define evaluation metrics to assess the quality and diversity of your multi-agent system.\n* **User Interface Design:** Design the user interface to effectively present the diverse agent behaviors and interactions to the user.\n\nBy adopting the principles of PLAN-QD and leveraging existing JavaScript frameworks and libraries, you can create more engaging, dynamic, and personalized web experiences powered by multi-agent LLM systems.  This research bridges the gap between theory and practice, empowering JavaScript developers to create the next generation of intelligent web apps.",
  "pseudocode": "```javascript\nfunction qdOptimization(initialPrompt, maxIterations, batchSize, numRepeats) {\n  // Initialize an empty archive to store diverse prompt lists.\n  const archive = new Map();\n\n  // Iterate for a specified number of iterations.\n  for (let i = 1; i <= maxIterations; i++) {\n    // Process a batch of prompt lists in each iteration.\n    for (let j = 1; j <= batchSize; j++) {\n      let promptList;\n\n      // If the archive is empty (initial iteration), use the initial prompt.\n      if (archive.size === 0) {\n        promptList = [initialPrompt, initialPrompt]; // Assuming 2 agents\n      } else {\n        // Select a random prompt list from the archive.\n        const randomKey = Array.from(archive.keys())[Math.floor(Math.random() * archive.size)];\n        promptList = archive.get(randomKey);\n      }\n\n\n      // Mutate the selected prompt list to generate a new one.\n      const newPromptList = mutate(promptList);\n\n      // Evaluate the new prompt list multiple times and store the results.\n      const objectiveValues = [];\n      const measureValues = [];\n      for (let k = 1; k <= numRepeats; k++) {\n\n        const [objective, measures] = evaluate(newPromptList); //  Assume 'evaluate' returns objective & measures\n\n        objectiveValues.push(objective);\n        measureValues.push(measures);\n\n      }\n\n      // Calculate the median objective and measure values.\n      const medianObjective = median(objectiveValues);\n      const medianMeasures = median(measureValues);\n\n      // Update the archive with the new prompt list if it improves quality or diversity.\n      const key = medianMeasures.toString(); // Use measure values as key\n\n      if (!archive.has(key) || medianObjective > archive.get(key)[0]) {\n       archive.set(key, [medianObjective,newPromptList]);\n      }\n    }\n  }\n\n  return archive;\n}\n\n\n\nfunction mutate(promptList){\n\n  // Placeholder, replace with your actual mutation logic\n  const newPromptList = promptList.map(prompt => {\n    // Example mutation logic: add a random word\n\n    return prompt + \" \" + randomWord();\n  });\n\n  return newPromptList;\n\n\n}\n\n\nfunction evaluate(promptList){\n\n  // Placeholder. This function will simulate the environment & get the result\n\n  // Example return values:\n  const obj = Math.random()* 100;\n  const measures = [Math.random(),Math.random(),Math.random()]; // sample measures\n  return [obj,measures];\n\n}\n\nfunction median(values) {\n  // Helper function to calculate median. You can use a library for more robust implementations.\n  values.sort((a, b) => a - b);\n  const mid = Math.floor(values.length / 2);\n  return values.length % 2 !== 0 ? values[mid] : (values[mid - 1] + values[mid]) / 2;\n}\n\nfunction randomWord(){\n\n  // Generate random words for mutation\n  const words = [\"better\",\"faster\",\"stronger\",\"collaborate\",\"communicate\",\"efficient\",\"quickly\"];\n  return words[Math.floor(Math.random()* words.length)];\n}\n\n\n// Example Usage (replace placeholders with real data):\nconst initialPrompt = \"You are always focused on the objective.\";\nconst maxIterations = 50;\nconst batchSize = 2;\nconst numRepeats = 4;\n\nconst archive = qdOptimization(initialPrompt, maxIterations, batchSize, numRepeats);\n\nconsole.log(archive);\n\n```\n\n**Explanation and Purpose of the Algorithm**\n\nThis JavaScript code implements the Quality Diversity (QD) optimization algorithm described in the paper, specifically Algorithm 1 titled \"QD optimization to generate prompts for diverse agents\". The core idea is to evolve a set of prompts for LLM-powered agents, aiming to generate diverse and high-performing behaviors within a multi-agent environment.\n\n**Key Functions and Their Roles:**\n\n* **`qdOptimization(initialPrompt, maxIterations, batchSize, numRepeats)`:** This is the main function that drives the QD optimization process. It takes an initial prompt, the number of iterations, batch size, and number of evaluation repeats as input.  It maintains an archive (`archive`) to store the best-performing and diverse prompt lists found so far, using the measure values as keys.\n\n* **`mutate(promptList)`:**  This function is responsible for mutating a given prompt list to generate a new, slightly different one.  In the provided example, I use simple placeholder logic (adding a random word). The actual implementation, as described in the paper, would involve using a separate \"mutator LLM\" to modify the prompts more intelligently based on desired mutation directions in the measure space (e.g., \"increase collaboration,\" \"decrease specialization\").\n\n* **`evaluate(promptList)`:** This is a crucial function that simulates the multi-agent environment using the provided `promptList` to control the LLM-powered agents. It returns the `objective` (fitness) and `measures` obtained during the simulation. The paper describes a \"Steakhouse\" environment as an example. The `evaluate` function would need to encapsulate the logic for running the simulation and calculating the objective and measure values as described in the paper.\n\n* **`median(values)`:**  A helper function to calculate the median of an array of values. This is used to aggregate the results of multiple simulation runs to reduce the impact of stochasticity.\n\n* **`randomWord()`:**  A helper function in the placeholder mutate function that generates random words to append to the prompt during mutation.\n\n**How the Algorithm Works:**\n\n1. **Initialization:** The archive is initialized as empty.\n\n2. **Iteration:** The algorithm iterates for a specified number of iterations.\n\n3. **Batch Processing:**  In each iteration, a batch of prompt lists is processed.\n\n4. **Prompt Selection:** If the archive is empty (in the first iteration), the initial prompt is used. Otherwise, a random prompt list is selected from the archive to serve as a starting point (\"stepping stone\") for mutation.\n\n5. **Mutation:** The selected prompt list is mutated using the `mutate` function to generate a new prompt list.\n\n6. **Evaluation:** The new prompt list is evaluated multiple times in the environment using the `evaluate` function. The median objective and measure values are calculated.\n\n7. **Archive Update:** The archive is updated with the new prompt list if it either maps to an empty cell in the measure space or if it achieves a higher objective value than the existing prompt list in that cell.\n\n8. **Repeat:** Steps 4-7 are repeated until the budget of prompt evaluations is exhausted.\n\n\nThe `qdOptimization` function effectively explores the prompt space to find a diverse set of prompt lists that result in varied and high-performing behaviors in the multi-agent environment. The crucial part that needs to be implemented according to the paper is the `mutate` and `evaluate` functions, along with a meaningful definition of the `measures` and `objective` based on the target multi-agent application.",
  "simpleQuestion": "How can LLMs generate diverse team behaviors?",
  "timestamp": "2025-04-08T05:10:13.551Z"
}