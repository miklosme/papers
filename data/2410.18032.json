{
  "arxivId": "2410.18032",
  "title": "GraphTeam: Facilitating Large Language Model-based Graph Analysis via Multi-Agent Collaboration",
  "abstract": "Graphs are widely used for modeling relational data in real-world scenarios, such as social networks and urban computing. While large language models (LLMs) have achieved strong performance in many areas, existing LLM-based graph analysis approaches either integrate graph neural networks (GNNs) for specific machine learning tasks (e.g., node classification), limiting their transferability, or rely solely on LLMs' internal reasoning ability, resulting in suboptimal performance. To address these limitations, we take advantage of recent advances in LLM-based agents, which have shown capabilities of utilizing external knowledge or tools for problem solving. By simulating human problem-solving strategies such as analogy and collaboration, we propose a multi-agent system based on LLMs named GraphTeam, for graph analysis. GraphTeam consists of five LLM-based agents from three modules, and the agents with different specialities can collaborate with each other to address complex problems. Specifically, (1) input-output normalization module: the question agent extracts and refines four key arguments (e.g., graph type and output format) from the original question, facilitating the problem understanding, and the answer agent organizes the results to meet the output requirement; (2) external knowledge retrieval module: we first build a knowledge base consisting of relevant documentation and experience information, and then the search agent retrieves the most relevant entries from the knowledge base for each question. (3) problem-solving module: given the retrieved information from search agent, the coding agent uses established algorithms via programming to generate solutions, and in case the coding agent does not work, the reasoning agent will directly compute the results without programming. Extensive experiments on six graph analysis benchmarks demonstrate that GraphTeam achieves state-of-the-art performance with an average 25.85% improvement over the best baseline in terms of accuracy. The code and data are available at https://github.com/BUPT-GAMMA/GraphTeam.",
  "summary": "1. **Main Topic:** This paper introduces GraphTeam, a system that leverages multiple cooperating LLM-based agents to solve graph analysis problems more effectively than LLMs alone.\n\n2. **Key Points for LLM-based Multi-Agent Systems:**\n    * **Specialized Agents:** GraphTeam utilizes five agents with specific roles (question understanding, answer formatting, information retrieval, code generation, logical reasoning) to mimic human problem-solving strategies.\n    * **Knowledge Integration:** It incorporates external knowledge bases (API documentation and past solution examples) to augment LLM capabilities.\n    * **Iterative Refinement:**  It employs retry mechanisms in both code generation and answer formatting stages for improved accuracy.\n    * **Modular Design:** GraphTeam's modular structure allows for flexible agent interaction and potential integration of specialized agents for specific graph analysis tasks.",
  "takeaways": "Let's translate the insights of the \"GraphTeam\" paper into practical JavaScript applications for web developers.\n\n**1. Multi-Agent Architecture for Interactive Web Experiences**\n\n* **Scenario:** Imagine building an interactive chatbot that helps users explore a complex dataset visualized as a graph (e.g., product relationships, social connections, knowledge graphs).\n* **JavaScript Implementation:**\n    * **Agents:**\n        * **Question Agent:** Uses a JavaScript LLM library like `transformers.js` to parse user queries (e.g., \"Find products similar to this one,\" \"Show me the shortest path to this category\").\n        * **Graph Query Agent:** Translates natural language queries into graph database queries (using libraries like `neo4j-driver` for Neo4j or `graphql-request` for GraphQL-based graph databases).\n        * **Visualization Agent:**  Updates the web-based graph visualization in response to query results (using libraries like `vis.js`, `Cytoscape.js`, or `D3.js`).\n    * **Communication:** Use a message queue or event bus (like `Redis`, `RabbitMQ`, or browser-based events) to enable agent communication.\n\n**2. Collaborative Code Generation and Debugging**\n\n* **Scenario:** A pair-programming tool where an LLM assists JavaScript developers.\n* **JavaScript Implementation:**\n    * **Agents:**\n        * **Code Understanding Agent:**  Analyzes code structure and context using a JavaScript parser like `Esprima` or `Acorn`.\n        * **Task Suggestion Agent:** Proposes code completions, identifies potential errors, or suggests relevant documentation. \n        * **Code Generation Agent:**  Generates JavaScript code snippets based on user instructions and context.\n    * **Integration:** Integrate with popular code editors (VS Code, Atom) using their extension APIs.\n\n**3. LLM-Powered Web Analytics and User Behavior Prediction**\n\n* **Scenario:** Enhance website analytics with predictive capabilities by analyzing user navigation patterns.\n* **JavaScript Implementation:**\n    * **Data Collection:**  Track user interactions (page visits, clicks) as events, representing them as nodes and edges in a graph (consider libraries like `Google Analytics`, `Segment`, or custom event tracking). \n    * **Graph Analysis Agent:**  Uses an LLM to perform pattern analysis on the user journey graph – identifying common paths, drop-off points, or predicting future actions.\n    * **Recommendation Agent:**  Provides insights and personalized recommendations to improve user engagement and conversion rates.\n\n**Key JavaScript Libraries and Frameworks**\n\n* **LLM Integration:** `transformers.js` (for running LLMs in the browser or Node.js)\n* **Graph Databases:**  `neo4j-driver`, `graphql-request`, `arangodb-driver` \n* **Graph Visualization:** `vis.js`, `Cytoscape.js`, `D3.js`, `React-Force-Graph`\n* **Code Analysis and Generation:** `Esprima`, `Acorn`, `Babel`\n* **Message Queues/Event Buses:** `Redis`, `RabbitMQ`, `socket.io` \n\n**Benefits of the Multi-Agent Approach**\n\n* **Modularity:** Break down complex problems into smaller, manageable tasks.\n* **Specialization:** Each agent can excel at a specific task (natural language understanding, graph analysis, code generation).\n* **Scalability:** Easier to add, remove, or update agents as your application evolves.\n\n**Important Considerations**\n\n* **LLM Latency:** Choose LLMs with lower latency for real-time web applications.\n* **Data Privacy:** Handle user data responsibly, especially when processing it with external LLMs.\n* **Experimentation:** The field is rapidly evolving – be prepared to experiment with different agents, LLMs, and architectures to find what works best.\n\nThis multi-agent approach empowers JavaScript developers to leverage the power of LLMs in creative ways, leading to smarter and more engaging web experiences.",
  "pseudocode": "```javascript\n/**\n * Collects problem-solving experiences by running a solver on training data and evaluating its performance on validation data.\n *\n * @param {Array<Object>} trainingData - An array of training data objects, each containing a question (`q`), an answer (`a`), and a problem type (`t`).\n * @param {Array<Object>} validationData - An array of validation data objects, each containing a question (`q`), an answer (`a`), and a problem type (`t`).\n * @param {number} candidateExperienceSize - The maximum number of experiences to store for each problem type.\n * @returns {Object} An object containing experiences for each problem type, where each experience is an object with a question (`q`), an answer (`a`), and meta-information (`metaInfo`).\n */\nfunction collectProblemSolvingExperiences(trainingData, validationData, candidateExperienceSize) {\n  const experienceKnowledgeBase = {};\n\n  // Iterate over training data to collect initial experiences\n  for (const { q, a, t } of trainingData) {\n    const { answer, metaInfo } = solver(questionAgent(q));\n    if (answer === a) {\n      if (experienceKnowledgeBase[t]?.length < candidateExperienceSize) {\n        experienceKnowledgeBase[t] = [...(experienceKnowledgeBase[t] || []), { q, a, metaInfo }];\n      }\n    }\n  }\n\n  // Evaluate and refine experiences using validation data\n  for (const { q, a, t } of validationData) {\n    for (const experience of experienceKnowledgeBase[t] || []) {\n      const { answer } = solver(questionAgent(q), experience);\n      if (answer === a) {\n        experience.utility = (experience.utility || 0) + 1;\n      }\n    }\n\n    // Keep only the experiences with the highest utility\n    experienceKnowledgeBase[t] = (experienceKnowledgeBase[t] || []).reduce((bestExperience, currentExperience) => {\n      return currentExperience.utility > bestExperience.utility ? currentExperience : bestExperience;\n    }, { utility: 0 });\n  }\n\n  return experienceKnowledgeBase;\n}\n\n/**\n * Represents the question agent, responsible for extracting key information from a graph analysis problem.\n *\n * @param {string} question - The original problem description.\n * @returns {Object} An object containing the refined question (`refinedQuestion`), graph type (`graphType`), input graph (`inputGraph`), and output format (`outputFormat`).\n */\nfunction questionAgent(question) {\n  // Implementation for extracting key information from the question using an LLM (not provided)\n  // ...\n\n  return { refinedQuestion, graphType, inputGraph, outputFormat };\n}\n\n/**\n * Represents the solver, which attempts to solve a graph analysis problem with or without an experience.\n *\n * @param {Object} questionAgentOutput - The output of the question agent.\n * @param {Object} [experience] - An optional experience object.\n * @returns {Object} An object containing the answer (`answer`) and meta-information (`metaInfo`) such as codes and thinking processes.\n */\nfunction solver(questionAgentOutput, experience) {\n  // Implementation for solving the problem using an LLM, potentially augmented with an experience (not provided)\n  // ...\n\n  return { answer, metaInfo };\n}\n```\n\n**Explanation:**\n\n1. **`collectProblemSolvingExperiences`:** This function implements the experience collection algorithm described in the paper. It takes training and validation datasets as input and iterates through them to collect and evaluate problem-solving experiences. \n\n   - It first runs the `solver` function on the training data to generate initial experiences, storing them in the `experienceKnowledgeBase`. \n   - It then evaluates the utility of each experience by using it to solve problems in the validation dataset and updating its `utility` score. \n   - Finally, it keeps only the experience with the highest utility for each problem type.\n\n2. **`questionAgent`:** This function simulates the question agent, which processes the raw question and extracts relevant information like graph type, input data, and output format. This pre-processing step is crucial for the subsequent agents to understand and solve the problem effectively.\n\n3. **`solver`:** This function represents a simplified version of the overall GraphTeam system, taking the output of the `questionAgent` and an optional experience as input. It attempts to solve the problem and returns the answer and meta-information about the solving process.\n\n**Purpose:**\n\nThe provided JavaScript code demonstrates the core concepts of experience collection, question processing, and problem-solving using LLMs as described in the research paper. It highlights the importance of leveraging past experiences to enhance the problem-solving capabilities of AI systems, particularly in the domain of graph analysis.",
  "simpleQuestion": "Can LLMs work together to analyze graphs?",
  "timestamp": "2024-10-24T05:01:12.577Z"
}