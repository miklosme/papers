{
  "arxivId": "2411.05990",
  "title": "Game-theoretic LLM: Agent Workflow for Negotiation Games",
  "abstract": "This paper investigates the rationality of large language models (LLMs) in strategic decision-making contexts, specifically within the framework of game theory. We evaluate several state-of-the-art LLMs across a spectrum of complete-information and incomplete-information games. Our findings reveal that LLMs frequently deviate from rational strategies, particularly as the complexity of the game increases with larger payoff matrices or deeper sequential trees.\nTo address these limitations, we design multiple game-theoretic workflows that guide the reasoning and decision-making processes of LLMs. These workflows aim to enhance the models' ability to compute Nash Equilibria and make rational choices, even under conditions of uncertainty and incomplete information. Experimental results demonstrate that the adoption of these workflows significantly improves the rationality and robustness of LLMs in game-theoretic tasks. Specifically, with the workflow, LLMs exhibit marked improvements in identifying optimal strategies, achieving near-optimal allocations in negotiation scenarios, and reducing susceptibility to exploitation during negotiations. Furthermore, we explore the meta-strategic considerations of whether it is rational for agents to adopt such workflows, recognizing that the decision to use or forgo the workflow constitutes a game-theoretic issue in itself.\nOur research contributes to a deeper understanding of LLMs' decision-making capabilities in strategic contexts and provides insights into enhancing their rationality through structured workflows. The findings have implications for the development of more robust and strategically sound AI agents capable of navigating complex interactive environments. Code and data supporting this study are available at https://github.com/Wenyueh/game_theory.",
  "summary": "This paper explores how well Large Language Models (LLMs) can make rational decisions in strategic scenarios, like negotiations, using game theory as a framework.  It finds that LLMs often struggle with complex games and deviate from optimal strategies, especially when uncertainty is involved. To address this, researchers designed game-theory-inspired workflows to guide LLM decision-making. These workflows significantly improved LLM performance in reaching agreements and achieving near-optimal outcomes.  However, the research also found that LLM-agents using these workflows can be exploited by agents *not* using them, raising a meta-strategic question of when it's beneficial to use such a workflow.  Additionally, LLM rationality was found to be surprisingly sensitive to seemingly minor changes in a game's parameters, like the exact numerical payoffs, and even to the LLM's assigned \"personality\".  Finally, the study examined differences between LLM irrationality and human irrationality, finding different patterns despite overall sub-optimal outcomes for both.",
  "takeaways": "This paper offers several key insights applicable to JavaScript developers working on LLM-based multi-agent web applications. Here are some practical examples leveraging its findings:\n\n**1. Integrating Game-Theoretic Workflows:**\n\n* **Scenario:** Building a multi-agent chatbot system for customer support, where agents need to negotiate solutions within defined constraints (e.g., discounts, available resources).\n* **Application:**  Implement a workflow inspired by the paper's \"backward induction\" for sequential games.  Using a library like `machina.js` (a finite state machine library) or `xstate` (statecharts library), define the negotiation steps, possible actions at each step, and the payoff matrix (customer satisfaction, resolution time, cost to the business). The LLM agents, interacting through a message queue (like Redis or RabbitMQ), would use this workflow to determine their optimal actions, improving negotiation efficiency and outcomes.\n\n* **Scenario:** Developing a collaborative online game where LLMs play against or with human players.\n* **Application:** Implement simultaneous game workflows based on \"dominant strategy search\"  as described in the paper.  When an LLM agent needs to make a move, it evaluates the payoff matrix (game points, resource acquisition) considering possible opponent actions (human or LLM).  Client-side JavaScript would manage user interactions and communicate with a server-side Node.js application where the LLM agents and workflow logic reside. Frameworks like `socket.io` could handle real-time communication.\n\n**2. Handling Incomplete Information and Bayesian Updates:**\n\n* **Scenario:** Creating a decentralized marketplace for digital assets where LLM agents automatically trade on behalf of users.\n* **Application:** Implement the Bayesian belief update mechanism from the paper to handle incomplete information about other agents' valuations. As trades happen, the LLM agent updates its belief distribution regarding other agents' preferences for asset types or price ranges. This can be implemented using a Bayesian inference library like `webppl-cljs` (if using ClojureScript) or by creating custom JavaScript functions to manage probabilities and updates.\n\n**3. Addressing LLM Rationality Limitations:**\n\n* **Scenario:** Building a multi-agent simulation for urban planning, where LLM agents represent different stakeholders (residents, businesses, government).\n* **Application:** To address LLM \"insensitivity to numerical values\" as identified in the paper, especially around zero-reward outcomes, consider normalizing the payoff matrix to larger, more distinct values.  Also, carefully design the prompts to encourage strategic thinking and avoid biases towards certain outcomes.  Experiment with different temperature settings to balance exploration and exploitation.  The simulation could be visualized using JavaScript libraries like `d3.js` or `leaflet`.\n\n\n**4. Meta-Strategy for Workflow Adoption:**\n\n* **Scenario:** Developing a system for automated contract negotiations between businesses.\n* **Application:** Recognizing that workflow adoption itself is a strategic decision, create a higher-level \"meta-strategy\"  using JavaScript. This could involve a simple rule-based system or a more complex reinforcement learning algorithm (using a library like `reinforcejs`) that decides whether to use the negotiation workflow based on the perceived \"personality\" or behavior of the opponent agent (cooperative, aggressive, rational).\n\n\n**Libraries and Frameworks:**\n\n* `machina.js`/`xstate`: For state machine management in workflows.\n* `socket.io`: For real-time communication in multi-agent systems.\n* `Redis`/`RabbitMQ`: For message queuing between agents.\n* `webppl-cljs` (or custom Bayesian logic): For belief update mechanisms.\n* `d3.js`/`leaflet`: For visualization of agent interactions or simulations.\n* `reinforcejs`:  For potential meta-strategy implementations.\n\n\nBy implementing these concepts in JavaScript, developers can create more robust, efficient, and strategically intelligent LLM-based multi-agent web applications. Remember that this research emphasizes careful prompt engineering, iterative experimentation, and awareness of LLM limitations as crucial aspects of successful multi-agent system development.",
  "pseudocode": "```javascript\nfunction allocationGame(privateValuation, commonResources) {\n  // Input: privateValuation (array of valuations for each item), commonResources (array of items)\n  // Output: Final allocation for the agent (array of items)\n\n  let beliefDistribution = initializeUniformBelief(commonResources); // Initially uniform belief\n  let rejectionReason = sampleRejectionReason(); // Randomly sample rejection reason\n\n  while (true) {\n    let proposedAllocation = maximizeUtilityEnvyFree(privateValuation, commonResources, beliefDistribution);\n    let [outcome, updatedAllocation] = proposeOffer(proposedAllocation, commonResources);\n\n    if (outcome === 'A') { // Agreement reached\n      return updatedAllocation;\n    } else { // Offer rejected\n      beliefDistribution = updateBelief(beliefDistribution, privateValuation, updatedAllocation, rejectionReason);\n      rejectionReason = sampleRejectionReason();\n    }\n  }\n\n  function initializeUniformBelief(resources) {\n    // Initialize belief distribution uniformly over all possible valuations\n    // (Implementation depends on how valuations are represented, omitted for brevity)\n\n  }\n\n\n\n  function maximizeUtilityEnvyFree(valuation, resources, belief) {\n    // Find allocation that maximizes agent's utility while being envy-free according to belief.\n    // Uses Monte Carlo sampling or LLM for efficiency (Implementation simplified for brevity)\n\n  }\n\n  function proposeOffer(allocation, resources) {\n    // Proposes the allocation to the other agent (simulated or actual)\n    // Returns outcome (A = accept, R1/R2 = reject) and potentially updated allocation\n    // (Implementation depends on the negotiation interface, omitted for brevity)\n\n  }\n\n  function updateBelief(belief, valuation, allocation, rejection) {\n    // Updates the belief distribution based on the rejection and the current allocation using equation (3)\n    // (Implementation omitted for brevity)\n\n  }\n\n\n  function sampleRejectionReason() {\n    // Samples rejection reasons (R1 = not envy free, R2 = suboptimal) based on set probabilities\n\n  }\n\n}\n\n\n```\n\n**Explanation and Purpose:**\n\nThis JavaScript code implements Algorithm 1 from the paper, designed for the Common Resource Allocation game (a two-player incomplete-information game like \"Deal or No Deal\").  The core logic revolves around iteratively proposing allocations and updating beliefs until an agreement is reached.\n\n1. **Initialization:**  The agent starts with a uniform belief about the opponent's valuations and a random rejection reason.\n\n2. **Allocation Proposal:** In each round, the `maximizeUtilityEnvyFree` function finds an allocation that maximizes the agent's utility while ensuring the allocation has a non-zero probability of being envy-free according to its current belief. This function might use Monte Carlo sampling or the LLM itself to assess envy-freeness.\n\n3. **Offer and Outcome:**  The `proposeOffer` function sends the proposed allocation to the other agent (either another LLM or a simulated opponent). The outcome is either acceptance ('A') or rejection ('R1' or 'R2', as described in the paper).\n\n4. **Belief Update:** If the offer is rejected, the agent updates its belief about the opponent's valuations using the `updateBelief` function based on Bayesian inference (equation (3) in the paper). This step is crucial for refining the agent's strategy in subsequent rounds.\n\n5. **Termination:** The loop continues until an agreement is reached (outcome 'A'), at which point the final allocation is returned.\n\n**Key Simplifications and Omissions:**\n\n* **Belief Representation and Update Implementation:** The specifics of how the belief distribution (`beliefDistribution`) is represented and updated are omitted for brevity. This depends on the chosen data structure and the implementation of the Bayesian update formula.\n* **`maximizeUtilityEnvyFree` Implementation:** The paper mentions both Monte Carlo sampling and utilizing the LLM for efficient utility maximization.  This example provides a simplified function signature; the actual implementation would be more complex.\n* **`proposeOffer` Implementation:** The details of how the offer is communicated and the outcome is received are omitted. This depends on the negotiation interface (e.g., direct function calls, message passing, etc.).\n* `sampleRejectionReason`: This function samples rejection reasons.  The actual probabilities for R1 and R2 (as represented by gamma in the paper) could be learned or adjusted.\n\n\nThis provided JavaScript code gives a clearer structure for a software engineer to implement compared to the pseudocode description in the original paper, focusing on the key functions and flow of the algorithm. It allows a starting point for building a functional agent for this type of negotiation game. Remember to fill in the missing implementation details to have a completely working agent.",
  "simpleQuestion": "How can LLMs play games rationally?",
  "timestamp": "2024-11-12T06:08:25.783Z"
}