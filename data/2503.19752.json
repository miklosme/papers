{
  "arxivId": "2503.19752",
  "title": "Inducing Personality in LLM-Based Honeypot Agents: Measuring the Effect on Human-Like Agenda Generation",
  "abstract": "This paper presents SANDMAN, an architecture for cyber deception that leverages Language Agents to emulate convincing human simulacra. Our 'Deceptive Agents' serve as advanced cyber decoys, designed for high-fidelity engagement with attackers by extending the observation period of attack behaviours. Through experimentation, measurement, and analysis, we demonstrate how a prompt schema based on the five-factor model of personality systematically induces distinct 'personalities' in Large Language Models. Our results highlight the feasibility of persona-driven Language Agents for generating diverse, realistic behaviours, ultimately improving cyber deception strategies.",
  "summary": "This paper introduces SANDMAN, a framework for creating \"Deceptive Agents\" â€“  AI-powered decoys that mimic human behavior in digital environments to mislead attackers. These agents utilize Large Language Models (LLMs) to generate realistic schedules and activities based on assigned personality traits derived from the Five-Factor Model (OCEAN).  Key findings relevant to LLM-based multi-agent systems include the ability to induce distinct personalities in LLMs which significantly influence task planning, the potential for using LLMs to create dynamic and believable simulated human behavior, and the importance of memory and a decision-making engine in agent architectures for creating plausible activity sequences.  The research also highlights the need for further exploration into multi-agent communication and dynamic adaptation to environment and context.",
  "takeaways": "This paper introduces SANDMAN, a novel architecture for creating \"Deceptive Agents\" using LLMs. These agents aim to mimic human behavior in digital environments, specifically for cybersecurity applications within a web context. Here's how a JavaScript developer can apply these insights:\n\n**1. Implementing the SANDMAN Architecture:**\n\n* **Decision Engine (JavaScript Core):**  The core logic can be implemented using Node.js or a browser-based JavaScript framework. This engine manages agent state, interacts with memory modules, and selects tasks.  Think of this as the central \"brain\" of your agent, orchestrating actions based on its personality and environment.  Libraries like `async.js` can manage asynchronous operations efficiently.\n\n* **Memory Modules (Browser Storage/Databases):**  Semantic memory (agent profile, personality) can be stored using browser LocalStorage, IndexedDB, or a server-side database. Episodic memory (past interactions) can be stored similarly, allowing agents to learn and adapt. Libraries like `localforage` simplify working with different browser storage options.\n\n* **Task List (JavaScript Arrays/Queues):**  The task list can be represented using JavaScript arrays or queues, prioritized based on the agent's goals and schedule generated by the Bootstrap Task. Libraries like `priorityqueue` can manage task prioritization.\n\n* **Channels (Web APIs/Browser Automation):**  Crucially, channels translate agent actions into interactions within the web environment.  Here's where web development expertise shines:\n    * Use browser APIs (DOM manipulation, Fetch API, WebSockets) for direct interaction with web pages.\n    * Leverage browser automation libraries like `Puppeteer` or `Playwright` for more complex interactions like form submissions, navigation, and simulating user input.\n\n* **Generators (LLM Integration):** This is where you integrate with the LLM API (e.g., OpenAI's API). Use JavaScript's `fetch` or libraries like `axios` to send requests to the LLM, providing prompts enriched with agent persona, memory, and task details. Receive generated content (text, code, etc.) and pass it to the appropriate channel.\n\n* **Bootstrap Task (LLM-driven Scheduling):**  Implement the bootstrapping process using an LLM. Send the agent's profile and available tasks as a prompt and receive a schedule (sequence of tasks). This schedule can be stored in the task list and used by the Decision Engine.\n\n**2.  Personality Induction:**\n\n* **Prompt Engineering:**  Craft prompts according to the five-factor model (OCEAN).  Use descriptive keywords to induce specific personalities.  For example, to induce high conscientiousness, you might use prompts like:  \"You are a meticulous and organized individual.  You value efficiency and always plan your actions carefully.  Given the following tasks...\", including words suggested in the paper like \"outgoing, energetic, public.\"  Experiment with prompt variations to see how they influence the generated schedule.\n\n* **MPI Integration (Optional):**  You could integrate a JavaScript implementation of the MPI (Machine Personality Inventory) to quantify and evaluate the induced personality of your agents, ensuring the desired traits are reflected.\n\n**3. Multi-Agent Scenarios (Advanced):**\n\n* **Inter-agent Communication:** Extend the architecture to support communication between agents. Use technologies like WebSockets or server-sent events to enable real-time information exchange, collaboration on tasks, and emergent behavior.\n\n* **Decentralized Decision-Making:** Explore decentralized decision-making algorithms, allowing agents to act autonomously based on local information and interactions, instead of relying solely on a central Decision Engine. Libraries like `peerjs` enable peer-to-peer communication.\n\n**Example Scenario: Automated Website Testing:**\n\nImagine a team of deceptive agents designed to test a website's security.  Each agent could have a different personality (e.g., cautious, reckless, curious). Their tasks might include browsing the site, filling forms, clicking links, and attempting common attack vectors (e.g., SQL injection). The agents' different personalities would influence how they approach these tasks, potentially revealing vulnerabilities a traditional testing approach might miss.\n\n**JavaScript Frameworks & Libraries:**\n\n* **Node.js:** For the core Decision Engine and server-side components.\n* **React, Vue, Angular:** For building user interfaces for monitoring and interacting with the agents.\n* **Puppeteer, Playwright:** For browser automation and simulating user interactions.\n* **localforage, IndexedDB:** For managing agent memory.\n* **axios, fetch:** For communicating with LLMs and other APIs.\n* **async.js, priorityqueue:** For managing asynchronous operations and task prioritization.\n* **peerjs, WebSockets:** For inter-agent communication in multi-agent scenarios.\n\nBy combining the insights from this research with practical web development skills, JavaScript developers can build innovative LLM-based multi-agent applications, particularly in the exciting field of cybersecurity.  The key is to carefully design the interaction between the LLM, the agent's personality, and the web environment using the available JavaScript tools and techniques.",
  "pseudocode": "No pseudocode block found.",
  "simpleQuestion": "Can LLM personalities improve honeypot effectiveness?",
  "timestamp": "2025-03-26T06:05:59.266Z"
}