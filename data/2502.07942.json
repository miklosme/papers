{
  "arxivId": "2502.07942",
  "title": "Symbiotic Cooperation for Web Agents: Harnessing Complementary Strengths of Large and Small LLMs",
  "abstract": "Web browsing agents powered by large language models (LLMs) have shown tremendous potential in automating complex web-based tasks. Existing approaches typically rely on large LLMs (e.g., GPT-4) to explore web environments and generate trajectory data, which is then used either for demonstration retrieval (for large LLMs) or to distill small LLMs (e.g., Llama 3) in a process that remains decoupled from the exploration. In this paper, we propose AgentSymbiotic, an iterative framework that couples data synthesis with task-performance, yielding a \"symbiotic improvement\" for both large and small LLMs. Our study uncovers a complementary dynamic between LLM types: while large LLMs excel at generating high-quality trajectories for distillation, the distilled small LLMs—owing to their distinct reasoning capabilities—often choose actions that diverge from those of their larger counterparts. This divergence drives the exploration of novel trajectories, thereby enriching the synthesized data. However, we also observe that the performance of small LLMs becomes a bottleneck in this iterative enhancement process. To address this, we propose two innovations in LLM distillation: a speculative data synthesis strategy that mitigates off-policy bias, and a multi-task learning approach designed to boost the reasoning capabilities of the student LLM. Furthermore, we introduce a Hybrid Mode for Privacy Preservation to address user privacy concerns. Evaluated on the WEBARENA benchmark, AgentSymbiotic achieves SOTA performance with both LLM types. Our best Large LLM agent reaches 52%, surpassing the previous best of 45%, while our 8B distilled model demonstrates a competitive 49%, exceeding the prior best of 28%. Code will be released upon acceptance.",
  "summary": "This paper introduces AgentSymbiotic, a framework for web agents that uses large and small language models (LLMs) cooperatively.  Large LLMs generate high-quality web interaction data, which is then used to train smaller, faster LLMs.  These smaller LLMs explore the web more broadly, generating additional diverse data, including edge cases missed by the larger models. This new data is then fed back to the large LLM, creating a continuous improvement loop.  Key innovations include speculative data synthesis to reduce bias during LLM training and multi-task learning to improve the smaller LLM's reasoning abilities. A hybrid mode improves privacy by handling sensitive data locally with a small LLM.  Experiments show AgentSymbiotic outperforms previous state-of-the-art approaches on the WEBARENA benchmark.",
  "takeaways": "This paper presents exciting opportunities for JavaScript developers working with LLM-based multi-agent systems. Here are some practical examples of how its insights can be applied in web development scenarios:\n\n**1. Symbiotic LLM Enhancement for a Collaborative Code Editor:**\n\n* **Scenario:** Imagine building a collaborative code editor where multiple users (represented by agent-LLMs) work together on a project.  One agent might be specialized in generating code (Large LLM), while other agents (Smaller LLMs) are specialized in code review, testing, and refactoring.\n* **Implementation:**\n    * **Large LLM (Code Generation Agent - Server-Side):** Use a powerful LLM like GPT-4 (accessed via API) as the code generation agent. This agent runs server-side due to resource constraints. Implement RAG using a vector database (e.g., Pinecone, Weaviate) storing code snippets, documentation, and successful interaction histories (trajectories) to enhance code generation based on past experience.\n    * **Smaller LLMs (Code Review, Testing, Refactoring Agents - Client-Side):** Deploy smaller, faster LLMs (e.g., Llama 2, quantized and optimized for browser execution using `webgpu` if available, or `wasm` otherwise) on the client-side to handle tasks like code review (generating critiques and suggestions) and basic unit testing. These agents can explore alternative coding patterns and solutions.\n    * **Symbiotic Improvement (Node.js + WebSockets):**  Use Node.js and WebSockets to facilitate communication between the server-side Large LLM and client-side Smaller LLMs. The smaller LLMs' findings (new trajectories, code critiques, test results) are sent back to the server, enriching the Large LLM's RAG knowledge base and refining its future code generation abilities.\n    * **Frontend (React, Vue.js):** Use a framework like React or Vue.js to build the user interface, allowing users to interact with their respective agents and visualize the collaborative coding process.\n\n**2. Multi-agent Ecommerce Shopping Assistant:**\n\n* **Scenario:** Build a shopping assistant where one agent helps the user find products (Large LLM) and another agent helps negotiate discounts or find better deals (Smaller LLM).\n* **Implementation:**\n    * **Large LLM (Product Discovery Agent - Server-Side):** A Large LLM, powered by RAG with product information, reviews, and past user preferences (trajectories), drives product discovery.\n    * **Smaller LLM (Deal Negotiation Agent - Client-Side):** A Smaller LLM on the client-side attempts to find discounts, coupons, or price comparisons. It can even experiment with simulated negotiations on e-commerce platforms using Puppeteer or Playwright.\n    * **Symbiosis (Serverless Functions + Browser Extension):**  Use serverless functions to enable the client-side agent to communicate with the server-side LLM. Successful deal-finding strategies (new trajectories) are sent to the server to improve the Large LLM's understanding of pricing dynamics and user preferences. Implement the client-side agent as a browser extension, using a library like `langchain.js` to manage prompts and interactions.\n\n**3. Multi-agent Content Creation Platform:**\n\n* **Scenario:**  Develop a platform where one agent generates content outlines (Large LLM), and smaller agents specialize in writing specific sections, fact-checking, and optimizing for SEO (Smaller LLMs).\n* **Implementation:**\n    * **Speculative Data Synthesis:** Implement Speculative Data Synthesis as described in the paper. As Smaller LLMs generate content, the Large LLM produces candidate texts. If the Smaller LLM's output aligns with the Large LLM's candidates, it is accepted; otherwise, the Large LLM's suggestions are used. This setup reduces off-policy drift.\n    * **Multi-Task Learning:** Train Smaller LLMs with multi-task objectives: generating content, checking facts (using an API like Google Fact Check Tools), and optimizing for SEO (using libraries that analyze keyword density, readability, etc.). This retains the reasoning capabilities of smaller agents during distillation.\n\nThese examples highlight how to leverage the paper's core concepts in JavaScript:\n\n* **Symbiosis:**  Combine Large and Smaller LLMs to leverage their respective strengths.\n* **Speculative Data Synthesis:** Use Large LLMs to guide and correct Smaller LLMs during content generation and task execution, reducing off-policy bias.\n* **Multi-Task Learning:**  Train Smaller LLMs on multiple related tasks to preserve reasoning abilities.\n* **Hybrid Mode (Privacy):** Handle sensitive data locally with Smaller LLMs, delegating non-sensitive tasks to server-side Large LLMs.\n\nBy applying these techniques, JavaScript developers can build more robust, efficient, and privacy-preserving multi-agent web applications powered by LLMs. Remember that optimization for browser execution, especially for larger models, will be an ongoing challenge. Libraries like `webllm` are promising and might play an essential role in bringing the benefits of larger models to client-side multi-agent applications. Efficient communication between server-side and client-side agents will be crucial and should be addressed through appropriate communication protocols and libraries.",
  "pseudocode": "The provided research paper contains two algorithms described in pseudocode blocks. Here are their JavaScript conversions along with explanations:\n\n**Algorithm 1: RAG-Enhanced Large LLM**\n\n```javascript\nasync function ragEnhancedLLM(instruction, observation, ragKnowledgeBase, numRetrievedExamples) {\n  let interactionHistory = [];\n\n  for (const currentInstruction of instruction) {\n    let trajectory = await interactWithEnvironment(currentInstruction); // Interacts with the web environment\n    let subsequences = generateSubsequences(trajectory); // Splits trajectories into subsequences\n\n    for (const sub of subsequences) {\n      let [instructionPrime, summaryPrime] = await largeLLM(sub); // Generate instructions and summaries using LLM\n\n      if (await judgeLLM(sub, instructionPrime, summaryPrime)) {\n        ragKnowledgeBase.push({ trajectory: sub, instruction: instructionPrime, summary: summaryPrime }); // Store in knowledge base\n      }\n    }\n\n    for (let i = 0; i < interactionHistory.length || i ===0; i++) { //i=0 only if interactionHistory is an empty array, i=interactionHistory.length means the trajectory is finished\n      let query = await largeLLM(currentInstruction, observation[i]); // Generate retrieval queries\n\n      let retrievedExamples = [];\n      const retrievalStrategies = [taskGuidedSummaryRetrieval, directMatching, trajectorySimilaritySearch]; // Example retrieval strategies\n\n      for (const strategy of retrievalStrategies) {\n        retrievedExamples = retrievedExamples.concat(await strategy(query, ragKnowledgeBase, interactionHistory.slice(0,i))); // Retrieve examples based on different strategies\n      }\n\n      let filteredExamples = await filterExamples(retrievedExamples, largeLLM); // Filter retrieved examples using LLM\n      let [action, reason] = await largeLLM(currentInstruction, observation[i], filteredExamples); // Generate action and reasoning using LLM\n      interactionHistory.push({ observation: observation[i], action, reason });\n      if(observation.length===i+1) break; //break if reached the end of the trajectory\n    }\n\n\n  }\n  return interactionHistory;\n}\n\n\n// Example placeholder functions - these need actual implementations based on your specific setup.\nasync function interactWithEnvironment(instruction) { /* ... */ }\nfunction generateSubsequences(trajectory) { /* ... */ }\nasync function largeLLM( /* ... */ ) { /* ... */ }\nasync function judgeLLM( /* ... */ ) { /* ... */ }\nasync function taskGuidedSummaryRetrieval( /* ... */ ) { /* ... */ }\nasync function directMatching( /* ... */ ) { /* ... */ }\nasync function trajectorySimilaritySearch( /* ... */ ) { /* ... */ }\nasync function filterExamples( /* ... */ ) { /* ... */ }\n```\n\n* **Explanation:** This algorithm enhances a large language model (LLM) with Retrieval Augmented Generation (RAG). It first generates a knowledge base of successful and failed web interaction trajectories. Then, for a given task, it retrieves relevant trajectories from the knowledge base based on the current observation and instruction.  The LLM uses these retrieved examples, combined with the current observation and instruction, to decide the next action and reason. This iterative retrieval and action selection enhances the LLM's performance by providing contextually relevant information from past interactions.\n\n**Algorithm 2: Improved Distillation for Small LLMs**\n\n```javascript\nasync function improvedDistillation(largeLLM, smallLLM, environment, instruction, numActionCandidates, judgeLLM) {\n  let trainingDataset = [];\n\n  for (const currentInstruction of instruction) {\n    let interactionHistory = [];\n\n    for (let i = 0; i < environment.maxSteps; i++) {\n      let observation = await environment.getObservation();\n\n      let [action, reason] = await smallLLM(currentInstruction, observation);\n      let candidateActions = await largeLLM(currentInstruction, interactionHistory, observation);\n\n      if (candidateActions.some(candidate => candidate.action === action)) {\n        // Accept small LLM's action\n      } else {\n        action = findBestAction(candidateActions); // Replace with large LLM's best action\n      }\n\n      interactionHistory.push({ observation, action, reason });\n        if (await environment.isTerminal()) break; // End interaction if the environment is terminal after taking an action\n    }\n\n\n    if (await judgeLLM(interactionHistory)) {\n      trainingDataset.push(...interactionHistory);\n    }\n  }\n\n  // Multi-task learning\n  for (const { observation, action, reason } of trainingDataset) {\n    let lossAction = computeLoss(smallLLM(currentInstruction, observation).action, action); // Calculate loss for action prediction\n    let lossReasoning = computeLoss(smallLLM(currentInstruction, observation).reason, reason); // Calculate loss for reasoning generation\n\n    await smallLLM.optimize(lossAction, lossReasoning); // Optimize small LLM using both losses\n  }\n\n  return smallLLM;\n}\n\n// Example placeholder functions\nfunction findBestAction(candidates) { /* ... */ }\nfunction computeLoss(predicted, target) { /* ... */ }\n```\n\n* **Explanation:** This algorithm distills the knowledge of a large LLM to a smaller LLM, specifically for web browsing tasks.  It uses a \"speculative\" approach where the small LLM proposes actions, but the large LLM validates them. This helps mitigate off-policy bias.  The algorithm also uses multi-task learning, training the small LLM to predict both the next action *and* the reasoning behind it. This helps preserve the reasoning capabilities of the larger model.  The distilled small LLM is then more efficient and retains more of the large model's capabilities than traditional distillation approaches.",
  "simpleQuestion": "How can I best combine large and small LLMs for web agent tasks?",
  "timestamp": "2025-02-13T06:17:42.682Z"
}