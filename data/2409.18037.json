{
  "arxivId": "2409.18037",
  "title": "HARMONIC: A Framework for Explanatory Cognitive Robots",
  "abstract": "Abstract-We present HARMONIC, a framework for implementing cognitive robots that transforms general-purpose robots into trusted teammates capable of complex decision-making, natural communication and human-level explanation. The framework supports interoperability between a strategic (cognitive) layer for high-level decision-making and a tactical (robot) layer for low-level control and execution. We describe the core features of the framework and our initial implementation, in which HARMONIC was deployed on a simulated UGV and drone involved in a multi-robot search and retrieval task.",
  "summary": "This paper introduces HARMONIC, a framework for building robots that can understand and respond to requests, explain their actions, and collaborate with humans.  \n\nHere's how it relates to LLM-based multi-agent systems:\n\n* **Dual Control System:** HARMONIC uses a \"strategic\" layer (for high-level reasoning, potentially using LLMs) and a \"tactical\" layer (for robot control). This split is key for integrating LLMs into real-world applications where they can't directly control actions.\n* **Explainability:** The paper highlights the need for robots to explain their actions to build trust.  While LLMs alone aren't great at providing transparent reasoning, HARMONIC suggests limiting them to specific modules within the framework to improve explainability. \n* **Knowledge Bases:**  HARMONIC relies on ontologies, lexicons, and agent profiles to give robots the background knowledge needed for understanding requests and reasoning about the world. This suggests that LLM-based agents would benefit from well-structured external knowledge sources.",
  "takeaways": "This paper presents HARMONIC, a framework for building explainable cognitive robots that can work with humans. While it focuses on robots, many of its principles directly apply to building LLM-based multi-agent systems for the web, particularly when LLMs need to collaborate or interact with humans in explainable ways.\n\nHere's how JavaScript developers can apply the insights from this paper:\n\n**1. Dual-Layer Architecture:**\n\n* **Strategic Layer (System 2):**  This is where your LLM shines. Use a powerful LLM like GPT-4 for:\n    * **Natural Language Understanding:** Process user requests and teammate communications (e.g., using `langchain.js` for interaction with OpenAI API).\n    * **Planning & Reasoning:**  Break down high-level goals into steps (e.g., leverage planning libraries like `graphlib` or `planjs`).\n    * **Explanation Generation:**  Provide human-understandable reasons for actions taken (e.g., use LLM prompting techniques to generate clear explanations).\n\n* **Tactical Layer (System 1):** Handle the practical execution of LLM-generated plans using JavaScript:\n    * **Web Interaction:**  Manipulate web elements, make API calls, retrieve/display information (e.g., using frameworks like React, Vue.js, or libraries like Axios).\n    * **Reactive Behavior:** Implement simple rule-based responses to events or changes in the web environment (e.g., using event listeners and conditional logic).\n\n* **Bridging the Layers:**\n    * Define a clear interface for communication between the LLM and your JavaScript code (e.g., JSON objects to represent tasks, data, and feedback).\n    * Consider message queues (e.g., RabbitMQ, Redis) or websockets for real-time, asynchronous communication.\n\n**2. Practical Web Application Examples:**\n\n* **Collaborative Document Editing:**\n    * **Strategic Layer (LLM):** Understands user edits, suggests improvements, detects potential conflicts, and generates explanations for suggestions.\n    * **Tactical Layer (JavaScript):** Integrates with a rich text editor (e.g., ProseMirror, Slate), applies edits, highlights conflicts, displays LLM suggestions. \n\n* **AI-Powered Customer Support:**\n    * **Strategic Layer (LLM):**  Analyzes customer queries, retrieves relevant information, generates helpful responses, and explains solutions.\n    * **Tactical Layer (JavaScript):**  Powers the chatbot interface (e.g., using Dialogflow, Botpress), manages conversation flow, displays information dynamically. \n\n* **Personalized Learning Platforms:**\n    * **Strategic Layer (LLM):**  Assesses student knowledge, creates personalized learning paths, generates practice exercises, explains concepts.\n    * **Tactical Layer (JavaScript):**  Presents learning content, handles user interactions, provides feedback on exercises, tracks progress.\n\n**3.  Key JavaScript Tools & Libraries:**\n\n* **LLM Interaction:** `langchain.js` (OpenAI API), `transformers.js` (local model execution)\n* **Web Frameworks:** React, Vue.js, Angular\n* **State Management:** Redux, Zustand\n* **API Calls:** Axios, Fetch API\n* **Real-time Communication:** Socket.IO \n\n**Remember:**  This paper emphasizes the importance of **explainability** to build trust.  Design your JavaScript code to not just execute LLM instructions but also capture and present the LLM's reasoning process to users. This transparency is crucial for effective human-AI collaboration.",
  "pseudocode": "No pseudocode block found.",
  "simpleQuestion": "How to make robots explain their decisions?",
  "timestamp": "2024-09-27T05:01:47.719Z"
}