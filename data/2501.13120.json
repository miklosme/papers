{
  "arxivId": "2501.13120",
  "title": "Multilinguality in LLM-Designed Reward Functions for Restless Bandits: Effects on Task Performance and Fairness",
  "abstract": "Restless Multi-Armed Bandits (RMABs) have been successfully applied to resource allocation problems in a variety of settings, including public health. With the rapid development of powerful large language models (LLMs), they are increasingly used to design reward functions to better match human preferences. Recent work has shown that LLMs can be used to tailor automated allocation decisions to community needs using language prompts. However, this has been studied primarily for English prompts and with a focus on task performance only. This can be an issue since grassroots workers, especially in developing countries like India, prefer to work in local languages, some of which are low-resource. Further, given the nature of the problem, biases along population groups unintended by the user are also undesirable. In this work, we study the effects on both task performance and fairness when the DLM algorithm, a recent work on using LLMs to design reward functions for RMABs, is prompted with non-English language commands. Specifically, we run the model on a synthetic environment for various prompts translated into multiple languages. The prompts themselves vary in complexity. Our results show that the LLM-proposed reward functions are significantly better when prompted in English compared to other languages. We also find that the exact phrasing of the prompt impacts task performance. Further, as prompt complexity increases, performance worsens for all languages; however, it is more robust with English prompts than with lower-resource languages. On the fairness side, we find that low-resource languages and more complex prompts are both highly likely to create unfairness along unintended dimensions.",
  "summary": "This paper investigates the impact of using different languages, particularly low-resource languages, in prompts for LLMs that design reward functions for Restless Multi-Armed Bandits (RMABs), a type of multi-agent resource allocation problem.  It specifically examines how non-English prompts affect both the task performance (how well the allocation aligns with the prompt's goal) and fairness (whether allocations are equitable across demographic groups). Key findings reveal that English prompts yield better reward functions and performance compared to other languages.  Furthermore, prompt phrasing and complexity significantly influence the resulting allocations, with explicit phrasing and simpler prompts leading to better outcomes.  Low-resource language prompts and complex prompts tend to introduce more unfairness in the allocation. These findings have implications for developing fair and effective LLM-based multi-agent systems, especially in real-world applications like public health resource allocation in multilingual communities.",
  "takeaways": "This paper highlights crucial considerations for JavaScript developers building LLM-powered multi-agent web apps, especially when targeting diverse linguistic groups. Let's explore practical applications with code examples and relevant JavaScript tools:\n\n**1. Prompt Engineering for Multilingual Reward Functions:**\n\nThe paper demonstrates that LLM performance in generating reward functions varies significantly across languages.  For a JavaScript developer, this means careful prompt engineering is paramount.  You need to ensure your prompts translate accurately and retain their semantic meaning in the target language.\n\n* **Example:** Imagine building a multi-agent system for a collaborative online game where agents negotiate resource allocation.  You could use LangChain.js to manage your LLM interactions.\n\n```javascript\nimport { OpenAI } from \"langchain/llms/openai\";\nimport { PromptTemplate } from \"langchain/prompts\";\n\nconst llm = new OpenAI({ openAIApiKey: \"YOUR_API_KEY\", temperature: 0.7 });\nconst promptTemplate = new PromptTemplate({\n    template: \"Design a reward function for agents in a game where the goal is to {goal}. Agents have the following features: {features}. Prioritize agents who {priority}.\",\n    inputVariables: [\"goal\", \"features\", \"priority\"],\n});\n\nconst prompt = await promptTemplate.format({\n    goal: \"collect the most resources\",\n    features: \"language, score, resources\",\n    priority: \"speak Spanish and have a high score\", // Multilingual priority\n});\n\n\nconst rewardFunctionCode = await llm.call(prompt);\n// Evaluate and refine the generated code\n```\n\n* **Key takeaway**: Use translation libraries (e.g., `@google-cloud/translate`)  and verify translations with native speakers. Iterate on prompts to maximize LLM performance in each language.\n\n**2. Addressing Fairness in Multilingual Contexts:**\n\nThe paper reveals that low-resource languages and complex prompts can lead to unfairness in allocations. This is critical for web apps dealing with sensitive issues like resource distribution or personalized recommendations.\n\n* **Example:** Consider a multi-agent system for distributing aid resources after a disaster. Agents represent different affected communities, communicating their needs via LLMs. To mitigate unfairness:\n\n```javascript\n// Agent Class\nclass AidAgent {\n    constructor(language, needs) {\n        this.language = language;\n        this.needs = needs;\n        // ... other properties\n    }\n\n    async communicateNeeds(llm) {\n        // ... translate needs to English if necessary\n        const translatedNeeds = translate(this.needs, \"en\"); // Use a translation library\n        const prompt = `Prioritize aid distribution based on: ${translatedNeeds}`;\n        const response = await llm.call(prompt);\n        // ... process and return response\n    }\n}\n// Analysis of allocation fairness:\nfunction analyzeFairness(allocations, agentLanguages) {\n    // Group allocations by language\n    const allocationsByLanguage = {};\n    for (let i = 0; i < allocations.length; i++) {\n        const language = agentLanguages[i];\n        allocationsByLanguage[language] = allocationsByLanguage[language] || [];\n        allocationsByLanguage[language].push(allocations[i]);\n    }\n\n    // Calculate statistics (e.g., mean, variance) for each language group\n    for (const language in allocationsByLanguage) {\n        // ... calculate and compare statistics across languages\n    }\n}\n\n\n```\n\n* **Key takeaway:**  Group agents by language and analyze resource allocation statistics for each group. Implement fairness metrics (like those in the paper) in JavaScript. Adjust your system to minimize disparities between language groups.\n\n**3. Handling Prompt Complexity:**\n\nComplex prompts decrease LLM performance across all languages, with a more significant impact on low-resource languages. Developers must design prompts that are concise, unambiguous, and directly related to the desired reward function.\n\n* **Example:** Instead of a complex prompt like \"Prioritize users who speak Hindi, are over 30, and have a premium subscription\", break it down into simpler, modular prompts.  You can chain these sub-prompts together using LangChain.js:\n\n\n\n* **Key Takeaway:**  Decompose complex goals into smaller sub-tasks. Use LLM chaining to generate reward components for each sub-task and combine them into a final reward function.\n\n\nBy incorporating these practical strategies and using relevant JavaScript frameworks, developers can leverage the power of LLMs for building robust, fair, and multilingual multi-agent web applications.  Remember that this field is rapidly evolving, so continuous exploration and experimentation are essential for staying at the cutting edge.",
  "pseudocode": "No pseudocode block found. However, there are mathematical formulas that can be translated into JavaScript:\n\n**1. Probability of Allocation Given Age:**\n\n```javascript\nfunction probabilityAllocationGivenAge(probAgeGivenAllocation, probAllocation, probAge) {\n  return (probAgeGivenAllocation * probAllocation) / probAge;\n}\n```\n\nThis function implements Equation (1) and calculates the probability of an individual receiving an allocation given their age. It takes the probability of an individual being of a certain age given they received an allocation (`probAgeGivenAllocation`), the overall probability of receiving an allocation (`probAllocation`), and the probability of an individual being of a certain age (`probAge`) as inputs.\n\n\n\n**2. Mean Probability of Allocation:**\n\n```javascript\nfunction meanProbabilityAllocation(ageProbabilities) {\n  let sum = 0;\n  for (let i = 0; i < ageProbabilities.length; i++) {\n    sum += ageProbabilities[i];\n  }\n  return sum / ageProbabilities.length;\n}\n```\n\nThis function corresponds to Equation (3) and calculates the average probability of allocation across all age groups.  It receives an array of probabilities, `ageProbabilities`, where each element represents the probability of receiving an allocation for a specific age group.\n\n\n\n**3. Demographic Parity Variance:**\n\n```javascript\nfunction demographicParityVariance(ageProbabilities) {\n  const meanProb = meanProbabilityAllocation(ageProbabilities);\n  let varianceSum = 0;\n  for (let i = 0; i < ageProbabilities.length; i++) {\n    varianceSum += Math.pow(ageProbabilities[i] - meanProb, 2);\n  }\n  return varianceSum / ageProbabilities.length;\n}\n```\n\nThis function translates Equation (2) and calculates the demographic parity variance. It uses the `meanProbabilityAllocation` function defined earlier and takes the same `ageProbabilities` array as input.  It quantifies the disparity in allocation probabilities across different age groups.  A lower value indicates more fairness in terms of demographic parity.\n\n\nThese JavaScript snippets operationalize the core fairness calculations of the paper, enabling JavaScript developers to assess the fairness implications of their multi-agent systems.  They can be readily integrated into a web application to monitor and analyze the allocation behaviors of an LLM-driven resource allocation system.",
  "simpleQuestion": "How do LLM reward functions' language impact fairness and performance?",
  "timestamp": "2025-01-24T06:03:08.941Z"
}