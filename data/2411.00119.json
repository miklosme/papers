{
  "arxivId": "2411.00119",
  "title": "Soft Condorcet Optimization for Ranking of General Agents",
  "abstract": "A common way to drive progress of AI models and agents is to compare their performance on standardized benchmarks. Comparing the performance of general agents requires aggregating their individual performances across a potentially wide variety of different tasks. In this paper, we describe a novel ranking scheme inspired by social choice frameworks, called Soft Condorcet Optimization (SCO), to compute the optimal ranking of agents: the one that makes the fewest mistakes in predicting the agent comparisons in the evaluation data. This optimal ranking is the maximum likelihood estimate when evaluation data (which we view as votes) are interpreted as noisy samples from a ground truth ranking, a solution to Condorcet's original voting system criteria. SCO ratings are maximal for Condorcet winners when they exist, which we show is not necessarily true for the classical rating system Elo. We propose three optimization algorithms to compute SCO ratings and evaluate their empirical performance. When serving as an approximation to the Kemeny-Young voting method, SCO rankings are on average 0 to 0.043 away from the optimal ranking in normalized Kendall-tau distance across 865 preference profiles from the Pref Lib open ranking archive. In a simulated noisy tournament setting, SCO achieves accurate approximations to the ground truth ranking and the best among several baselines when 59% or more of the preference data is missing. Finally, SCO ranking provides the best approximation to the optimal ranking, measured on held-out test sets, in a problem containing 52,958 human players across 31,049 games of the classic seven-player game of Diplomacy.",
  "summary": "This paper introduces Soft Condorcet Optimization (SCO), a new method for ranking AI agents based on their performance across different tasks or against each other.  It addresses the problem of incomplete data, common in agent evaluation, by using a differentiable loss function inspired by voting theory.  SCO aims to find the ranking that minimizes disagreements with observed performance comparisons (votes).\n\nFor LLM-based multi-agent systems, SCO offers a way to rank and compare LLMs based on their performance across diverse benchmarks, even with incomplete data.  It can potentially identify the best-performing LLM in a group by aggregating results from various tasks, similar to how voting systems elect a winner. The method is differentiable, which may prove useful for training or fine-tuning LLMs based on their relative performance rankings. It also offers an online version for updating rankings as new evaluation data becomes available, which could be beneficial for continuously evolving LLM agents.",
  "takeaways": "This paper introduces Soft Condorcet Optimization (SCO), a novel ranking system for multi-agent AI, particularly relevant for LLM-based agents where traditional methods like Elo fall short. Here are practical examples of how JavaScript developers can apply these insights to LLM-based multi-agent projects:\n\n**1. Chatbot Arena/Tournament Platform:**\n\n* **Scenario:** Building a platform where users can pit different LLM-powered chatbots against each other and vote on their performance in various tasks (e.g., question answering, creative writing).\n* **Application of SCO:** Instead of relying on pairwise win rates (which can be misleading), use SCO to aggregate user votes (preferences) across multiple tasks. This provides a more robust and nuanced ranking, even with sparse voting data.\n* **Implementation:**\n    * **Frontend (React, Vue, etc.):**  Implement the UI for chatbot battles, task selection, and user voting.\n    * **Backend (Node.js):** Use a numerical optimization library (e.g., `ml.js`, `numjs`) to implement the SCO algorithm (gradient descent on the sigmoid loss is recommended). Store user votes as preference profiles and update SCO rankings in real-time as votes come in. Expose API endpoints for fetching rankings and chatbot information.\n    * **LLM Integration:** Use a JavaScript LLM library (e.g., `langchain.js`, `transformers.js`) to integrate the chatbots into the platform.\n\n**2. Collaborative Content Creation:**\n\n* **Scenario:** Developing a multi-agent system where LLMs collaborate to write articles, generate code, or design websites.  Users provide feedback on different versions generated by different agent teams.\n* **Application of SCO:** Use SCO to rank the agent teams based on user preferences. This allows the system to learn which team combinations produce better results according to users, even if feedback is incomplete.\n* **Implementation:**\n    * **Collaboration Framework:** Use a JavaScript library like `peer.js` or `socket.io` to enable real-time communication and collaboration between the LLMs.\n    * **SCO Integration:** Similar to the chatbot arena, implement SCO on the backend to process user feedback (votes) and update rankings for different LLM teams.\n    * **Frontend:**  Develop a UI where users can view different output versions, provide feedback, and track the progress of the content creation process.\n\n**3. Personalized Recommendation Systems:**\n\n* **Scenario:** Creating a recommendation system where multiple LLM agents propose different recommendations (e.g., products, articles, movies). Users express their preferences through implicit or explicit feedback.\n* **Application of SCO:**  Use SCO to learn user preferences across multiple agents. This allows for a more dynamic and personalized ranking of LLM agents, improving recommendation relevance.\n* **Implementation:**\n    * **LLM Agents:**  Develop specialized LLM agents (using different prompts or fine-tuning) for different recommendation categories.\n    * **User Feedback Collection:** Implement mechanisms to capture user feedback (e.g., clicks, ratings, dwell time) on recommendations.\n    * **SCO Integration:** Use SCO to aggregate user feedback and learn personalized rankings of LLM agents for each user.  The backend should serve recommendations based on the personalized agent rankings.\n\n**4. A/B Testing and Optimization:**\n\n* **Scenario:**  Testing different versions of a website or application feature generated by multiple LLM agents.  Users interact with each version and provide implicit or explicit feedback.\n* **Application of SCO:** Use SCO to rank the different versions based on user preferences. This provides a robust way to identify the best-performing version, especially when A/B testing data is sparse or noisy.\n* **Implementation:**\n    * **A/B Testing Framework:** Integrate with a JavaScript A/B testing library (e.g., `react-ab-test`, `ember-a11y-testing`).\n    * **LLM-generated Versions:**  Use LLMs to generate variations of website content, UI elements, or code.\n    * **SCO Integration:**  Use SCO on the backend to aggregate user feedback and rank the different LLM-generated versions.\n\n**Key JavaScript Libraries/Frameworks:**\n\n* **LLM Integration:** `langchain.js`, `transformers.js`\n* **Frontend UI:**  React, Vue, Angular\n* **Backend:** Node.js, Express.js\n* **Numerical Optimization:** `ml.js`, `numjs`\n* **Real-time Communication:** `socket.io`, `peer.js`\n* **A/B Testing:** `react-ab-test`, `ember-a11y-testing`\n\n\nBy leveraging SCO, JavaScript developers can build more robust, user-centered, and efficient LLM-based multi-agent web applications that adapt and learn from user feedback in complex scenarios. Remember to experiment with different hyperparameters and optimization methods within the SCO framework to find the best solution for your specific application.",
  "pseudocode": "```javascript\n// Algorithm 1: Learning SCO ratings by gradient descent\n\nfunction learnSCORatings(preferenceProfile, initialRatings, learningRates, batchSize) {\n  const numAlternatives = initialRatings.length;\n  const numVotes = preferenceProfile.length;\n  let theta = [...initialRatings]; // Create a copy to avoid modifying the original\n  const maxRating = Math.max(...initialRatings);\n  const minRating = Math.min(...initialRatings);\n\n\n  for (let t = 0; t < learningRates.length; t++) {  // Iterate through learning rates\n    const alpha = learningRates[t];\n    for (let iteration = 0; iteration < 10000; iteration++){  // Added iteration limit for demonstration\n\n\n       // Sample a batch of votes\n      const batch = [];\n      for (let i = 0; i < batchSize; i++) {\n        batch.push(preferenceProfile[Math.floor(Math.random() * numVotes)]);\n      }\n\n      // Calculate the gradient of the sigmoid loss for the batch\n      const gradient = new Array(numAlternatives).fill(0);\n      for (const vote of batch) {\n        for (let i = 0; i < vote.length; i++) {\n          for (let j = i + 1; j < vote.length; j++) {\n            const alt1 = vote[i];\n            const alt2 = vote[j];\n            const diff = theta[alt2] - theta[alt1];\n            const sigmoid = 1 / (1 + Math.exp(-diff)); // Assuming temperature tau = 1\n            gradient[alt1] -= sigmoid;\n            gradient[alt2] += sigmoid;\n          }\n        }\n      }\n\n\n      // Update ratings using gradient descent and project back to valid range\n      for (let a = 0; a < numAlternatives; a++) {\n        theta[a] = Math.min(maxRating, Math.max(minRating, theta[a] - alpha * gradient[a]));\n      }\n    }\n\n  }\n  return theta;\n}\n\n\n\n// Example Usage (Refer to Table 1 and Equation 10 for preference profile structure)\n\nconst preferenceProfile = [\n  [0, 1, 2], // A > B > C - Example vote format (agent indices)\n  [0, 1, 2],\n  [2, 0, 1], // C > A > B\n  [2, 0, 1],\n  [2, 0, 1]\n\n];\n\n\n// Example initial ratings (can be initialized randomly or otherwise)\nconst initialRatings = [50, 50, 50]; \nconst learningRates = [0.1, 0.01]; // Example Learning Rates (can be adjusted)\nconst batchSize = 2; // Example Batch Size\n\nconst finalRatings = learnSCORatings(preferenceProfile, initialRatings, learningRates, batchSize);\nconsole.log(\"Final Ratings:\", finalRatings);\n\n// To get the final ranking, sort the agents based on their final ratings:\n\n\nconst rankedAgents = finalRatings.map((rating, index) => ({ rating, index }))\n                        .sort((a, b) => b.rating - a.rating)\n                        .map(item => item.index);\n\nconsole.log(\"Ranked Agent Indices (Descending order of rating/skill):\", rankedAgents);\n\n\n\n```\n\n**Explanation of Algorithm 1 and its Purpose:**\n\nThis JavaScript code implements Algorithm 1 from the paper, which learns SCO (Soft Condorcet Optimization) ratings for a set of alternatives (e.g., AI agents) based on a preference profile. The purpose of SCO is to find an optimal ranking of these alternatives that best reflects the pairwise comparisons provided in the preference profile, especially when dealing with incomplete or noisy data.\n\nThe algorithm uses gradient descent to minimize a sigmoid loss function, which is a differentiable approximation of the Kendall-tau distance between the induced ranking and the votes in the preference profile.\n\n**Key Steps and Concepts:**\n\n1. **Initialization:** The algorithm starts with initial ratings for each alternative, a learning rate (or a schedule of them) and a batch size.\n\n2. **Batch Sampling:** In each iteration, it samples a batch of votes from the preference profile.\n\n3. **Gradient Calculation:** It calculates the gradient of the sigmoid loss function with respect to the ratings, based on the sampled batch. The gradient indicates the direction in which to adjust the ratings to reduce the loss.\n\n4. **Rating Update:** It updates the ratings using gradient descent, moving the ratings in the opposite direction of the gradient, scaled by the learning rate.\n\n5. **Projection:** It projects the updated ratings back to the valid range [θmin, θmax] to ensure they remain within the defined bounds.\n\n6. **Iteration:** Steps 2-5 are repeated for a number of iterations until convergence (or a predetermined number of training steps).\n\n\n7. **Ranking:** After the iterations are done, the final rankings are determined by sorting the alternatives based on their learned ratings.\n\nThe example usage demonstrates how to use the `learnSCORatings` function with a sample preference profile and other parameters. It also shows how to get the final ranking by sorting the alternatives based on their final ratings.  It should be noted that hyperparameters like learning rates, batch sizes, and iteration limits may need to be tuned based on the specific problem.",
  "simpleQuestion": "How to rank agents using noisy performance data?",
  "timestamp": "2024-11-04T06:02:34.024Z"
}