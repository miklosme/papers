{
  "arxivId": "2503.09758",
  "title": "Multi-Agent LLM Actor-Critic Framework for Social Robot Navigation",
  "abstract": "Recent advances in robotics and large language models (LLMs) have sparked growing interest in human-robot collaboration and embodied intelligence. To enable the broader deployment of robots in human-populated environments, socially-aware robot navigation (SAN) has become a key research area. While deep reinforcement learning approaches that integrate human-robot interaction (HRI) with path planning have demonstrated strong benchmark performance, they often struggle to adapt to new scenarios and environments. LLMs offer a promising avenue for zero-shot navigation through commonsense inference. However, most existing LLM-based frameworks rely on centralized decision-making, lack robust verification mechanisms, and face inconsistencies in translating macro-actions into precise low-level control signals. To address these challenges, we propose SAMALM, a decentralized multi-agent LLM actor-critic framework for multi-robot social navigation. In this framework, a set of parallel LLM actors, each reflecting distinct robot personalities or configurations, directly generate control signals. These actions undergo a two-tier verification process via a global critic that evaluates group-level behaviors and individual critics that assess each robot's context. An entropy-based score fusion mechanism further enhances self-verification and re-query, improving both robustness and coordination. Experimental results confirm that SAMALM effectively balances local autonomy with global oversight, yielding socially compliant behaviors and strong adaptability across diverse multi-robot scenarios. More details and videos about this work are available at: https://sites.google.com/view/SAMALM.",
  "summary": "This paper introduces SAMALM, a decentralized multi-agent framework using LLMs for controlling multiple robots navigating a space with humans. Each robot has an individual LLM \"actor\" generating control signals and \"critic\" LLMs providing feedback, alongside a global \"critic\" LLM evaluating overall group behavior. This actor-critic system, enhanced by entropy-based score fusion for verification and re-querying, aims for robust and socially-compliant navigation, addressing limitations of centralized LLM approaches in multi-robot systems by considering individual robot characteristics and preferences.  Key aspects relevant to LLM-based multi-agent systems include the decentralized architecture, the personalized prompts for individual LLM actors, the two-tiered critic system combining individual and global feedback, and the use of entropy for score fusion to ensure robust and adaptable behavior.",
  "takeaways": "This paper presents SAMALM, a decentralized multi-agent LLM actor-critic framework for enhanced social navigation in multi-robot systems.  Let's translate these insights into practical examples for a JavaScript developer working on LLM-based multi-agent web applications:\n\n**1. Decentralized LLM Agents with LangChain:**\n\n* **Scenario:** Building a collaborative writing web app where multiple LLM agents generate different sections of a story, maintaining coherence and consistency.\n* **Implementation:** Use LangChain or similar frameworks to manage multiple LLM instances (actors) in a Node.js backend. Each agent can specialize in a particular writing style, genre, or character perspective.  The `agents` module in LangChain is well-suited for this.  Consider using different prompt templates for individual agents, mirroring the \"personalized prompt engineering\" discussed in the paper.\n\n```javascript\nimport { LLMChain, OpenAI, PromptTemplate } from \"langchain\";\n// ... other imports\n\nconst agent1 = new LLMChain({\n  llm: new OpenAI({ temperature: 0.7 }),\n  prompt: new PromptTemplate({\n    template: \"Write a {genre} story about {topic}.\",\n    inputVariables: [\"genre\", \"topic\"],\n  }),\n});\n\n// ... define other agents (agent2, agent3, etc.) with different prompts.\n\n// ... use LangChain agents module to orchestrate these agents.\n```\n\n**2. Implementing Critics with LLM-based Evaluation:**\n\n* **Scenario:**  A multi-agent customer support system where LLMs respond to user queries, but a separate LLM critic evaluates the responses for quality, relevance, and helpfulness.\n* **Implementation:**  After an agent LLM generates a response, send it to another LLM (critic) for evaluation. Define prompt templates for the critic to assess different aspects of the response.  For example: “Evaluate the following customer support response for clarity, relevance, and helpfulness: {agent_response}”. Use the critic's output (score and textual feedback) to improve subsequent agent responses (re-querying as in SAMALM).\n\n**3. Entropy-Based Score Fusion with JavaScript:**\n\n* **Scenario:** Aggregating feedback from multiple LLM critics in a content moderation system, accounting for disagreement among the critics.\n* **Implementation:**  Normalize the scores from different critics (e.g., using softmax), calculate the entropy of the distribution as described in the paper (Equation 6), and use it to weigh the critic scores (Equation 8) when making a final decision.  This can be easily implemented with standard JavaScript math functions.\n\n```javascript\nfunction calculateEntropy(probabilities) {\n  let entropy = 0;\n  for (const p of probabilities) {\n    if (p > 0) {\n      entropy -= p * Math.log(p);\n    }\n  }\n  return entropy;\n}\n\n// ... normalize critic scores to probabilities\n// ... calculate entropy and use it for weighted averaging\n```\n\n**4. World Model Representation with JSON Graphs:**\n\n* **Scenario:**  A multi-agent simulation in a virtual world (e.g., a game).\n* **Implementation:** Represent the world state using JSON-based graph structures, similar to the spatio-temporal graphs described in the paper. Include nodes for agents, objects, and their relationships. This graph serves as input to the LLM agents.  Libraries like `Cytoscape.js` can be helpful for visualizing and manipulating graph data on the frontend.\n\n**5. Front-end Integration with React or Vue:**\n\n* **Scenario:**  Displaying the interactions and decisions of multiple LLM agents in a user interface.\n* **Implementation:** Use React or Vue to create dynamic components for each agent, displaying their actions, feedback from critics, and changes in the world model. This allows users to monitor the behavior of the multi-agent system and provide input if needed.\n\n**Key JavaScript Libraries and Frameworks:**\n\n* **LangChain:** For managing multiple LLM instances, prompt engineering, and agent orchestration.\n* **Node.js:** For running the backend server and handling LLM interactions.\n* **React/Vue:** For building the user interface and visualizing agent behavior.\n* **TensorFlow.js/ML5.js:**  If incorporating more complex numerical computations (e.g., for advanced score fusion).\n* **Cytoscape.js/Vis.js:** For visualizing graph-based world models.\n\n\nBy understanding the principles of decentralized agent control, critic-based evaluation, and score fusion, JavaScript developers can leverage LLMs to create innovative and sophisticated multi-agent web applications.  This paper provides valuable theoretical foundations for building practical and effective LLM-powered multi-agent systems in the browser and beyond.",
  "pseudocode": "```javascript\n// Algorithm 1: Socially-Aware Multi-Agent LLM (SAMALM)\n\nasync function SAMALM(initialState, actors, critics, hyperparameters) {\n  let jointState = initialState;\n  let dataBuffer = []; // Initialize data buffer for critic feedback\n\n  for (let step = 0; step < hyperparameters.maxSteps; step++) {\n    const observations = await getObservations();  // Placeholder function\n    const worldModels = observations.map(observation => constructWorldModel(observation)); // Placeholder function\n\n    let jointAction = await Promise.all(\n      worldModels.map(async (worldModel, i) => {\n        const action = await actors[i].generateAction(worldModel, hyperparameters.taskDescription);\n        return action;\n      })\n    );\n\n    let [globalCriticScore, localCriticScores] = await queryCritics(jointAction, critics); // Placeholder function\n    let fusionScore = calculateFusionScore(globalCriticScore, localCriticScores, hyperparameters); // Placeholder function\n\n\n    while (fusionScore < hyperparameters.fusionScoreThreshold) {\n      // Re-query actions below threshold\n      jointAction = await Promise.all(\n        jointAction.map(async (action, i) => {\n          if (localCriticScores[i].score < fusionScore) {\n            // Update the action using critic reasoning text and global critic text\n            const updatedAction = await actors[i].updateAction(\n              worldModels[i], \n              hyperparameters.taskDescription, \n              localCriticScores[i].text, \n              globalCriticScore.text\n            );\n            dataBuffer[i] = localCriticScores[i].text // Store or use critic reasoning for learning/analysis.\n\n            return updatedAction;\n\n          } else {\n\n            return action;\n          }\n\n        })\n      );\n      // Re-calculate scores\n      [globalCriticScore, localCriticScores] = await queryCritics(jointAction, critics);\n      fusionScore = calculateFusionScore(globalCriticScore, localCriticScores, hyperparameters); \n    }\n    // Execute the joint action in the environment and transition to next state\n    jointState = await executeAction(jointState, jointAction); // Placeholder function\n\n  }\n}\n\n// Placeholder functions (replace with your implementations)\n\nasync function getObservations(){\n  // Function for obtaining the environment observations \n  // For each agent, it might involve sensor readings, etc.\n  // Returns an array of observations, one for each agent.\n  return []\n}\n\nfunction constructWorldModel(observation) {\n  // Transforms the observation into the textual world model representation\n  return observation.toString()\n}\n\n\nasync function queryCritics(jointAction, critics){\n  // Function to interact with critics, global and local\n  // Retrieves their numerical scores and reasoning texts.\n  // This could involve API calls or direct interactions with LLM models.\n  // Should return [globalCriticScore, localCriticScores].\n  // Individual elements inside  localCriticScores should have \"score\" and \"text\" attributes\n  // e.g. localCriticScores[i] = {\"score\": numericalScore , \"text\": reasoningText}\n\n  return []\n}\n\n\nfunction calculateFusionScore(globalScore, localScores, hyperparameters) {\n  // Implments the entropy-based fusion mechanism as described in equation (8).\n  return 0\n}\n\n\n\nasync function executeAction(jointState, jointAction){\n  // Executes the given actions on the robots in the environment\n  // Updates the environment state based on the effects of the actions\n  // Should return the new state of the environment\n  return jointState\n}\n\n\n\n// Example usage\nconst initialState = \"...\";\nconst actors = [\"...\", \"...\", \"...\"]; // Array of LLM actors\nconst critics = [\"...\", \"...\", \"...\"]; // Array of LLM critics\nconst hyperparameters = {\n  maxSteps: 100,\n  taskDescription: \"...\",\n  fusionScoreThreshold: 70, // An example value, adjust as needed\n};\n\nSAMALM(initialState, actors, critics, hyperparameters)\n  .then(() => console.log(\"SAMALM completed.\"))\n  .catch(error => console.error(\"An error occurred:\", error));\n\n```\n\n\n\n**Explanation and Purpose of the SAMALM Algorithm:**\n\nThe Socially-Aware Multi-Agent LLM (SAMALM) algorithm coordinates multiple robots in a shared environment, enabling them to navigate socially compliantly while achieving their individual goals.  It uses Large Language Models (LLMs) for both action generation (actors) and evaluation (critics).\n\n**Key Features:**\n\n* **Decentralized Control:**  Each robot has its own LLM actor generating actions based on local observations. This increases robustness and adaptability to dynamic environments.\n* **Two-Tier Verification:**  Actions are evaluated by both individual (local) LLM critics and a global LLM critic. Local critics assess individual robot actions in their immediate context, while the global critic focuses on overall team performance and coordination.\n* **Self-Verification and Re-query:**  If actions fail to meet the specified evaluation threshold (determined by entropy-based score fusion), the actors re-generate actions, taking into account the feedback provided by the critics. This iterative refinement loop improves robustness and social compliance.\n* **Entropy-based Score Fusion:**  The algorithm balances local and global critic scores based on their level of agreement. When local critics are consistent, their opinions are weighted more heavily. Conversely, when local critics disagree, the global critic’s assessment becomes more influential.\n* **Textual World Models:** Observations are transformed into textual representations (world models) that capture the spatial-temporal dynamics of the environment and interactions between robots and humans. This allows LLMs to leverage their natural language processing capabilities for reasoning and action generation.\n* **Personalized Prompts:** LLM actors can be customized with robot-specific preferences for speed and social distance, accommodating the diverse characteristics of different robot platforms.\n\n**Purpose:**\n\nThe algorithm aims to solve multi-robot navigation tasks in human-populated environments while adhering to social norms and avoiding collisions.  It is particularly relevant in scenarios where robots need to adapt to dynamic and unpredictable human behavior, making pre-defined rules or pre-trained policies difficult to apply.  The use of LLMs allows SAMALM to generalize better to new environments and tasks, and the actor-critic framework with self-verification ensures robust and socially compliant behavior.",
  "simpleQuestion": "How can LLMs improve multi-robot navigation?",
  "timestamp": "2025-03-14T06:02:34.898Z"
}