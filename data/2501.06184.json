{
  "arxivId": "2501.06184",
  "title": "PEACE: Empowering Geologic Map Holistic Understanding with MLLMs",
  "abstract": "Geologic map, as a fundamental diagram in geology science, provides critical insights into the structure and composition of Earth's subsurface and surface. These maps are indispensable in various fields, including disaster detection, resource exploration, and civil engineering. Despite their significance, current Multimodal Large Language Models (MLLMs) often fall short in geologic map understanding. This gap is primarily due to the challenging nature of cartographic generalization, which involves handling high-resolution map, managing multiple associated components, and requiring domain-specific knowledge. To quantify this gap, we construct GeoMap-Bench, the first-ever benchmark for evaluating MLLMs in geologic map understanding, which assesses the full-scale abilities in extracting, referring, grounding, reasoning, and analyzing. To bridge this gap, we introduce GeoMap-Agent, the inaugural agent designed for geologic map understanding, which features three modules: Hierarchical Information Extraction (HIE), Domain Knowledge Injection (DKI), and Prompt-enhanced Question Answering (PEQA). Inspired by the interdisciplinary collaboration among human scientists, an AI expert group acts as consultants, utilizing a diverse tool pool to comprehensively analyze questions. Through comprehensive experiments, GeoMap-Agent achieves an overall score of 0.811 on GeoMap-Bench, significantly outperforming 0.369 of GPT-40. Our work, emPowering gEologic map holistic understanding (PEACE) with MLLMs, paves the way for advanced AI applications in geology, enhancing the efficiency and accuracy of geological investigations.",
  "summary": "This paper introduces PEACE, a framework leveraging Multimodal Large Language Models (MLLMs) for enhanced geological map understanding.  It includes GeoMap-Bench, a new benchmark for evaluating MLLM performance on geological map tasks, and GeoMap-Agent, a multi-agent system designed for these tasks.  GeoMap-Agent uses a hierarchical approach to information extraction (HIE), domain knowledge injection from specialized AI expert agents (DKI â€“ geologist, geographer, seismologist), and prompt engineering (PEQA) to improve MLLM performance.  Key multi-agent aspects include the collaborative expert group and scalable tool pool, offering a model for other complex scientific visualization tasks.",
  "takeaways": "This paper introduces PEACE, a framework for enhancing geological map understanding using Multimodal Large Language Models (MLLMs) and a multi-agent approach.  Let's translate these concepts into practical JavaScript applications for web developers:\n\n**1. Hierarchical Information Extraction (HIE) with JavaScript:**\n\nThe HIE concept of breaking down complex images into smaller, manageable chunks is directly applicable to web development. Imagine a web app analyzing a user-uploaded floor plan or a complex diagram.\n\n* **Implementation:**  Use a JavaScript library like OpenCV.js (a port of OpenCV) or Konva.js for image manipulation. Detect bounding boxes of regions of interest (rooms, furniture in a floorplan, components in a diagram) using object detection models (e.g., YOLO, SSD) implemented in TensorFlow.js or ONNX.js. These regions can be extracted as separate image \"chunks.\"\n* **Example:**\n```javascript\n// Conceptual example using OpenCV.js\nlet src = cv.imread('floorplanImage');\nlet regions = detectRegions(src); // Using a pre-trained object detection model\n\nregions.forEach(region => {\n  let croppedImage = cropImage(src, region.boundingBox); // Custom cropping function\n  let extractedInfo = analyzeRegion(croppedImage); // Send to LLM agent for analysis\n  // ... process extractedInfo\n});\n```\n\n**2. Domain Knowledge Injection (DKI) with LLMs and Agents:**\n\nThe DKI concept translates to incorporating specialized knowledge into your agents.\n\n* **Implementation:** In a floor plan example, you might have agents specialized in:\n    * **Space planning:** (LLM prompt engineered to analyze room sizes, layouts, and suggest improvements.)\n    * **Interior design:** (LLM trained on interior design data, suggesting color palettes, furniture arrangements, etc.)\n    * **Accessibility:** (LLM focused on building code compliance, suggesting accessible design changes.)\n\n* **Example (Conceptual using LangChain):**\n```javascript\nconst spacePlanner = new LLMAgent({ llm: spacePlanningLLM, tools: [areaCalculator] });\nconst designAgent = new LLMAgent({ llm: interiorDesignLLM, tools: [colorPaletteGenerator] });\n\n// ... after HIE, send cropped images to relevant agents\nlet spacePlanningResult = await spacePlanner.analyze(croppedRoomImage); \n```\n**3. Prompt-Enhanced Question Answering (PEQA) in a Web App:**\n\nPEQA's structured prompts and reasoning steps can improve the quality of responses from LLMs.\n\n* **Implementation:** Consider a web app that allows users to ask questions about a historical map.\n    * **Context:** Provide extracted metadata from the HIE stage (date, location, key features) as context in the LLM prompt.\n    * **CoT:**  Encourage step-by-step reasoning in the prompt (e.g., \"First identify the region mentioned in the question, then analyze its features based on the map's legend\").\n    * **Few-Shot Learning:** Include examples of questions and answers in the prompt to guide the LLM's response format.\n\n\n* **Example:**\n\n```javascript\nlet question = \"What type of agriculture was prevalent in this area in 1850?\";\nlet prompt = `\nMap Metadata: ${JSON.stringify(metadata)}\nQuestion: ${question}\nReasoning Steps:\n1. Locate the area on the map.\n2. Identify land use symbols based on the legend.\n3. ...\nAnswer (JSON format): \n`;\nlet response = await queryLLM(prompt);\n```\n\n**4. Multi-Agent System Architecture in a JavaScript App:**\n\n* **Implementation:**  Use a message-passing framework like Comlink or a dedicated library for multi-agent systems (if one emerges for LLMs). Your main JavaScript application would coordinate the agents (HIE, DKI experts), send messages, and collect responses.\n\n\n**Key Libraries/Frameworks:**\n\n* **OpenCV.js/Konva.js:** Image processing and region extraction.\n* **TensorFlow.js/ONNX.js:** Running object detection models.\n* **LangChain:** Building LLM-powered agents and chains.\n* **Comlink:** Message passing between agents (if running in separate workers).\n\n**Web Development Scenarios:**\n\n* **Interactive Diagrams/Floorplans:** Analyze complex visual input, provide insights, answer user questions.\n* **Document Analysis:** Extract information from scanned documents (invoices, forms, etc.).\n* **Educational Tools:**  Interactive learning tools for complex subjects, explaining concepts using visuals.\n* **Collaborative Design:**  Multiple agents with different expertise contributing to a design project.\n\n\nBy combining these techniques, JavaScript developers can create sophisticated, interactive web applications that harness the power of LLMs and multi-agent systems for complex image understanding and analysis, going beyond the specific geological domain presented in the paper.  The key is modularity, specialization of agents, and effective prompt engineering.",
  "pseudocode": "No pseudocode block found.",
  "simpleQuestion": "Can LLMs fully understand geologic maps?",
  "timestamp": "2025-01-13T06:02:30.617Z"
}