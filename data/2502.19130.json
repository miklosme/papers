{
  "arxivId": "2502.19130",
  "title": "Voting or Consensus? Decision-Making in Multi-Agent Debate",
  "abstract": "Much of the success of multi-agent debates depends on carefully choosing the right parameters. Among them, the decision-making protocol stands out. Systematic comparison of decision protocols is difficult because studies alter multiple discussion parameters beyond the protocol. So far, it has been largely unknown how decision-making addresses the challenges of different tasks. This work systematically evaluates the impact of seven decision protocols (e.g., majority voting, unanimity consensus). We change only one variable at a time (i.e., decision protocol) to analyze how different methods affect the collaboration between agents and test different protocols on knowledge (MMLU, MMLU-Pro, GPQA) and reasoning datasets (StrategyQA, MuSR, SQUAD 2.0). Our results show that voting protocols improve performance by 13.2% in reasoning tasks and consensus protocols by 2.8% in knowledge tasks over the other decision protocol. Increasing the number of agents improves performance, while more discussion rounds before voting reduces it. To improve decision-making by increasing answer diversity, we propose two new methods, All-Agents Drafting (AAD) and Collective Improvement (CI). Our methods improve task performance by up to 3.3% with AAD and up to 7.4% with CI. This work demonstrates the importance of decision-making in multi-agent debates beyond scaling.",
  "summary": "This paper investigates how different decision-making protocols (consensus vs. voting) impact the performance of multi-agent LLM systems in solving knowledge-based and reasoning-based tasks.  It finds voting is more effective for reasoning, while consensus is better for knowledge tasks.  Two novel methods are introduced: All-Agents Drafting (AAD) and Collective Improvement (CI), which boost performance by encouraging answer diversity. Increasing the number of agents is shown to be more beneficial than increasing discussion rounds.  The research highlights the importance of tailoring decision protocols to specific task types in multi-agent LLM applications and leveraging answer diversity for optimal performance.",
  "takeaways": "This research paper provides valuable insights for JavaScript developers working on LLM-based multi-agent web applications.  Here's how its findings can be applied in practical scenarios:\n\n**1. Choosing the Right Decision Protocol:**\n\n* **Scenario:** Building a collaborative writing tool where multiple LLMs suggest edits and improvements to a document.\n* **Insight:** The paper demonstrates that consensus protocols are better for knowledge-based tasks, while voting excels in reasoning tasks.  Since collaborative writing involves both knowledge (grammar, style) and reasoning (coherence, argumentation), a hybrid approach might be optimal.  \n* **Implementation:**\n    * Use LangChain or similar libraries to manage the LLM interactions and voting/consensus mechanisms.\n    * For grammatical and stylistic corrections (knowledge), implement a majority consensus protocol.  If two out of three LLMs agree on a correction, it's applied.\n    * For content suggestions and restructuring (reasoning), use ranked voting. LLMs rank proposed edits, and the edit with the highest cumulative rank is presented to the user.\n\n\n**2. Managing Agent Diversity and Preventing Sycophancy:**\n\n* **Scenario:** Developing a customer support chatbot system where multiple LLMs analyze user queries and collaboratively generate responses.\n* **Insight:** The paper emphasizes the importance of answer diversity and introduces All-Agents Drafting (AAD) and Collective Improvement (CI).  These methods prevent LLMs from simply echoing each other and promote independent thinking.\n* **Implementation:**\n    * **AAD:** When a user submits a query, each LLM independently generates a draft response *before* seeing the other LLMs' drafts. This ensures diverse starting points.  Implement this in JavaScript by making parallel API calls to your LLM provider (e.g., OpenAI, Cohere) for each agent.\n    * **CI:** For complex queries, after the initial drafting, use CI.  In each subsequent round, show each LLM the previous round's responses but *not* the current round's responses. This discourages imitation and promotes iterative improvement.  You can implement this with asynchronous JavaScript functions and promises.\n\n**3. Optimizing the Number of Agents and Discussion Rounds:**\n\n* **Scenario:** Creating a multi-agent system for generating creative content, like stories or poems.\n* **Insight:** The paper shows that increasing the number of agents tends to improve performance, but increasing the number of discussion rounds may not be as beneficial, particularly in reasoning tasks, and can even hinder performance.\n* **Implementation:** Start with a smaller number of rounds (e.g., 3-5) and focus on optimizing the number of agents.  Experiment with different numbers of agents (3, 5, 7) to find the sweet spot between performance and computational cost.  Monitor the responses to ensure they stay on topic and avoid repetitive or nonsensical outputs.\n\n**4.  Handling Edge Cases and Unanswerable Questions:**\n\n* **Scenario:** A multi-agent research assistant that analyzes academic papers and answers user questions.\n* **Insight:** The paper shows that consensus methods are more effective at identifying unanswerable questions.\n* **Implementation:** If the LLMs fail to reach a consensus or if their confidence scores are low, implement a fallback mechanism. This could involve:\n    * Returning a message like \"I'm unable to answer your question based on the provided context.\"\n    * Prompting the user to rephrase the question or provide additional information.\n    * Querying a different knowledge base or search engine.\n\n**5. JavaScript Libraries and Frameworks:**\n\n* **LangChain:** Ideal for orchestrating LLM chains, managing agent prompts and responses, and implementing decision protocols.\n* **Web Workers:** Useful for running LLM interactions in the background without blocking the main thread, especially when dealing with multiple agents or long discussions.\n* **Node.js:** Enables server-side LLM integration and management of multiple agents.\n* **React/Vue/Angular:**  For building interactive front-end interfaces that display agent responses and allow user interaction with the multi-agent system.\n\nBy understanding these insights and applying them with relevant JavaScript tools, developers can build more robust, effective, and engaging multi-agent web applications. Remember to experiment and adapt these principles to your specific project requirements and context.",
  "pseudocode": "No pseudocode block found.",
  "simpleQuestion": "How best to make decisions in multi-agent LLMs?",
  "timestamp": "2025-02-27T06:03:47.815Z"
}