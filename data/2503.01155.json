{
  "arxivId": "2503.01155",
  "title": "NATURE-INSPIRED POPULATION-BASED EVOLUTION OF LARGE LANGUAGE MODELS",
  "abstract": "Evolution, the engine behind the survival and growth of life on Earth, operates through the population-based process of reproduction. Inspired by this principle, this paper formally defines a newly emerging problem—the population-based evolution of large language models (LLMs)—and introduces a novel framework. Starting with a population of parent LLMs, our framework enables the population to evolve through four key operations: (i) crossover, merging the weights of different parents to create offspring LLMs, (ii) mutation, introducing small, random changes to model weights to foster diversity, (iii) selection, prioritizing high-performing models, and (iv) succession, transferring the learned experience from parent to offspring LLMs. With only 200 samples per new task, the LLM population evolves rapidly to adapt to the task at hand, without any gradients. Experiments on 12 datasets show that our framework consistently outperforms existing multi-LLM merging and adaptation methods, achieving accuracy gains of up to 54.8% over the best LLM in the initial population. Moreover, our framework allows for the evolution of LLMs across multiple new tasks simultaneously, scaling effectively with populations of up to 40 LLMs, and even zero-shot generalization to unseen held-out tasks. We have open-sourced the code on GitHub and released the weights of 10 parent LLMs, fine-tuned from gemma-2-2b-it, on HuggingFace, enabling reproduction of our proposed framework using just a single 4090 GPU with 24GB memory, without any performance degradation.",
  "summary": "This paper introduces GENOME(+), a novel framework inspired by biological evolution for adapting and improving Large Language Models (LLMs).  It treats LLM weights as \"genes\" and uses evolutionary operations like crossover (combining weights of different LLMs), mutation (introducing small changes to weights), and selection (keeping the best-performing LLMs). GENOME+ extends this with succession (learning from the best and worst performers) and ensemble (combining outputs of multiple LLMs) to enhance performance. Experiments show GENOME+ outperforms other LLM merging and adaptation methods, particularly in reasoning tasks, and effectively generalizes to new tasks with few or no samples. It is computationally efficient, requiring only a single GPU, and scales well with larger populations of LLMs.  Key points relevant to multi-agent systems include the crossover mechanism as a means of agent knowledge transfer and the ensemble mechanism as a means of collective decision-making between agents.  This work provides a potential foundation for evolving multi-agent systems of LLMs by merging, mutating, and selecting agent \"genes\" (weights), potentially leading to emergent capabilities and adaptable multi-agent systems.",
  "takeaways": "This paper introduces GENOME(+), a novel framework for evolving populations of LLMs to adapt to new tasks, inspired by genetic algorithms.  Here's how a JavaScript developer can apply these insights to LLM-based multi-agent web applications:\n\n**1. Conceptualizing Agents as Evolving LLMs:**\n\n* **Individual Agents:** Each agent in your application can be powered by an LLM whose \"genes\" are its weights or LoRA parameters.  These parameters determine the agent's behavior and skills (e.g., negotiation, task completion, communication).\n* **Population-Based Approach:** Instead of training individual agents in isolation, maintain a population of agents and allow them to evolve over time using GENOME(+). This allows for the emergence of more robust and adaptable agents.\n\n**2. Implementing GENOME(+) in JavaScript:**\n\n* **LLM Integration:** Use a JavaScript LLM library like `LangChain.js` or a cloud-based API to interact with the LLMs powering your agents.\n* **Genetic Operators:** Implement the core genetic operations in JavaScript:\n    * **Crossover:** Create new agents (\"offspring\") by combining the LoRA parameters of two \"parent\" agents using weighted averages based on fitness scores.\n    * **Mutation:** Introduce small, random changes to the LoRA parameters of agents to promote diversity and exploration of new behaviors.\n    * **Selection:** Prioritize high-performing agents based on their fitness scores (e.g., task completion rate, user satisfaction).  Remove low-performing agents.\n    * **Succession (GENOME+):** Update agent parameters based on the best and worst performing agents in the population, simulating learning from experience. This can be implemented using the experience update equation (Equation 5 in the paper).\n    * **Ensemble (GENOME+):** During inference, aggregate responses from the top-k performing agents using majority voting or similarity-based approaches (e.g., embedding similarity). This can be implemented using libraries like `TensorFlow.js` for embeddings and similarity calculations.\n* **Fitness Evaluation:** Define fitness functions tailored to your application's objectives. For example, in a multi-agent e-commerce simulation, an agent's fitness could be based on its profit, customer satisfaction, or successful negotiations.\n\n**3. Web Development Scenarios:**\n\n* **Multi-Agent Chatbots:** Create a population of chatbot agents that can evolve to improve their conversational abilities, handling diverse user queries and personalizing responses.\n* **Collaborative Task Completion:** Develop agents that can collaborate on complex tasks, dynamically adapting their roles and strategies based on evolving task requirements. For example, in a project management application, agents could handle task assignment, resource allocation, and progress tracking.\n* **Game AI:** Design evolving agents for web-based games, enabling more dynamic and challenging gameplay.\n* **Personalized Recommendations:** Develop a population of recommender agents that can evolve to better understand individual user preferences and provide personalized recommendations.\n\n**4. Example Implementation Snippet (Conceptual):**\n\n```javascript\n// Simplified crossover operation using LangChain.js and hypothetical LORA access\nasync function crossover(agent1, agent2) {\n  const fitness1 = await evaluateFitness(agent1);\n  const fitness2 = await evaluateFitness(agent2);\n  const totalFitness = fitness1 + fitness2;\n  const weight1 = fitness1 / totalFitness;\n  const weight2 = fitness2 / totalFitness;\n\n  const offspringLORA = {};\n  for (const key in agent1.lora) {\n    offspringLORA[key] = weight1 * agent1.lora[key] + weight2 * agent2.lora[key];\n  }\n\n  return new Agent(offspringLORA); // Create a new agent with the combined LORA\n}\n\n// Hypothetical fitness evaluation function\nasync function evaluateFitness(agent) {\n  // Implement logic to assess agent performance (e.g., task completion)\n  const performance = await agent.performTask(); \n  return performanceScore(performance); \n}\n```\n\n**5. JavaScript Frameworks and Libraries:**\n\n* **LangChain.js:** For integrating LLMs.\n* **TensorFlow.js:** For numerical computations, including mutation, embedding similarity, and implementing the succession update equation.\n* **Web Workers:** For managing agent populations and genetic operations asynchronously to maintain UI responsiveness.\n\n\nBy adapting the GENOME(+) framework, JavaScript developers can create more robust, adaptable, and intelligent multi-agent web applications that can evolve to meet dynamic and complex challenges. This approach reduces the need for extensive hand-crafted rules and allows for the emergence of more sophisticated agent behaviors through evolutionary optimization.",
  "pseudocode": "The paper contains two algorithms presented in pseudocode blocks. Here are their JavaScript equivalents along with explanations:\n\n**Algorithm 1: GENOME**\n\n```javascript\nasync function genome(task, fitnessFunction, expertModels, {\n  populationSize = 10,\n  crossoverRate = 0.3,\n  individualMutationRate = 0.3,\n  geneMutationRate = 0.2,\n  sigma = 0.001,\n  eliteRatio = 0.1,  // Alpha\n  maxIterations = 10\n}) {\n\n  // Initialization. Create population from linear combinations of expert LoRA weights.\n  let population = [];\n  for (let i = 0; i < populationSize; i++) {\n    const t = Math.random(); // t ~ U(0,1)\n    const model1Index = Math.floor(Math.random() * expertModels.length);\n    const model2Index = Math.floor(Math.random() * expertModels.length);\n    const w_i = combineLoraWeights(expertModels[model1Index], expertModels[model2Index], t);\n    population.push(w_i); // Simplified representation. In reality, manage models/weights.\n  }\n\n  // Evaluate initial fitness.\n  let fitnessScores = await Promise.all(population.map(individual => fitnessFunction(individual, task)));\n  let bestIndividual = population[fitnessScores.indexOf(Math.max(...fitnessScores))];\n\n  for (let iter = 1; iter <= maxIterations; iter++) {\n    // Crossover\n    for (let i = 0; i < populationSize * crossoverRate; i++) {  // Simplified pairing for demo\n      const probabilities = fitnessScores.map(f => f / fitnessScores.reduce((a, b) => a + b, 0));\n      const parent1Index = weightedRandomChoice(population.length, probabilities);\n      const parent2Index = weightedRandomChoice(population.length, probabilities); // Ensure different parents in actual implementation\n      const t = fitnessScores[parent1Index] / (fitnessScores[parent1Index] + fitnessScores[parent2Index]);\n      const childWeights = combineLoraWeights(population[parent1Index], population[parent2Index], t);\n      const childFitness = await fitnessFunction(childWeights, task);\n\n       // Add child to population (replacement strategy varies; could be generational, elitist, etc.)\n      population.push(childWeights);\n      fitnessScores.push(childFitness);\n\n    }\n\n    // Mutation\n    for (let i = 0; i < population.length; i++){\n      if (Math.random() < individualMutationRate){\n        const mutatedWeights = mutateLoraWeights(population[i], geneMutationRate, sigma);\n        const mutatedFitness = await fitnessFunction(mutatedWeights, task);\n\n        //Replace original with mutation\n        population[i] = mutatedWeights;\n        fitnessScores[i] = mutatedFitness;\n      }\n    }\n\n    // Selection (elitist + fitness-proportional)\n    const sortedIndices = fitnessScores.map((score, index) => ({ score, index }))\n                                      .sort((a, b) => b.score - a.score);\n\n    const elite = sortedIndices.slice(0, eliteRatio * populationSize).map(x => population[x.index]);\n    const rest = [];\n    const remainingCount = populationSize - elite.length;\n    const remainingProbabilities = sortedIndices.map(f => f.score / fitnessScores.reduce((a, b) => a + b, 0)); // Could remove elites from calc\n    for (let i = 0; i < remainingCount; i++){\n      const selectedIndex = weightedRandomChoice(population.length, remainingProbabilities);\n      rest.push(population[selectedIndex]);\n    }\n    population = [...elite, ...rest]; // Update the population\n    fitnessScores = await Promise.all(population.map(individual => fitnessFunction(individual, task))); // Re-evaluate\n\n\n    bestIndividual = population[fitnessScores.indexOf(Math.max(...fitnessScores))];\n  }\n\n  // Final evaluation on test set.\n  return bestIndividual;\n}\n\nfunction combineLoraWeights(weights1, weights2, t){\n  //Actual implementation would depend on the LoRA library\n  //This is placeholder for demonstration purposes\n  return  weights1 * t + weights2 *(1-t); //Simplified. Elementwise weight combination\n}\n\n\nfunction mutateLoraWeights(weights, gm, sigma){\n  //Actual implementation would depend on the LoRA library\n  //This is placeholder for demonstration purposes\n  const mutated = [...weights]; //Simplified representation. Elementwise weight mutation.\n  for(let i = 0; i < mutated.length; i++){\n    if(Math.random() < gm){\n      mutated[i] += gaussianRandom(0, sigma);\n    }\n  }\n  return mutated;\n}\n\n\n\nfunction weightedRandomChoice(n, weights){\n  let sum = 0, r = Math.random();\n  for(let i = 0; i < n; i++){\n    sum += weights[i];\n    if(r < sum) return i;\n  }\n  return n-1;\n}\n\nfunction gaussianRandom(mean=0, stdev=1) {\n  let u = 1 - Math.random(); //Converting [0,1) to (0,1]\n  let v = Math.random();\n  let z = Math.sqrt( -2.0 * Math.log( u ) ) * Math.cos( 2.0 * Math.PI * v );\n  return z * stdev + mean;\n}\n\n\n```\n\n\n\n* **Explanation:** This algorithm simulates the evolution of a population of LLMs to improve performance on a given task. It uses LoRA for parameter efficiency.  It starts with an initial population created by combining weights of pre-trained \"expert\" LLMs.  It iteratively applies crossover (combining weights of two parent models), mutation (adding small random changes to weights), and selection (keeping the best-performing models) to evolve the population.\n\n**Algorithm 2: GENOME+**\n\n```javascript\nasync function genomePlus(task, fitnessFunction, expertModels, {\n  // ... same parameters as GENOME ...\n  learningWeight,\n  learningRate\n}) {\n  // Initialization (same as GENOME)\n  // ...\n\n  //Initialize experience vectors\n  let experienceVectors = Array(populationSize).fill(null).map(() => Array(population[0].length).fill(0)); // Assuming all individuals have same weights size\n\n  for (let iter = 1; iter <= maxIterations; iter++) {\n    // Crossover, Mutation (same as GENOME)\n     // ...\n\n    // Succession\n    const globalBest = bestIndividual;\n    const globalWorst =  population[fitnessScores.indexOf(Math.min(...fitnessScores))]\n    for (let i = 0; i < population.length; i++) {\n      const currentBest =  population[i]; // Simplified\n      experienceVectors[i] = updateExperience(experienceVectors[i], globalBest, currentBest, globalWorst, learningWeight);\n      population[i] = applyExperience(population[i], experienceVectors[i], learningRate); // Update weights based on experience\n\n        const individualFitness = await fitnessFunction(population[i], task);\n\n      population[i] = population[i];\n        fitnessScores[i] = individualFitness\n\n    }\n\n    // Selection (same as GENOME)\n    // ...\n  }\n\n  // Ensemble\n  //Sort indices based on fitness, and select top-k\n  const topKIndices = fitnessScores\n    .map((score, index) => ({score, index}))\n    .sort((a, b) => b.score - a.score)\n    .slice(0, 3) // top-3 for instance\n    .map(x => x.index);\n  const ensemble = topKIndices.map(i => population[i]);\n\n\n  return {bestIndividual, ensemble};\n}\n\nfunction updateExperience(e_i, e_g, e_c, e_w, lw){\n  //lw = learningWeight, which is actually four weights\n  const [phi_e, phi_g, phi_c, phi_w] = lw;\n  const c = phi_e + phi_g + phi_c + phi_w;\n  const updatedExperience = [];\n\n  for(let j = 0; j < e_i.length; j++){\n    updatedExperience.push(\n        (phi_e*e_i[j] + phi_g*(e_g[j] - e_i[j]) + phi_c*(e_c[j] - e_i[j]) - phi_w*(e_w[j] - e_i[j])) / c\n    )\n  }\n  return updatedExperience;\n}\n\nfunction applyExperience(weights, experience, learningRate) {\n  const updatedWeights = [...weights];\n  for(let i=0; i < updatedWeights.length; i++){\n    updatedWeights[i] += learningRate*experience[i];\n  }\n  return updatedWeights;\n}\n\n```\n\n\n\n* **Explanation:** GENOME+ extends GENOME by adding succession (learning from the best and worst individuals in the population's history) and ensemble (combining predictions of the top-k models). The succession mechanism uses \"experience vectors\" to store and transfer knowledge across generations. The ensemble component aims to achieve a more robust performance.\n\n**Key Improvements and Differences:**\n\n* **Succession:** GENOME+ introduces a knowledge transfer mechanism inspired by Particle Swarm Optimization, absent in GENOME. This helps individuals learn from the collective experience of the population.\n* **Ensemble:** GENOME+ uses an ensemble of top-performing models for prediction, leveraging collective intelligence. GENOME relies solely on the single best individual.\n* **Complexity:** GENOME+ is more complex due to the added succession and ensemble mechanisms.\n\nThese JavaScript implementations are simplified for demonstration. A real-world implementation would require integration with a specific LoRA library and proper management of LLM models and their weights, which are abstracted away here for clarity. Additionally, population replacement strategies during crossover and specific ensemble methods (like majority voting or similarity-based aggregation) would need to be chosen based on the specific application.",
  "simpleQuestion": "Can LLMs evolve via population-based methods?",
  "timestamp": "2025-03-10T06:10:31.815Z"
}