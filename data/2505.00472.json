{
  "arxivId": "2505.00472",
  "title": "USERCENTRIX: AN AGENTIC MEMORY-AUGMENTED AI FRAMEWORK FOR SMART SPACES",
  "abstract": "Agentic AI, with its autonomous and proactive decision-making, has transformed smart environments. By integrating Generative AI (GenAI) and multi-agent systems, modern AI frameworks can dynamically adapt to user preferences, optimize data management, and improve resource allocation. This paper introduces UserCentrix, an agentic memory-augmented AI framework designed to enhance smart spaces through dynamic, context-aware decision-making. This framework integrates personalized Large Language Model (LLM) agents that leverage user preferences and LLM memory management to deliver proactive and adaptive assistance. Furthermore, it incorporates a hybrid hierarchical control system, balancing centralized and distributed processing to optimize real-time responsiveness while maintaining global situational awareness. UserCentrix achieves resource-efficient AI interactions by embedding memory-augmented reasoning, cooperative agent negotiation, and adaptive orchestration strategies. Our key contributions include (i) a self-organizing framework with proactive scaling based on task urgency, (ii) a Value of Information (VoI)-driven decision-making process, (iii) a meta-reasoning personal LLM agent, and (iv) an intelligent multi-agent coordination system for seamless environment adaptation. Experimental results across various models confirm the effectiveness of our approach in enhancing response accuracy, system efficiency, and computational resource management in real-world application.",
  "summary": "This paper introduces UserCentrix, a framework for creating AI agents that manage smart spaces (like smart homes or offices).  It uses a hybrid approach, combining centralized and distributed control to balance responsiveness and thoroughness.\n\nKey points for LLM-based multi-agent systems:\n\n* **Personalized LLM Agents:**  UserCentrix utilizes personalized LLM agents on the user-side that learn preferences and use memory to automate tasks.\n* **Memory-Augmented Meta-Reasoning:** Building-side agents use memory and \"thinking about thinking\" to optimize decisions and resource allocation.\n* **Hybrid Hierarchical Control:** Combines fast, less precise responses for urgent tasks with slower, more detailed responses for less urgent tasks.\n* **Value of Information (VoI):**  Uses VoI to guide decision-making, prioritizing what is most relevant to the user.\n* **Cooperative Reasoning Networks:** Low-level agents negotiate to avoid conflicts, ensuring diverse user requirements are met.\n* **Dynamic Task Management:**  Agents create time slices for tasks based on urgency and VoI, optimizing workflows and communication.\n* **Proactive Scaling:** The system dynamically scales computational resources according to the demands of the task.\n* **Environment Agent:** An environment agent tracks ongoing tasks and ensures the smart space's state aligns with user preferences.",
  "takeaways": "This paper presents UserCentrix, a sophisticated framework for building LLM-based multi-agent systems within smart spaces. Here's how a JavaScript developer can apply its concepts to their projects:\n\n**1. Personalized LLM Agents with Memory:**\n\n* **Concept:** UserCentrix emphasizes personalized user experiences through dedicated LLM agents that learn from past interactions and user preferences. This involves maintaining a memory store for each user.\n* **JavaScript Implementation:**\n    * Use a database (like MongoDB or IndexedDB) or server-side storage (like Redis) to persist user-specific data and interaction history.\n    * Employ LangChain.js to manage the interaction between the LLM (e.g., OpenAI, Cohere, or local models like Mistral.js) and the memory store.  LangChain's memory modules (like `ConversationBufferMemory`) can be adapted for this.\n    * Example:  When a user requests a room booking, the agent retrieves their past preferences (temperature, lighting) from the store and includes them in the prompt to the LLM.\n\n```javascript\n// Using LangChain.js and a hypothetical database\nimport { OpenAI } from \"langchain/llms/openai\";\nimport { ConversationChain } from \"langchain/chains\";\nimport { MongoDBChatMessageHistory } from \"langchain-mongodb\";\n\nconst llm = new OpenAI({ temperature: 0 }); // Choose your LLM\nconst history = new MongoDBChatMessageHistory({\n  sessionId: userId, // Unique identifier for the user\n  // ... database connection details\n});\nconst chain = new ConversationChain({ llm, memory: history });\n\nconst response = await chain.call({ input: userRequest });\n```\n\n**2. Hybrid Hierarchical Control System:**\n\n* **Concept:** UserCentrix uses a hybrid system combining centralized and distributed processing. High-urgency tasks are handled quickly by specialized agents, while low-urgency tasks allow for more complex reasoning and negotiation.\n* **JavaScript Implementation:**\n    * Use a message queue (like RabbitMQ, Kafka, or a simple in-memory queue) to distribute tasks to different agent types.\n    * Implement agent logic using separate JavaScript modules or classes.\n    * Example:  A \"high-urgency\" agent might handle immediate light adjustments, while a \"low-urgency\" agent manages more complex room booking scenarios involving negotiation with other agents (see below).\n\n```javascript\n// Simplified example using an in-memory queue\nconst taskQueue = [];\nconst highUrgencyAgent = { /* ...agent logic... */ };\nconst lowUrgencyAgent = { /* ...agent logic... */ };\n\n// Add a task to the queue\ntaskQueue.push({ type: \"high\", data: { /* ...task data */ } });\n\n// Process the queue\nconst task = taskQueue.shift();\nif (task.type === \"high\") {\n  highUrgencyAgent.process(task.data);\n} else {\n  lowUrgencyAgent.process(task.data);\n}\n```\n\n**3. Multi-Agent Negotiation and Cooperation:**\n\n* **Concept:** For complex tasks, multiple agents can cooperate by negotiating and sharing intermediate reasoning results. This prevents conflicts and improves overall solution quality.\n* **JavaScript Implementation:**\n    * Design a communication protocol between agents (e.g., using WebSockets or a shared database).\n    * Implement negotiation logic using algorithms like contract nets or auctions.\n    * Example: Multiple agents could negotiate available resources (rooms, equipment) during a complex meeting scheduling task.\n\n```javascript\n// Conceptual example using WebSockets\n// Agent A sends a proposal to Agent B\nsocketA.send(JSON.stringify({ type: \"proposal\", data: { /* ...proposal */ } }));\n\n// Agent B receives the proposal and responds\nsocketB.onmessage = (event) => {\n  const message = JSON.parse(event.data);\n  if (message.type === \"proposal\") {\n    // ... process proposal and send acceptance/rejection\n  }\n};\n```\n\n**4.  Dynamic Scaling and Resource Allocation:**\n\n* **Concept:** UserCentrix adapts its resource usage based on task demands, prioritizing speed for urgent tasks and accuracy for less time-sensitive ones.\n* **JavaScript Implementation:**\n    * Use serverless functions or container orchestration (like Kubernetes) to dynamically scale the number of active agents.\n    * Implement logic to allocate different inference time budgets (and potentially different LLMs) based on task urgency.\n    * Example:  For a simple light adjustment, a smaller, faster LLM could be used, while a more complex task could trigger the use of a larger LLM with a longer inference time budget.\n\n\n**5. Value of Information (VoI):**\n\n* **Concept:** Prioritize actions and resource allocation based on the expected value of the information gained.\n* **JavaScript Implementation:**\n    * Design heuristics or more formal VoI calculations to guide agent decisions.\n    * Example: An agent might choose to query a sensor for more information if the uncertainty about the environment's state is high and the cost of querying is low.\n\n\nBy combining these ideas with appropriate JavaScript frameworks and tools, developers can create more intelligent and adaptable web applications based on the principles outlined in the UserCentrix research.  Remember that many of the implementation details will depend on the specific requirements of your application. This requires careful consideration of your project's scale, available resources, and the complexity of the tasks you aim to automate.  This answer aims to provide a starting point for applying the research to practical scenarios.",
  "pseudocode": "The paper includes two pseudocode blocks describing algorithms. Here are their JavaScript conversions and explanations:\n\n**Algorithm 1: UserCentrix Decision-Making Module**\n\n```javascript\nasync function userCentrixDecisionMaking(userTasks, currentTime) {\n  let T = userTasks; // Assume userTasks is an array of objects, each with a deadline (D) and task details\n\n  for (let i = 0; i < T.length; i++) {\n    const Ti = T[i];\n    const classify = Ti.D - currentTime;\n\n    if (classify < 0) {\n      T.splice(i, 1); // Remove expired task\n      i--; // Adjust index after removal\n    } else if (classify > 2 * 3600) { // 2 hours threshold, convert to seconds if currentTime is in seconds\n      Ti.U = 0; // Low urgency\n      const lowUrgencyAgent = new LowUrgencyAgent(); // Assuming LowUrgencyAgent class exists\n      const MLow = await lowUrgencyAgent.recallMemory();\n      const Enew = await embed(\"all-MiniLM-L6-v2\", Ti.taskDetails); // Assuming embed function exists\n      const Epast = await embed(\"all-MiniLM-L6-v2\", MLow); \n      const similarity = calculateSimilarity(Enew, Epast); // Assuming calculateSimilarity function exists\n\n      let potentialSolutions;\n      if (similarity <= 0.7) {\n        potentialSolutions = await lowUrgencyAgent.generateSolutions(Ti.taskDetails);\n      } else {\n        const { solution: Ei, reason: Ri, factors: Fi } = await lowUrgencyAgent.retrieveSolution(MLow, Enew);\n        potentialSolutions = await lowUrgencyAgent.generateSolutions(Ti.taskDetails, Ei, Ri, Fi); //Incorporate past data\n      }\n\n\n      for (const solution of potentialSolutions) {\n        const semanticSimilarity = await calculateSemanticSimilarity(solution); // Assuming llama-index based function\n        const precision = calculatePrecision(solution, Ti.taskDetails); // Assuming calculatePrecision function exists based on TP, FP\n        const numCalls = solution.llmCalls.length;\n        const maxCalls = 10; // Or determine based on task. This is a hyperparameter.\n        const llmCost = 1 - Math.exp(-numCalls / maxCalls);\n        const paretoResult = await paretoOptimize(llmCost, semanticSimilarity, precision); // Assuming paretoOptimize function\n        const { solution: bestSolution, reason, factors} = await evaluatorAgent.evaluate(paretoResult); // Assuming evaluatorAgent class\n        await memoryModule.inject(bestSolution, reason, factors, Ti.taskDetails); // Assuming memoryModule class exists.\n      }\n\n\n    } else {\n      Ti.U = 1; // High urgency\n      const highUrgencyAgent = new HighUrgencyAgent(); // Assuming HighUrgencyAgent class exists.\n      const quickSolution = await highUrgencyAgent.generateQuickSolution(Ti.taskDetails);\n      // ... handle quickSolution as needed\n\n    }\n  }\n\n  return T;\n}\n```\n\n\n\n* **Purpose:** This algorithm forms the core decision-making logic of UserCentrix. It categorizes user tasks based on their urgency (high or low) relative to their deadline.  Low-urgency tasks trigger more complex reasoning, potentially leveraging past solutions from memory, while high-urgency tasks prioritize speed and generate quick solutions.\n\n\n* **Explanation:** The JavaScript code iterates through each user task. If a task's deadline has passed, it's removed. Low urgency tasks trigger the low-urgency agent, which tries to retrieve a past solution from memory if a similar one exists. If not, or if the similarity is below a threshold, it generates new potential solutions. These solutions are evaluated based on several criteria (semantic similarity, precision, and LLM call cost). A Pareto optimization then selects the best solution. High-urgency tasks, on the other hand, are processed by the high-urgency agent to produce a quick solution.\n\n\n**Algorithm 2: Sub-tasks Execution Module**\n\n\n\n```javascript\nasync function subTasksExecution(k, subTaskSolutions, dataset) {\n  const agents = [];\n  let commands = [];\n\n  // Generate Low-level agents\n  for (let i = 0; i < k; i++) {\n    agents.push(new LowLevelAgent(subTaskSolutions[i])); // Assuming LowLevelAgent class\n  }\n\n\n  for (let i = 0; i < agents.length; i++) {\n    const agent = agents[i];\n    const relevantData = dataset.filter(d => isCompatible(d, agent.subTask)); // Assuming isCompatible function exists\n    const command = await agent.execute(relevantData); // Assuming an execute method in LowLevelAgent\n    commands.push(command);\n  }\n\n  return commands;\n}\n\n```\n\n\n\n* **Purpose:** This algorithm manages the execution of sub-tasks generated by the decision-making module. It creates low-level agents for each sub-task and dispatches them to execute, generating commands for the smart building's control systems.\n\n\n* **Explanation:** The function creates `k` low-level agents, each responsible for one sub-task.  For each agent, it filters the dataset to find relevant data for its specific sub-task.  The agent then executes its sub-task using this data, producing a command. The function collects all commands and returns them.\n\n\n\nNo pseudocode was found for the environment agent.  The prompt given for the environment agent dictates its behavior.",
  "simpleQuestion": "How can LLMs build smart-space agents?",
  "timestamp": "2025-05-02T05:04:39.098Z"
}