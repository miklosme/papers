{
  "arxivId": "2410.13757",
  "title": "MobA: A Two-Level Agent System for Efficient Mobile Task Automation",
  "abstract": "Current smart assistants on mobile phones are often limited by dependence on APIs of system and third-party applications. At the same time, model-based screen agents struggle with diverse interfaces and complex commands, due to restricted understanding and decision-making abilities. To address these challenges, we propose MOBA, a novel Mobile-phone Agent empowered by multimodal large language models that enhances comprehension and planning capabilities through a sophisticated two-level agent architecture. The high-level Global Agent (GA) interprets user commands, manages history, and plans tasks, while the low-level Local Agent (LA) executes precise actions as function calls based on sub-tasks and memories from GA. By incorporating a double-reflection mechanism, MOBA efficiently handles tasks, even those previously unseen. MOBA demonstrates significant improvements in task execution efficiency and completion rate in real-life evaluations, underscoring the potential of MLLM-empowered mobile assistants.",
  "summary": "This paper introduces MobA, a system that uses multiple AI agents to automate tasks on mobile phones. It focuses on using a two-level agent system driven by a large language model (LLM) to understand complex instructions and interact with mobile app interfaces. \n\nKey takeaways for LLM-based multi-agent systems:\n\n* **Two-Level Structure:**  MobA employs a \"Global Agent\" for high-level planning and a \"Local Agent\" for execution, similar to how the human brain delegates tasks. This makes the system more efficient and adaptable.\n* **Task Decomposition:** MobA breaks down complex instructions into smaller sub-tasks, enabling more robust and error-resistant execution.\n* **Memory and Reflection:** The system incorporates memory modules to learn from past experiences, and reflection mechanisms to analyze and correct mistakes during task execution. \n* **View Hierarchy Processing:** MobA utilizes the hierarchical structure of mobile app interfaces to better understand and interact with UI elements. This reduces reliance on purely visual processing and improves efficiency.",
  "takeaways": "This paper proposes MobA, a two-level AI agent system for mobile task automation powered by MLLMs (Multimodal Large Language Models). While MobA targets mobile app interactions, its core principles have great implications for JavaScript developers building LLM-based multi-agent systems for the web. Here's how:\n\n**1. Two-Level Agent Structure:**\n\n* **Concept:** MobA divides tasks between a high-level \"Global Agent\" responsible for planning and a low-level \"Local Agent\" for execution. \n* **JavaScript Application:**\n    * **Global Agent:**  A Node.js service running an LLM could act as the Global Agent. It receives high-level user requests (\"Book a flight to London\") and decomposes them into sub-tasks (\"Search flights,\" \"Select dates,\" \"Enter passenger details,\" etc.). This agent could leverage libraries like **Langchain.js** for LLM interaction and **Planner.js** for task decomposition.\n    * **Local Agent:** A browser-based JavaScript agent (using frameworks like **Puppeteer** or **Playwright**) could be the Local Agent, executing sub-tasks by interacting with web elements, filling forms, and navigating pages based on the Global Agent's instructions.\n\n**2. Task Planning and Execution Pipeline:**\n\n* **Concept:** MobA utilizes a robust pipeline involving task decomposition, feasibility checks, action generation, reflection, and result validation.\n* **JavaScript Application:**\n    * **Task Queues:** Use JavaScript task queues (e.g., **Bull**, **Bee-queue**) to manage sub-tasks generated by the Global Agent. The Local Agent picks up and executes these tasks sequentially.\n    * **Feasibility Checks:** Implement logic in your Local Agent to verify if actions are possible. For example, before clicking a button, ensure it's visible and enabled using DOM APIs.\n    * **Reflection:** After each sub-task, send feedback (success/failure, observations) to the Global Agent for reflection and potential course correction. This feedback loop can be implemented using WebSockets or server-sent events.\n\n**3. Multi-Aspect Memory:**\n\n* **Concept:** MobA employs a multi-aspect Memory Module to store task execution history, user preferences, and application information for informed decision-making.\n* **JavaScript Application:**\n    * **Databases:** Use databases (e.g., **MongoDB**, **PostgreSQL**) or in-memory stores like **Redis** to persist task execution history.\n    * **User Profiles:** Create user profiles to store preferences and frequently accessed information. This data can be used to personalize agent responses and provide proactive assistance.\n    * **Web Scraping:** Employ web scraping techniques (using libraries like **Cheerio**, **Puppeteer**) to extract relevant information from web pages and update the App Memory. \n\n**4. JavaScript Frameworks and Libraries:**\n\n* **Langchain.js:** Enables seamless integration with various LLMs for natural language understanding and generation.\n* **Puppeteer, Playwright:** Provide powerful browser automation capabilities for the Local Agent to interact with web pages.\n* **Express.js, Socket.IO:**  Suitable for building APIs and real-time communication channels between agents. \n\n**Example Scenario:** Imagine building a multi-agent system for automating online shopping:\n\n1. **User Request:** \"Order a black t-shirt from my favorite store.\"\n2. **Global Agent:** Decomposes the task, identifies the store from user history, and generates sub-tasks: \"Navigate to the store,\" \"Search for 'black t-shirt',\" \"Select size,\" \"Add to cart,\" \"Checkout.\"\n3. **Local Agent:** Executes sub-tasks using browser automation (Puppeteer), interacting with the website to perform the actions. \n4. **Reflection:** After each sub-task, the Local Agent sends feedback to the Global Agent. If the \"Search for 'black t-shirt'\" fails, the Global Agent might reflect and generate a new sub-task, \"Refine search.\"\n5. **Memory:** The system remembers the user's purchase history for future recommendations and faster checkout.\n\n**By applying these concepts, JavaScript developers can build sophisticated LLM-based multi-agent systems for web development, enabling a new generation of intelligent web applications.**",
  "pseudocode": "```javascript\nfunction processViewHierarchy(xml) {\n  // 1. Parse UI elements and sort by area\n  let elements = xml.getElementsByTagName('*'); // Assuming basic XML parsing\n  elements.sort((a, b) => getElementArea(a) - getElementArea(b));\n\n  let selectedElements = [];\n\n  // 2. Filter interactive elements and handle overlap\n  for (let element of elements) {\n    if (isElementInteractive(element)) {\n      let isValid = true;\n      for (let selectedElement of selectedElements) {\n        if (calculateOverlapArea(element, selectedElement) > OVERLAP_THRESHOLD) {\n          isValid = false;\n          break;\n        }\n      }\n      if (isValid) {\n        selectedElements.push(element);\n      }\n    }\n  }\n\n  // 3. Merge text into interactive elements\n  for (let element of elements) {\n    for (let selectedElement of selectedElements) {\n      if (isElementContained(element, selectedElement) && element.textContent) {\n        selectedElement.textContent += ' ' + element.textContent; // Assuming simple merging\n      }\n    }\n  }\n\n  // 4. Sort and assign index\n  selectedElements.sort((a, b) => a.offsetTop - b.offsetTop || a.offsetLeft - b.offsetLeft);\n  for (let i = 0; i < selectedElements.length; i++) {\n    selectedElements[i].index = i + 1; // Assign index starting from 1\n  }\n\n  return selectedElements;\n}\n\n// Helper functions (not shown but assumed to be implemented)\nfunction getElementArea(element) {}\nfunction isElementInteractive(element) {}\nfunction calculateOverlapArea(element1, element2) {}\nfunction isElementContained(element1, element2) {}\n```\n\n**Explanation:**\n\nThis JavaScript code represents the View-Hierarchy Processing algorithm described in the paper. The algorithm aims to simplify the raw view hierarchy (VH) data extracted from the mobile interface's XML file, making it easier for the LLM-based agent to understand and interact with the interface.\n\n**Purpose:**\n\n* **Reduce Redundancy:** Mobile interface XMLs often contain a large amount of information irrelevant to user interaction. This algorithm filters out non-interactive elements and unnecessary attributes, reducing the data size and complexity.\n* **Highlight Interactive Elements:** By focusing on interactive elements (clickable buttons, input fields, etc.), the algorithm helps the agent identify targetable elements for interaction.\n* **Enhance Textual Information:**  The algorithm merges text content into associated interactive elements when appropriate. This provides more context to the agent, making it easier to understand the purpose and action associated with each element.\n* **Logical Ordering:** The final sorting of elements based on their coordinates (left-to-right, top-to-bottom) mimics the natural visual scanning behavior of users, allowing the agent to process elements in a human-like manner.\n\n**Key Steps:**\n\n1. **Parse and Sort:** Parse UI elements from the XML and sort them by their visual area, prioritizing larger elements.\n2. **Filter and Handle Overlap:**  Select only interactive elements, ensuring minimal overlap between selected elements to avoid ambiguity.\n3. **Merge Text Content:** Combine relevant text content into the bounding box of the associated interactive element.\n4. **Sort and Index:** Sort the final set of interactive elements based on their position and assign an index to each, facilitating easier referencing.\n\nBy applying this pre-processing step, the agent receives a simplified and enriched representation of the mobile interface, improving its efficiency in understanding the screen structure and making decisions for task execution.",
  "simpleQuestion": "Can LLMs automate mobile tasks efficiently?",
  "timestamp": "2024-10-18T05:01:45.868Z"
}