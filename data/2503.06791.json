{
  "arxivId": "2503.06791",
  "title": "AutoMisty: A Multi-Agent LLM Framework for Automated Code Generation in the Misty Social Robot",
  "abstract": "Abstract-The social robot's open API allows users to customize open-domain interactions. However, it remains inaccessible to those without programming experience. In this work, we introduce AutoMisty, the first multi-agent collaboration framework powered by large language models (LLMs), to enable the seamless generation of executable Misty robot code from natural language instructions. AutoMisty incorporates four specialized agent modules to manage task decomposition, assignment, problem-solving, and result synthesis. Each agent incorporates a two-layer optimization mechanism, with self-reflection for iterative refinement and human-in-the-loop for better alignment with user preferences. AutoMisty ensures a transparent reasoning process, allowing users to iteratively refine tasks through natural language feedback for precise execution. To evaluate AutoMisty's effectiveness, we designed a benchmark task set spanning four levels of complexity and conducted experiments in a real Misty robot environment. Extensive evaluations demonstrate that AutoMisty not only consistently generates high-quality code but also enables precise code control, significantly outperforming direct reasoning with ChatGPT-40 and ChatGPT-01. All code, optimized APIs, and experimental videos will be publicly released through the webpage: AutoMisty.",
  "summary": "AutoMisty simplifies programming social robots like Misty for non-programmers using natural language instructions. It leverages a multi-agent LLM system where specialized agents handle tasks like planning, actions, touch, and audiovisual processing.  A two-layer optimization with self-reflection and human feedback ensures code quality and user alignment. Optimized APIs improve LLM understanding, and memory enhances learning from past interactions.  Benchmark tests show AutoMisty outperforms direct prompting of LLMs like ChatGPT in complex robot tasks.",
  "takeaways": "This paper introduces AutoMisty, a multi-agent LLM framework for generating robot control code from natural language. While the paper focuses on robotics, its core concepts, especially the multi-agent architecture and optimization mechanisms, are highly relevant to web development involving LLMs.  Here's how a JavaScript developer can apply these insights:\n\n**1. Multi-Agent Architecture for Complex Web Apps:**\n\n* **Scenario:** Imagine building a web app for generating marketing copy.  Instead of a monolithic LLM, you could implement specialized agents: a \"Planner\" agent to decompose the user's request (e.g., \"Write a blog post about our new product\"), a \"Researcher\" agent to gather information, a \"Writer\" agent to draft the copy, and an \"Editor\" agent to refine and optimize the output.\n\n* **Implementation:**  Use a message-passing system (e.g., a simple event emitter library or a more robust solution like LangChain) to coordinate communication between agents, each implemented as a JavaScript function or class interacting with an LLM API.\n\n```javascript\n// Simplified example using Node.js EventEmitter\nconst EventEmitter = require('events');\nconst myEmitter = new EventEmitter();\n\n// Agent functions (simplified)\nconst planner = (task) => { /* ... */ myEmitter.emit('planReady', subtasks); };\nconst researcher = (subtasks) => { /* ... */ myEmitter.emit('researchDone', data); };\n// ... other agents\n\n// Event handling for inter-agent communication\nmyEmitter.on('planReady', researcher); \n// ... chain other agents\n\n// Start the process\nplanner('Write marketing copy about X');\n```\n\n**2. Two-Layer Optimization for Improved Output:**\n\n* **Scenario:** In a web app that generates code snippets (e.g., for React components), you can implement the two-layer optimization. Layer 1 (self-reflection) could involve a \"Critic\" agent that checks the generated code for syntax errors, best practices, or adherence to specific coding styles using libraries like ESLint. Layer 2 (human-in-the-loop) allows the user to review and provide feedback, which is then fed back to the \"Generator\" agent for refinement.\n\n* **Implementation:** Integrate a code analysis library (like ESLint) within the \"Critic\" agent's logic. For the human-in-the-loop part, build a user interface for feedback submission and use this input to re-prompt the LLM for improved code generation.\n\n**3. Optimized APIs for LLM Interaction:**\n\n* **Scenario:**  When building a chatbot using LLMs, instead of directly using the raw LLM API, create wrapper functions (optimized APIs) in JavaScript.  These wrappers can provide context, handle error cases, format requests, and manage prompt engineering more effectively.  This is analogous to how AutoMisty optimizes the Misty Robot's APIs for LLM consumption.\n\n* **Implementation:** Create JavaScript functions that encapsulate the LLM interaction logic.  These functions can be tailored to specific tasks or functionalities within your web app, improving the clarity and efficiency of LLM usage.  LangChain's tools and chains can be helpful here.\n\n**4.  Memory for Context and Learning:**\n\n* **Scenario:** In an interactive storytelling web app,  implementing \"memory\" allows the LLM to maintain character consistency and plot coherence across user interactions. Store previous user choices, story elements, and generated text in a database or in-memory store.  This allows the LLM to build upon past interactions.\n\n* **Implementation:** Leverage browser local storage, session storage, or a server-side database to store the conversation history. Pass this context as part of the LLM prompt in subsequent interactions.\n\n**JavaScript Libraries and Frameworks:**\n\n* **LangChain:**  Excellent for building chains of agents, managing prompts, and handling interactions with various LLM APIs.\n* **Node.js EventEmitter:** Simple and effective for basic inter-agent communication.\n* **ESLint:**  Useful for static code analysis in \"Critic\" agents.\n* **React, Vue, or Angular:** For building the front-end UI for human-in-the-loop feedback and visualization.\n\nBy adopting these practices, JavaScript developers can create more sophisticated, robust, and user-friendly web applications that harness the power of LLMs in a multi-agent paradigm, much like AutoMisty leverages LLMs for complex robotic control.  The key takeaway is to move from monolithic LLM interactions to a more modular, agent-based architecture with optimized communication and feedback mechanisms.",
  "pseudocode": "No pseudocode block found. However, several mathematical formulations describe processes within the AutoMisty framework. These formulations could be represented in JavaScript as functions, but they are not presented in a traditional pseudocode format within the paper.  Here's how some of those could be conceptually translated:\n\n**1. Task Decomposition and Agent Assignment:**\n\nThe mapping of subtasks to agents, represented as Φ:{T₁, ..., Tₖ} → A, can be implemented as a JavaScript function that takes an array of subtasks and returns an array of assigned agents.  The specific implementation would depend on the criteria for assigning agents to tasks (e.g., skill matching, resource availability).\n\n```javascript\nfunction assignAgentsToTasks(tasks, agents) {\n  const assignments = [];\n  // Implement logic to assign agents to tasks based on skills/resources\n  for (const task of tasks) {\n    const assignedAgent = findBestAgentForTask(task, agents);\n    assignments.push({ task, agent: assignedAgent });\n  }\n  return assignments;\n}\n\nfunction findBestAgentForTask(task, agents) {\n // Example logic: Find the agent with the highest skill level for the task\n let bestAgent = null;\n let highestSkill = -1;\n for (const agent of agents) {\n   const skillLevel = agent.skills[task.requiredSkill] || 0; // Access skill level or default to 0\n   if (skillLevel > highestSkill) {\n     highestSkill = skillLevel;\n     bestAgent = agent;\n   }\n }\n return bestAgent;\n}\n\n\n```\n\n**2. Execution Sequence Determination:**\n\nThe topological sort, π(G) = (Aᵢ₁, Aᵢ₂, ..., Aᵢₘ), can be implemented using a standard topological sorting algorithm in JavaScript.  This would take the dependency graph `G` (represented as an adjacency list or matrix) and return an ordered array of agents representing the execution sequence.\n\n```javascript\nfunction topologicalSort(graph) {\n  const numNodes = graph.length;\n  const inDegree = Array(numNodes).fill(0);\n  const queue = [];\n  const result = [];\n\n  for (let i = 0; i < numNodes; i++) {\n    for (const neighbor of graph[i]) {\n      inDegree[neighbor]++;\n    }\n  }\n\n  for (let i = 0; i < numNodes; i++) {\n    if (inDegree[i] === 0) {\n      queue.push(i);\n    }\n  }\n\n  while (queue.length > 0) {\n    const node = queue.shift();\n    result.push(node);\n\n    for (const neighbor of graph[node]) {\n      inDegree[neighbor]--;\n      if (inDegree[neighbor] === 0) {\n        queue.push(neighbor);\n      }\n    }\n  }\n\n  return result;\n}\n\n// Example graph representation (adjacency list)\nconst graph = [\n  [1, 2], // Node 0 depends on nodes 1 and 2\n  [],    // Node 1 has no dependencies\n  [1],   // Node 2 depends on node 1\n];\n\nconst sortedNodes = topologicalSort(graph);\nconsole.log(sortedNodes); // Output: [1, 2, 0]\n\n\n```\n\n**3. Code Generation:**\n\nThe code generation function, Γ(Aᵢₖ | Δ(Aᵢₖ)) = Cᵢₖ, can be represented as a JavaScript function that takes an agent and its input conditions (previous code/context) as arguments and returns the generated code. This would likely involve calling the LLM API and potentially using other logic related to code formatting and API utilization.\n\n```javascript\nasync function generateCode(agent, inputConditions) {\n  const prompt = constructPrompt(agent, inputConditions);\n  const response = await callLLM(prompt);\n  const generatedCode = extractCodeFromResponse(response);\n  return generatedCode;\n}\n\n```\n\nThese JavaScript snippets provide a high-level illustration of how the mathematical formulations in the paper can be conceptually translated into functional code. The actual implementations within the AutoMisty framework would be significantly more complex, involving interactions with the LLM, Misty's API, and the multi-agent coordination logic.  However, these examples provide a starting point for JavaScript developers to grasp the core algorithmic ideas.",
  "simpleQuestion": "Can LLMs build robot code from natural language?",
  "timestamp": "2025-03-11T06:02:31.094Z"
}