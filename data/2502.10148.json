{
  "arxivId": "2502.10148",
  "title": "Cooperative Multi-Agent Planning with Adaptive Skill Synthesis",
  "abstract": "Despite much progress in training distributed artificial intelligence (AI), building cooperative multi-agent systems with multi-agent reinforcement learning (MARL) faces challenges in sample efficiency, interpretability, and transferability. Unlike traditional learning-based methods that require extensive interaction with the environment, large language models (LLMs) demonstrate remarkable capabilities in zero-shot planning and complex reasoning. However, existing LLM-based approaches heavily rely on text-based observations and struggle with the non-Markovian nature of multi-agent interactions under partial observability. We present COMPASS, a novel multi-agent architecture that integrates vision-language models (VLMs) with a dynamic skill library and structured communication for decentralized closed-loop decision-making. The skill library, bootstrapped from demonstrations, evolves via planner-guided tasks to enable adaptive strategies. COMPASS propagates entity information through multi-hop communication under partial observability. Evaluations on the improved StarCraft Multi-Agent Challenge (SMACv2) demonstrate COMPASS achieves up to 30% higher win rates than state-of-the-art MARL algorithms in symmetric scenarios.",
  "summary": "This paper introduces COMPASS, a novel framework for building cooperative multi-agent systems, particularly suited for complex, partially observable environments like StarCraft II's SMACv2.  COMPASS utilizes Vision-Language Models (VLMs) to enable agents to perceive visual and textual information, reason about tasks, reflect on past actions, and select appropriate actions.\n\n\nKey points for LLM-based multi-agent systems:\n\n* **Closed-loop planning:**  COMPASS operates in a closed-loop fashion, incorporating environmental feedback for dynamic adaptation and skill refinement, addressing the limitations of open-loop LLM-agent systems.\n* **Dynamic skill synthesis:**  A dynamic skill library, initialized with demonstrations and expanded via VLM-generated code, allows for adaptable and interpretable agent behavior, moving beyond predefined action spaces.\n* **Structured communication:**  COMPASS employs a structured, entity-based communication protocol to facilitate efficient information sharing among agents under partial observability, mitigating the risks of hallucination and irrelevant information exchange common in unstructured communication.\n* **Code as policy:** VLMs generate Python code representing agent actions, allowing for complex and adaptable behaviors.\n* **Integration of perception, reasoning, and reflection:** The modular architecture incorporating these cognitive components demonstrates a more sophisticated approach to LLM-based agent decision-making.\n* **Performance on SMACv2:**  Evaluations showcase COMPASS's ability to outperform traditional MARL algorithms in specific scenarios, especially those involving the Protoss race, demonstrating the potential of VLM-based agents in complex multi-agent environments.",
  "takeaways": "This paper presents COMPASS, a multi-agent architecture utilizing VLMs for planning and dynamic skill synthesis. Here's how JavaScript developers can apply these concepts to web development:\n\n**1. Decentralized, Closed-Loop LLM Agents in Browser Games:**\n\nImagine building a browser-based strategy game using JavaScript and a framework like Phaser. Each unit in the game could be controlled by a decentralized LLM agent running in the browser.  Using a JavaScript implementation of a lightweight VLM (or by offloading visual processing to a server and sending text-based observations to a cloud-based LLM), each agent can perceive its local game state. Instead of hard-coded actions, agents use an evolving skill library of JavaScript functions.  A simple initial skill set might include \"moveTowards(target)\", \"attack(target)\", and \"flee(threat)\".  These skills are stored as JavaScript code snippets within each agentâ€™s local storage or IndexedDB, indexed by their text descriptions (\"move towards a location\", \"attack a target\", etc.).  The VLM generates JavaScript code for new skills based on the game state and sub-tasks determined by the planner, adding them to the skill library.\n\n**2. Collaborative Web Design using Multi-Agent LLMs:**\n\nConsider a web design tool where multiple LLMs collaborate to build a website. One agent might specialize in layout, another in content creation, and another in styling. Each agent uses a VLM (or a server-assisted LLM as described earlier) to perceive the current state of the website (represented as a DOM or a JSON structure) and suggests modifications.  Skills could be JavaScript functions that manipulate the DOM, like \"addSection(content)\", \"styleElement(styles)\", or \"optimizeLayout()\".  A centralized communication system (using a Node.js server and WebSockets, for example) facilitates information sharing among the agents, enabling them to coordinate their actions and avoid conflicts.  The agents can build new skills by composing existing JavaScript DOM manipulation functions in novel ways.\n\n**3. Multi-Agent Customer Support Chatbots:**\n\nSeveral customer support chatbots can be deployed on a website, each specializing in a different aspect of product support.  These agents use natural language processing (NLP) and VLMs (or server-based LLMs using rendered HTML snapshots as input) to understand the website and user queries.  The \"skill library\" here becomes a set of JavaScript functions that perform actions like \"searchKnowledgeBase(query)\", \"redirectUser(url)\", or \"escalateToHumanAgent()\".   Multi-hop communication via a central server allows agents to share information and route users to the most appropriate chatbot.  LLMs can dynamically create new support actions as JavaScript code based on learned user interactions, constantly refining the available support functions.\n\n**4. Adaptive User Interfaces with Multi-Agent LLMs:**\n\nA multi-agent system could drive personalized user interfaces in web applications.  Each agent focuses on optimizing a specific aspect of the UI, like layout, content recommendations, or accessibility.  VLMs (or server-based LLMs as before) perceive the current UI state and user interactions.  Skills could be JavaScript functions that modify the UI, such as \"rearrangeElements()\", \"recommendContent(interests)\", or \"adjustFontSizes()\".  The system can introduce new UI modification functions, again as JavaScript code, based on user preferences and observed interactions.\n\n**JavaScript Frameworks and Libraries:**\n\n* **TensorFlow.js:** For running lightweight VLMs client-side.\n* **Web Workers:** For running LLM agents in the background without blocking the UI.\n* **WebSockets:** For real-time communication between agents and a central server.\n* **IndexedDB or LocalStorage:** For storing and retrieving agent skills as JavaScript code.\n* **LangChain.js:** For interfacing with cloud-based LLMs.\n* **Phaser, Babylon.js:** For developing browser games with multi-agent control.\n* **React, Vue, Angular:** For creating dynamic and adaptive user interfaces driven by multi-agent LLMs.\n\n\nBy combining these concepts and tools, JavaScript developers can build sophisticated LLM-based multi-agent systems for a range of web applications.  The dynamic skill synthesis approach enables continuous learning and adaptation, making these systems highly flexible and robust.  The focus on decentralized, closed-loop control makes them scalable and responsive to dynamic web environments.",
  "pseudocode": "The provided research paper does contain pseudocode blocks presented as Python code snippets illustrating skills for agents in the StarCraft II SMACv2 environment.  I've translated these snippets into JavaScript, along with explanations.\n\n**1. Focus Fire Logic (Figure 4a)**\n\n```javascript\nfunction score_target(unit, obs_data) {\n  let score = base_priority; // Assume base_priority is defined elsewhere\n  const num_attackers = obs_data.allies.reduce((count, ally) => {\n    if (ally.last_action >= 6 && ally.last_action - 6 === unit.id) {\n      return count + 1;\n    }\n    return count;\n  }, 0);\n\n  if (num_attackers > 0) {\n    const focus_bonus = Math.pow(1.2, num_attackers);\n    score *= focus_bonus;\n  }\n  return score;\n}\n```\n\n* **Explanation:** This function prioritizes enemy units for targeting.  `obs_data` contains information about allies and enemies. It calculates a `focus_bonus` based on the number of allied units already attacking the given `unit`.  More attackers lead to a higher bonus, encouraging focused fire.\n\n**2. Kitting Logic (Figure 5d)**\n\n```javascript\nfunction control_logic(obs_data) {\n    const closest_enemy = // ...  (Assume this is retrieved based on proximity from obs_data)\n\n  if (closest_enemy.distance <= 4 / obs_data.own_sight_range && obs_data.last_action >= 6) {\n    const enemy_x = obs_data.enemies.reduce((sum, e) => sum + e.position[0], 0) / obs_data.enemies.length;\n    const enemy_y = obs_data.enemies.reduce((sum, e) => sum + e.position[1], 0) / obs_data.enemies.length;\n    return find_path(obs_data, enemy_x, enemy_y); // find_path is a helper function for navigation\n  }\n}\n\n```\n\n* **Explanation:** This \"kitting\" logic is a tactical retreat maneuver.  If an enemy is close and the last action was an attack, the agent calculates the average enemy position and calls `find_path` to move away while maintaining attack range.\n\n\n**3.  Area-of-Effect (AOE) Optimization (Figure 7a)**\n\n```javascript\nfunction control_logic(obs_data) {\n  const enemy_clusters = {};\n  for (const enemy of obs_data.enemies) {\n    const nearby_enemies = [];\n    const cluster_radius = obs_data.own_unit_type.toLowerCase() === 'baneling' ? 0.3 : 0.2;\n\n    for (const other of obs_data.enemies) {\n      const distance = Math.sqrt(Math.pow(other.position[0] - enemy.position[0], 2) + Math.pow(other.position[1] - enemy.position[1], 2));\n      if (distance <= cluster_radius) {\n        nearby_enemies.push(other);\n      }\n    }\n    enemy_clusters[enemy.id] = nearby_enemies.length;\n  }\n  // ... use enemy_clusters to decide where to detonate for maximum AOE damage\n}\n\n```\n\n* **Explanation:** This code snippet clusters enemies based on proximity.  The `cluster_radius` is dynamically adjusted based on the unit type (`baneling` units having a larger radius). The cluster information (`enemy_clusters`) is then used to find optimal detonation points for maximum area-of-effect damage.\n\n\n**4.  Enhanced Target Scoring and Control Logic (Listing 1, pages 17-29)**\n\nThis extensive code block combines and refines the previous logic with more complex unit-specific behaviors, dynamic target prioritization based on unit type, health, distance, and improved formation control. It's a more comprehensive implementation of tactical decision-making for various unit types in SMACv2. Due to the length, I've provided a summary of the key improvements:\n\n* **Refined Unit Priorities:** A dictionary `unit_priorities` assigns different base priorities to each unit type for target selection.\n\n* **Dynamic Matchup Priorities:** A dictionary `unit_counters` implements dynamic counter weights based on unit matchups to account for unit strengths and weaknesses.\n\n* **Enhanced Threat Assessment:**  Improves melee combat handling.\n\n* **Improved Support Priority:** Prioritizes healing of low-health units.\n\n* **Improved Focus Fire Logic:** Enhanced focus fire with stronger target commitment and prevention of overcommitment.\n\n\n* **Improved Combat Advantage Factor:**  Adjusts aggressiveness based on power advantage.\n\n* **Enhanced Position Analysis:** Improves unit spacing and formation control.\n\n* **Enhanced Cluster Detection:** Dynamic cluster radius calculation and cluster bonus for splash damage.\n\n* **Kitting and Formation Logic:** Includes kitting logic for ranged units and formation logic for melee units.\n\nThis final code block demonstrates how all the individual skill pieces come together to create a more sophisticated agent behavior. The use of helper functions like `find_path`, `calculate_combat_power`, `attack`, `heal` etc., are assumed but not explicitly defined in the paper.  They represent lower-level actions that would need to be implemented in a full SMACv2 agent.\n\n\nThese JavaScript translations and explanations should provide a more concrete understanding of the code-based behaviors used by the COMPASS multi-agent system. Remember to adapt these snippets to your specific JavaScript framework and SMACv2 implementation.",
  "simpleQuestion": "Can LLMs improve multi-agent planning efficiency?",
  "timestamp": "2025-02-17T06:05:46.227Z"
}