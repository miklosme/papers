{
  "arxivId": "2411.07362",
  "title": "Factorised Active Inference for Strategic Multi-Agent Interactions",
  "abstract": "Understanding how individual agents make strategic decisions within collectives is important for advancing fields as diverse as economics, neuroscience, and multi-agent systems. Two complementary approaches can be integrated to this end. The Active Inference framework (AIF) describes how agents employ a generative model to adapt their beliefs about and behaviour within their environment. Game theory formalises strategic interactions between agents with potentially competing objectives. To bridge the gap between the two, we propose a factorisation of the generative model whereby each agent maintains explicit, individual-level beliefs about the internal states of other agents, and uses them for strategic planning in a joint context. We apply our model to iterated general-sum games with 2 and 3 players, and study the ensemble effects of game transitions, where the agents' preferences (game payoffs) change over time. This non-stationarity, beyond that caused by reciprocal adaptation, reflects a more naturalistic environment in which agents need to adapt to changing social contexts. Finally, we present a dynamical analysis of key AIF quantities: the variational free energy (VFE) and the expected free energy (EFE) from numerical simulation data. The ensemble-level EFE allows us to characterise the basins of attraction of games with multiple Nash Equilibria under different conditions, and we find that it is not necessarily minimised at the aggregate level. By integrating AIF and game theory, we can gain deeper insights into how intelligent collectives emerge, learn, and optimise their actions in dynamic environments, both cooperative and non-cooperative.",
  "summary": "This paper proposes a new way to model how multiple AI agents interact strategically, using a framework called Active Inference (AIF).  Instead of assuming agents have perfect knowledge of each other, each agent maintains individual beliefs about the other agents' hidden \"mental states\" and preferences, updating these beliefs as the game unfolds. This factored approach makes the model more aligned with game theory principles. The researchers apply this model to iterated games and show how it can track shifts in agent behavior during game transitions where payoffs change, highlighting how equilibrium states are reached.\n\nKey points relevant to LLM-based multi-agent systems:\n* **Factorised beliefs:** Agents maintain individual beliefs about others' hidden states, mirroring how LLMs could model other agents' intentions and strategies.\n* **Adaptive behavior:** Agents adapt their actions based on observed behavior and updated beliefs, relevant for building responsive and adaptive LLM agents.\n* **Strategic uncertainty:** Agents don't know other agents' payoff functions, reflecting realistic multi-agent scenarios where LLMs might need to infer goals and preferences.\n* **Equilibrium selection:** The model shows how agents converge to different equilibrium states under varying conditions, useful for analyzing and designing stable multi-agent LLM systems.\n* **Game transitions:** The model handles dynamic environments where game rules change, offering insights for developing robust LLM agents in non-stationary scenarios.\n* **Joint context:**  While maintaining factorized beliefs, the model integrates these into a joint interaction context defined by the overall game payoff function, which is important for coordinating the actions of LLM-based multi-agents working toward a common objective.",
  "takeaways": "This paper presents a compelling approach to multi-agent AI interactions using a factorized Active Inference (AIF) model, which has practical implications for JavaScript developers working with LLM-based multi-agent systems. Here are some practical examples applied to web development scenarios:\n\n**1. Collaborative Content Creation:**\n\nImagine building a collaborative writing platform where multiple LLM agents assist users in real-time. Each agent could specialize in different aspects of writing (e.g., grammar, style, tone). The factorized AIF model allows each LLM agent to maintain individual beliefs about the other agents' \"internal states\" (e.g., writing style preferences, current focus). This can be implemented using a message-passing system (e.g., Socket.IO) where agents exchange information about their beliefs and intentions. Each agent can be a separate Node.js process, with inter-process communication managed by libraries like `cluster` or `worker_threads`. The shared context (the evolving document) can be represented in a shared data structure (e.g., using a collaborative editor library like ProseMirror or CKEditor 5). The EFE calculation (using TensorFlow.js or WebDNN) influences each agent's contribution, ensuring coherent and collaborative output.\n\n**2. Multi-Agent Chatbots for Customer Service:**\n\nConsider a scenario with multiple specialized chatbot agents handling different customer queries. A \"triage\" agent could initially assess user needs and delegate the conversation to a specialized agent (e.g., billing, technical support).  The factorized AIF allows the triage agent to maintain beliefs about the expertise and availability of other agents, making efficient delegation decisions.  You could use a JavaScript framework like React or Vue.js to manage the UI and handle communication between the chatbots and the user. Each agent can be backed by a different LLM fine-tuned for its specific domain.  The agents' belief updates can be managed using a central state store (e.g., Redux, Vuex) reflecting agent availability and expertise. The EFE calculation would guide the triage bot's decision-making process, balancing information gain (salience) with achieving the desired outcome (pragmatic value, e.g., directing the user to the correct agent).\n\n**3. Decentralized Autonomous Organizations (DAOs):**\n\nLLM-powered agents can participate in DAO governance, voting on proposals and executing actions. Using the factorized AIF model, each agent could represent a different stakeholder group (e.g., developers, investors, users), holding different beliefs and preferences about the DAO's future. AIF enables agents to adapt their voting strategies based on observed actions and inferred beliefs of other agents, fostering better collective decision-making. The agents' beliefs can be stored and updated in a distributed database (e.g., IPFS, GunDB), promoting transparency and decentralization.  The EFE calculation, considering both individual preferences and collective outcomes, can inform each agent's voting decisions, promoting cooperation and alignment within the DAO.\n\n**4. In-Game AI:**\n\nIn multi-player online games, AIF-powered agents could control non-player characters (NPCs) or provide personalized assistance to players.  Each agent can maintain beliefs about other players and adapt its behavior based on observed actions and game context. A JavaScript game engine (e.g., Phaser, Babylon.js) could integrate LLM-based agents, allowing for dynamic and adaptive gameplay. Each agent's internal model can be represented as a JavaScript object, with belief updates implemented using functions operating on this object.  The EFE guides agent actions, balancing exploration (learning about other players) and exploitation (achieving in-game objectives).\n\n**Key JavaScript Technologies:**\n\n* **LLM APIs:** OpenAI, Hugging Face, Cohere, etc., to power the agents' language capabilities.\n* **Frontend Frameworks:** React, Vue.js, Angular, to manage UI and user interaction.\n* **Backend Frameworks:** Node.js, Express.js, to handle server-side logic and communication.\n* **State Management Libraries:** Redux, Vuex, MobX, to manage shared state and beliefs.\n* **Message Passing:** Socket.IO, WebSockets, for real-time communication between agents.\n* **Numerical Computation:** TensorFlow.js, WebDNN, for efficient EFE calculations.\n\nBy implementing these examples using JavaScript and relevant frameworks, developers can bridge the gap between theory and practice, bringing the power of multi-agent AIF to the forefront of web development.  These examples inspire further exploration, leveraging AIF's potential to build truly intelligent and interactive web applications.",
  "pseudocode": "No pseudocode block found. However, the paper describes mathematical formulations and processes that could be implemented as JavaScript algorithms.  While not pseudocode, these formulations lend themselves to JavaScript implementation.  Here are some key parts and how they could be translated into JavaScript code:\n\n**1. Variational Free Energy (VFE) Calculation (Equation 4b):**\n\nThis equation calculates the VFE, a measure of surprise, using Monte Carlo sampling.\n\n```javascript\nfunction calculateVFE(observations, prior, posteriorSamples) {\n  let vfeSum = 0;\n  for (const posteriorSample of posteriorSamples) {\n    let vfeSample = 0;\n    // Note: Assuming discrete states and observations\n    for (const state in prior) { // Iterate through all possible states.\n      const likelihood = likelihoodModel[state][observations] || 0; // Access likelihood from precomputed likelihood model. Handle 0 likelihood\n      const priorProb = prior[state];\n      const posteriorProb = posteriorSample[state];\n      if (posteriorProb > 0 && likelihood > 0) {  // Prevent log(0) errors\n         vfeSample -= posteriorProb * (Math.log(likelihood) + Math.log(priorProb) - Math.log(posteriorProb));\n      } \n    }\n    vfeSum += vfeSample;\n  }\n\n  return vfeSum / posteriorSamples.length;\n}\n\n\n// Example usage (assuming Dirichlet distributions):\nconst numSamples = 1000; //number of MC samples.\nconst posteriorSamples = [];\nfor (let i = 0; i < numSamples; i++) {\n    posteriorSamples.push(dirichletSample(posteriorParameters)); \n}\nconst vfe = calculateVFE(currentObservations, prior, posteriorSamples);\n\n// ... likelihoodModel would be a 2D array representing p(o|s).\n// ... prior would be an object/array representing p(s)\n// ... posteriorParameters would be parameters for current Dirichlet belief\n// ... dirichletSample() is a function for sampling from Dirichlet distribution.\n```\n\n* **Explanation:** This JavaScript code takes the observations, prior beliefs over states, and sampled posterior beliefs as input.  It iterates through each sample, computes the VFE for that sample based on the given equation, and then averages the VFE across all samples. Note that Dirichlet distribution sampling and a precomputed likelihood model are assumed for simplicity. This would need to be instantiated and defined elsewhere in a full implementation.\n\n**2.  Expected Free Energy (EFE) Calculation (Equation 15):**\n\nThe EFE guides action selection, balancing pragmatic value (preference satisfaction) and epistemic value (information gain).\n\n```javascript\nfunction calculateEFE(action, preferences, predictedObservations) {\n  let pragmaticValue = 0;\n  for (const observationSet in preferences) { // Iterate through all joint observation possibilities\n    const preferenceProb = preferences[observationSet];\n    const predictedProb = predictedObservations[observationSet]; \n    if (predictedProb > 0 && preferenceProb > 0){ //prevent log(0) errors.\n        pragmaticValue -= predictedProb * Math.log(preferenceProb);\n    }\n  }\n\n  let salience = 0;\n  // Simplified as ambiguity = 0\n  for (let m = 0; m < numAgents; m++) {\n    salience -= entropy(predictedObservationsPerModality[m]); // Assuming predictedObservationsPerModality stores predicted observations for individual modalities/agents for the current action\n  }\n\n  return -pragmaticValue - salience; \n}\n\n\n// Example Usage\nconst efe = calculateEFE(selectedAction, preferences, predictedObservations);\n\n\n// ... preferences: represents p*(o) and would be obtained after softmax transformation on payoffs (as defined in Equation 9).\n// ... predictedObservations represents the joint predictive distribution q(ōi, ōj, ōk|ûi).\n// ... predictedObservationsPerModality: stores predictive distributions by agent/modality.\n// ... entropy(): a separate function to calculate entropy from a distribution.\n\n```\n\n* **Explanation:**  This JavaScript code calculates the EFE for a given action. It first computes the pragmatic value by summing across all possible joint observations, weighting each by its preference and predicted probability (cross-entropy).  It then computes salience as the negative sum of entropies of predicted observations per modality. Note that the code is simplified because ambiguity is zero in their model. In a more general case, the ambiguity term would need to be added.\n\n\n**3. Action Selection (Equation 16):**\n\nThis equation describes how agents select actions by sampling from a distribution determined by the EFE and habits.\n\n\n```javascript\nfunction selectAction(efes, habits, precision) {\n let actionProbabilities = [];\n const expEfes = efes.map(efe => Math.exp(-precision * efe)); // Note negative sign in exponent\n\n  const sumExpEfes = expEfes.reduce((a, b) => a + b, 0);\n  for (let i = 0; i < efes.length; i++) {\n      actionProbabilities.push(habits[i] * expEfes[i] / sumExpEfes);\n  }\n\n return categoricalSample(actionProbabilities);\n\n}\n\n\n// Example Usage:\nconst chosenAction = selectAction(efes, habits, calculatedPrecision);\n\n// ... efes: An array of EFE values for each possible action.\n// ... habits: Prior probability for each action (usually uniform initially).\n// ... calculatedPrecision: The precision parameter (gamma), updated each time step as per Equation 17.\n// ... categoricalSample: A function that samples from a categorical distribution.\n\n```\n\n\n* **Explanation:** This function calculates a probability distribution over actions, based on each action's EFE, current habits, and precision. Then, an action is selected by sampling from this categorical distribution.  It incorporates habits (prior probabilities for actions), EFEs, and precision to calculate the probabilities. The `categoricalSample()` function is a helper function to draw a sample from a categorical distribution (similar to `numpy.random.choice` in Python).\n\n\n\nThese JavaScript snippets illustrate how the core concepts of the paper can be translated into code. A complete implementation would require additional code for belief updating, learning, handling game transitions, etc. Moreover, helper functions for operations like Dirichlet sampling, categorical sampling and entropy calculation are assumed here. These would need to be implemented fully as a part of a multi-agent AIF system.",
  "simpleQuestion": "How can LLMs strategize in changing games?",
  "timestamp": "2024-11-13T06:02:16.395Z"
}