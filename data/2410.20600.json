{
  "arxivId": "2410.20600",
  "title": "Implementation and Application of an Intelligibility Protocol for Interaction with an LLM",
  "abstract": "Our interest is in constructing interactive systems involving a human-expert interacting with a machine learning engine on data analysis tasks. This is of relevance when addressing complex problems arising in areas of science, the environment, medicine and so on, which are not immediately amenable to the usual methods of statistical or mathematical modelling. In such situations, it is possible that harnessing human expertise and creativity to modern machine-learning capabilities of identifying patterns by constructing new internal representations of the data may provide some insight to possible solutions. In this paper, we examine the implementation of an abstract protocol developed for interaction between agents, each capable of constructing predictions and explanations. The PXP protocol, described in [12] is motivated by the notion of “two-way intelligibility” and is specified using a pair of communicating finite-state machines. While the formalisation allows the authors to prove several properties about the protocol, no implementation was presented. Here, we address this shortcoming for the case in which one of the agents acts as a \"generator\" using a large language model (LLM) and the other is an agent that acts as a \"tester\" using either a human-expert, or a proxy for a human-expert (for example, a database compiled using human-expertise). We believe these use-cases will be a widely applicable form of interaction for problems of the kind mentioned above. We present an algorithmic description of general-purpose implementation, and conduct preliminary experiments on its use in two different areas (radiology and drug-discovery). The experimental results provide early evidence in support of the protocol's capability of capturing one- and two-way intelligibility in human-LLM in the manner proposed in [12].",
  "summary": "This research explores a communication protocol (PXP) for interactions between human experts and large language models (LLMs) in multi-agent systems. \n\nThe paper implements a simplified version of PXP, demonstrating its use in tasks like X-ray diagnosis and molecule synthesis. Experiments show promising results, highlighting PXP's ability to:\n\n* **Facilitate \"intelligible\" communication** between humans and LLMs, enabling them to understand and refine each other's predictions and explanations.\n* **Improve LLM performance** by incorporating human feedback through iterative message exchanges. \n* **Quantify the level of intelligibility** in human-LLM interactions.\n\nThe research suggests PXP can be a valuable tool for building collaborative human-LLM systems for complex data analysis.",
  "takeaways": "This paper explores the concept of \"intelligibility\" in multi-agent systems, focusing on interactions between a human expert and an LLM. While not directly focused on web development, its insights can be applied to create more understandable and collaborative LLM-based applications. \n\nHere's how a JavaScript developer can leverage these insights:\n\n**1. Building Explainable AI Features:**\n\n* **Imagine a collaborative design tool:** A team of designers uses an LLM-powered tool to generate website mockups. By implementing a system inspired by the PXP protocol, each design suggestion from the LLM can be accompanied by an explanation. \n    * **Example:**  The LLM suggests a color palette. The explanation clarifies, \"This palette aligns with current web accessibility standards and evokes a feeling of trust, suitable for the client's industry.\"  \n* **JavaScript implementation:** You could use a frontend framework like React to display the LLM's suggestions and explanations dynamically. Libraries like `Axios` can be used to communicate with a backend service where the LLM and PXP logic resides.\n\n**2. Enhancing User Feedback Loops:**\n\n* **Scenario: An AI-powered chatbot for customer support:** The chatbot, powered by an LLM, provides answers to user queries. By applying the concept of \"two-way intelligibility,\" you can create a feedback mechanism that helps the LLM refine its responses.\n    * **Example:** If a user rates a chatbot response as unhelpful, the system can prompt them with, \"Can you explain why this wasn't helpful?\" The user's feedback can then be used to update the LLM's prompts.\n* **JavaScript implementation:** You can use JavaScript and libraries like `Socket.IO` to build real-time, bi-directional communication channels between the user interface, your backend, and the LLM API.\n\n**3. Developing Collaborative Editing Tools:**\n\n* **Scenario: A multi-user code editor:** Developers work together on a codebase, with an LLM suggesting code completions and refactoring options. The PXP protocol's message exchange system can be adapted to enable a conversation between developers and the LLM. \n    * **Example:** The LLM flags a potential performance bottleneck. A developer can ask, \"What are alternative solutions?\" The LLM can then provide a list of options with explanations.\n* **JavaScript implementation:** Frameworks like `Monaco Editor` (the foundation of VS Code) can be extended to integrate LLM suggestions. You can use JavaScript to handle real-time collaboration features and display LLM-generated explanations within the editor.\n\n**Frameworks and Libraries:**\n\n* **TensorFlow.js:**  For running LLM models directly in the browser for a more integrated experience.\n* **LLM APIs (OpenAI, Cohere, etc.):**  For accessing powerful LLMs through well-documented APIs.\n* **WebSockets (Socket.IO):**  For real-time communication between the frontend and the LLM backend.\n\n**Key Takeaway:** While implementing the full PXP protocol in a web app might be complex, its core principles—transparency of LLM reasoning, user feedback integration, and iterative refinement—are invaluable for building next-generation web applications that are both intelligent and understandable.",
  "pseudocode": "```javascript\n// INTERACT Procedure - Simulates a session between a human and an LLM agent\n// based on the PXP protocol.\n//\n// Parameters:\n//  X: An array of data instances to process.\n//  h: An identifier for the human agent.\n//  m: An identifier for the machine (LLM) agent.\n//  qh: A query function for the human agent, taking (data, context) as input.\n//  qm: A query function for the machine agent, taking (data, context) as input.\n//  n: Maximum number of messages in an interaction (interaction cycles = n / 2).\n//  k: Message number after which agents can send 'REJECT' tags.\n//\n// Returns: An object representing the interaction history:\n//  { D: [ [sessionID, data], ... ],\n//    M: [ [sessionID, msgNumber, senderID, message, receiverID], ... ],\n//    C: [ [sessionID, msgNumber, context], ... ] }\n//\nasync function interact(X, h, m, qh, qm, n, k) {\n  let left = X.slice(); // Data instances to process\n  let D = []; // Data table\n  let M = []; // Message table\n  let C = []; // Context table\n  let Δ = { D, M, C }; // Shared blackboard\n\n  // Process each data instance\n  while (left.length > 0) {\n    const x = left.shift();\n    const s = Math.random().toString(36).substring(2, 15); // Generate session ID\n    D.push([s, x]);\n    let j = 1; // Message counter\n    let lm = 'INIT'; // Initial message tag for machine\n    let lh = 'INIT'; // Initial message tag for human\n    let stop = false; // Flag to end the session\n\n    // Interaction loop for a single data instance\n    while (j <= n && !stop) {\n      // Machine agent's turn\n      let [ym, em] = await askAgent(qm, x, m, C[C.length - 1]?.[2] || null);\n      const μm = [lm, ym, em];\n      M.push([s, j, m, μm, h]);\n      j++;\n      stop = (lm === 'RATIFY' && lh === 'RATIFY') || lm === 'REJECT';\n\n      if (j <= n && !stop) {\n        // Human agent's turn\n        let [yh, eh] = await askAgent(qh, x, h, C[C.length - 1]?.[2] || null);\n        const μh = [lh, yh, eh];\n        M.push([s, j, h, μh, m]);\n        j++;\n        stop = (lm === 'RATIFY' && lh === 'RATIFY') || lh === 'REJECT';\n\n        // Update context\n        const newContext = updateContext([lh, yh, eh], j, C[C.length - 1]?.[2] || null);\n        C.push([s, j, newContext]);\n      }\n    }\n  }\n\n  return Δ;\n}\n\n// AGENT Procedure - Simulates an agent (human or LLM) \n// participating in the PXP protocol.\n//\n// Parameters:\n//  q: The agent's query function (domain specific).\n//  x: The data instance being processed.\n//  λ: The agent's identifier.\n//  C: Prior context information.\n//\n// Returns: An array [messageTag, prediction, explanation], representing\n//  the agent's message based on the current interaction state.\n//\nasync function agent(q, x, λ, C) {\n  // ... (Logic for agent decision making)\n  // ... (Uses MATCH, AGREE, and ASK_AGENT functions as needed)\n}\n\n// ASK_AGENT Function - Queries an agent (human or LLM) \n// for prediction and explanation.\n//\n// Parameters:\n//  q: The agent's query function.\n//  x: The data instance to process.\n//  λ: The agent's identifier ('h' for human, 'm' for machine).\n//  C: Prior context information.\n//\n// Returns: An array [prediction, explanation] based on the agent's response.\n//\nasync function askAgent(q, x, λ, C) {\n  if (λ === 'm') {\n    // Machine agent (LLM)\n    const prompt = assemblePrompt(q, C);\n    return await queryLLM(x, prompt); // Replace with actual LLM call\n  } else {\n    // Human agent\n    return await q(x, C); \n  }\n}\n```\n\n**Explanation:**\n\n1. **`interact(X, h, m, qh, qm, n, k)`:** This function simulates the main interaction loop between the human and LLM agents based on the PXP protocol. It takes data instances, agent identifiers, query functions, and interaction parameters as input. The function iterates through each data instance, simulating message exchanges between the agents and updating a shared blackboard (Δ) containing data, messages, and context information. \n\n2. **`agent(q, x, λ, C)`:** This function represents the decision-making logic of either the human or LLM agent. It receives a query, data instance, agent identifier, and context information. The function's implementation would utilize domain-specific `MATCH` and `AGREE` functions to compare predictions and explanations, and the `ASK_AGENT` function to query itself or the other agent. \n\n3. **`askAgent(q, x, λ, C)`:** This function handles querying either the LLM or the human agent. It differentiates between the two based on the `λ` identifier. For LLM agents, it constructs a prompt using `assemblePrompt` and calls the `queryLLM` function (which should be replaced with an actual LLM API call). For human agents, it directly calls the provided query function (`q`) with data and context.\n\n**Note:** This JavaScript code provides a structural outline. You need to implement the domain-specific logic for `assemblePrompt`, `queryLLM`, `MATCH`, `AGREE`, and the agent's query functions (`qh`, `qm`) based on the specific problem you are trying to solve.",
  "simpleQuestion": "How can LLMs explain their reasoning to humans?",
  "timestamp": "2024-10-29T06:01:23.362Z"
}