{
  "arxivId": "2410.02603",
  "title": "AGENTS' ROOM: NARRATIVE GENERATION THROUGH MULTI-STEP COLLABORATION",
  "abstract": "Writing compelling fiction is a multifaceted process combining elements such as crafting a plot, developing interesting characters, and using evocative language. While large language models (LLMs) show promise for story writing, they currently rely heavily on intricate prompting, which limits their use. We propose AGENTS' ROOM, a generation framework inspired by narrative theory, that decomposes narrative writing into subtasks tackled by specialized agents. To illustrate our method, we introduce TELL ME A STORYÂ¹, a high-quality dataset of complex writing prompts and human-written stories, and a novel evaluation framework designed specifically for assessing long narratives. We show that AGENTS' ROOM generates stories that are preferred by expert evaluators over those produced by baseline systems by leveraging collaboration and specialization to decompose the complex story writing task into tractable components. We provide extensive analysis with automated and human-based metrics of the generated output.",
  "summary": "This paper proposes a multi-agent framework called AGENTS' ROOM for generating long-form fictional narratives. Inspired by narrative theory, the framework employs specialized AI agents to collaboratively plan and write different story elements like plot, character, setting, and narrative sections. \n\nKey points:\n\n* **Specialized agents**: Individual agents are either fine-tuned or zero-shot prompted LLMs focused on specific subtasks, avoiding complex instructions for a single LLM.\n* **Collaboration**:  Agents communicate through a shared scratchpad, fostering efficient knowledge sharing and avoiding redundant information.\n* **Orchestration**: A central orchestrator (rule-based in this case) determines the order and necessity of agent calls, highlighting potential for future learning-based orchestration.\n* **Synthetic data**:  Scarcity of long-form writing datasets is addressed by generating synthetic data for agent training via distilled backtranslation.\n* **Evaluation**:  Human and LLM-based evaluators are used to assess different story quality dimensions, demonstrating preference for multi-agent generated stories over single LLM baselines.",
  "takeaways": "This paper presents an exciting opportunity for JavaScript developers to leverage the power of LLMs in creating more engaging and dynamic web applications. Let's translate \"Agents' Room\" into practical examples using JavaScript and popular web technologies:\n\n**Scenario: Interactive Storytelling Platform**\n\nImagine building a web platform where users collaborate with AI agents to craft stories. Here's how you could implement it:\n\n1. **Specialized Agents:**\n    * **Planning Agents (Node.js):**  You could use a Node.js backend to host these agents. Each agent could be implemented as a separate module:\n        * **ConflictAgent.js:** Uses a prompt like the paper's example to define the central conflict based on user input.\n        * **CharacterAgent.js:** Generates detailed character profiles, possibly using a library like `tracery.js` for more creative variations. \n        * **SettingAgent.js:**  Describes the setting, leveraging external APIs for geographical data or image generation (e.g., `OpenAI's DALL-E` API).\n        * **PlotAgent.js:** Outlines key plot points, potentially incorporating user choices to influence the story direction.\n    * **Writing Agents (Client-side JavaScript):** These agents run in the browser, dynamically updating the story as the user progresses. You could use a framework like `React` or `Vue.js` to manage the UI and story rendering:\n        * **ExpositionAgent.js:**  Creates the opening section, gradually revealing details based on the planning agent's output.\n        * **RisingActionAgent.js:** Introduces complications and challenges, possibly incorporating user interactions or choices.\n        * **ClimaxAgent.js:** Builds tension and presents the central conflict in a dramatic way.\n        * **FallingActionAgent.js:** Resolves the conflict and explores the consequences. \n        * **ResolutionAgent.js:** Provides a satisfying conclusion.\n\n2. **Scratchpad:**\n    * **Shared State (Redux):** Use a state management library like `Redux` to hold the scratchpad data, allowing agents to access and modify it. Each agent's output becomes part of the Redux store, making it available to subsequent agents.\n\n3. **Orchestrator (JavaScript):**\n    * **Event-Driven Flow:** Implement the orchestrator as an event-driven system.  When a user interacts (e.g., provides input, makes a choice), trigger the appropriate agent to generate its output and update the scratchpad.\n    * **Flexibility:** You could start with a simple, rule-based orchestrator, then experiment with more complex logic using techniques like reinforcement learning to train the orchestrator to call agents in an optimal order.\n\n**Other Web Development Applications**\n\n* **Content Creation Tools:**  Imagine a blog post generator that collaborates with agents for research (`Node.js` backend using libraries like `cheerio.js` for web scraping), outlining (`draftjs` for structured content), and writing. \n* **Personalized Learning Experiences:** Build an educational platform where agents adapt the learning path based on a student's progress.  An agent could assess understanding (`TensorFlow.js` for question answering), recommend relevant content, and generate personalized exercises.\n* **AI-Powered Chatbots:** Create multi-agent chatbots where each agent specializes in a domain (customer support, technical help, etc.), seamlessly handing off the conversation based on user needs.\n\n**Key JavaScript Tools and Libraries**\n\n* **LLM Integration:** Libraries like `LangChain.js` provide convenient ways to interact with LLMs like Gemini. \n* **State Management:** `Redux`, `MobX`, or `Context API` in React help manage the shared scratchpad data. \n* **Web Frameworks:**  `React`, `Vue.js`, or `Angular` provide the structure for building interactive UIs that respond to agent output.\n\n**Inspiring Innovation**\n\nThe \"Agents' Room\" paradigm opens a new era of web development. By combining the strengths of LLMs, JavaScript's versatility, and existing web frameworks, developers can create truly interactive, personalized, and engaging experiences, blurring the line between user and AI co-creation.",
  "pseudocode": "```javascript\nconst scratchpad = {}; // Initialize an empty object to represent the scratchpad\n\nfunction agentsRoom(x, agents, orchestrator, maxSteps) {\n  scratchpad.prompt = x; // Initialize scratchpad with the writing prompt\n  let output = \"\"; // Initialize an empty string to store the final output\n  let t = 0; // Initialize step counter\n\n  while (orchestrator.shouldContinue(scratchpad, agents) && t < maxSteps) {\n    const currentAgent = orchestrator.getNextAgent(scratchpad, agents);\n    const agentOutput = currentAgent.execute(scratchpad);\n    scratchpad[currentAgent.label] = agentOutput; // Add agent output to scratchpad\n\n    if (currentAgent.type === \"writing\") {\n      output += agentOutput; // Append output of writing agents to final output\n    }\n\n    t++;\n  }\n\n  return output;\n}\n```\n\n**Explanation:**\n\nThe `agentsRoom` function represents the AGENTS' ROOM framework for collaborative writing in JavaScript. It takes four arguments:\n\n* `x`: The initial writing prompt.\n* `agents`: An array of agent objects, each with properties like `label`, `type` (planning or writing), and an `execute` method to perform the agent's task.\n* `orchestrator`: An object responsible for determining the next agent to call and the stopping condition using the `shouldContinue` and `getNextAgent` methods.\n* `maxSteps`: The maximum number of steps allowed for the process.\n\nThe function initializes the scratchpad with the prompt, iterates through the agents based on the orchestrator's decisions, updates the scratchpad with agent outputs, and appends the output of writing agents to the final output string. It returns the complete output text when the process is finished.\n\n**Purpose:**\n\nThis algorithm implements the multi-agent collaboration framework for generating long-form text, breaking down complex writing tasks into smaller subtasks handled by specialized agents, and coordinating their actions through a shared scratchpad. This approach leverages the strengths of different LLMs (or other agents) to improve overall writing quality and address the challenges of long-form text generation.",
  "simpleQuestion": "How can specialized agents collaborate to write better stories?",
  "timestamp": "2024-10-04T05:05:00.473Z"
}