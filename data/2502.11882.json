{
  "arxivId": "2502.11882",
  "title": "Leveraging Dual Process Theory in Language Agent Framework for Real-time Simultaneous Human-AI Collaboration",
  "abstract": "Agents built on large language models (LLMs) have excelled in turn-by-turn human-AI collaboration but struggle with simultaneous tasks requiring real-time interaction. Latency issues and the challenge of inferring variable human strategies hinder their ability to make autonomous decisions without explicit instructions. Through experiments with current independent System 1 and System 2 methods, we validate the necessity of using Dual Process Theory (DPT) in real-time tasks. We propose DPT-Agent, a novel language agent framework that integrates System 1 and System 2 for efficient real-time simultaneous human-AI collaboration. DPT-Agent's System 1 uses a Finite-state Machine (FSM) and code-as-policy for fast, intuitive, and controllable decision-making. DPT-Agent's System 2 integrates Theory of Mind (ToM) and asynchronous reflection to infer human intentions and perform reasoning-based autonomous decisions. We demonstrate the effectiveness of DPT-Agent through further experiments with rule-based agents and human collaborators, showing significant improvements over mainstream LLM-based frameworks. To the best of our knowledge, DPT-Agent is the first language agent framework that achieves successful real-time simultaneous human-AI collaboration autonomously. Code of DPT-Agent can be found in https://github.com/sjtu-marl/DPT-Agent.",
  "summary": "This paper introduces DPT-Agent, a framework for building AI agents that can collaborate with humans in real-time, like in a fast-paced video game.  It addresses the challenge of LLMs being either too slow or too simple for effective real-time teamwork.\n\nKey points for LLM-based multi-agent systems:\n\n* **Dual Process Theory (DPT):** DPT-Agent combines a fast, rule-based system (System 1) with a slower, LLM-powered reasoning system (System 2) to balance speed and intelligence.\n* **Theory of Mind (ToM):**  System 2 uses ToM to infer the human player's intentions and adapt its strategy accordingly.\n* **Asynchronous Reflection:** System 2 reflects on past performance to improve its strategy over time, without interrupting real-time actions.\n* **Code as Policy:**  System 2 generates code that controls System 1, allowing high-level reasoning to influence low-level actions.\n* **Overcooked Environment:**  The system is tested in a modified version of the Overcooked game, a challenging benchmark for multi-agent collaboration.\n* **Human Evaluation:** Experiments show DPT-Agent performs better than existing frameworks when collaborating with both rule-based agents and real humans.",
  "takeaways": "This paper offers several valuable insights for JavaScript developers working on LLM-based multi-agent AI projects, especially in web development scenarios. Here are some practical examples:\n\n**1. Implementing Dual Process Theory (DPT) in a Chat Application:**\n\nImagine building a collaborative writing application where multiple users and an LLM agent work together simultaneously.  Latency from the LLM can be a major issue. DPT can be applied as follows:\n\n* **System 1 (Fast):** Use a client-side JavaScript library like `Redux` or `MobX` to manage the application state and handle immediate user interactions (e.g., text input, cursor movements).  A simple FSM could predict basic text completions or suggest common phrases based on local context, providing instant feedback.\n\n* **System 2 (Slow):** The LLM agent acts as System 2. It can asynchronously perform more complex tasks like grammar correction, style suggestions, content generation, and even summarize ongoing discussions. These suggestions are then integrated into the application state by System 1. Libraries like `RxJS` could be used to manage these asynchronous updates.\n\n**Code Example (Conceptual):**\n\n```javascript\n// System 1 (Redux reducer)\nconst textReducer = (state = '', action) => {\n  switch (action.type) {\n    case 'USER_INPUT':\n      return state + action.text; // Instant update\n    case 'LLM_SUGGESTION':\n      return action.newText; // Async update from LLM\n    default:\n      return state;\n  }\n};\n\n// System 2 (LLM interaction)\nasync function getLLMSuggestion(text) {\n  const response = await fetch('/api/llm', {\n    method: 'POST',\n    body: JSON.stringify({ text }),\n  });\n  const suggestion = await response.json();\n  store.dispatch({ type: 'LLM_SUGGESTION', newText: suggestion.text });\n}\n\n// Trigger System 2 periodically or on specific events\nsetInterval(() => {\n  getLLMSuggestion(store.getState().text);\n}, 5000); // Example: every 5 seconds\n```\n\n\n**2. Theory of Mind (ToM) for Personalized Recommendations in E-commerce:**\n\nIn a multi-agent e-commerce setting with multiple LLM-powered recommendation agents and human users, ToM can enable personalized experiences.\n\n* **Client-Side (JavaScript):** Track user interactions (clicks, views, purchases) and send this data to the server.  This data represents the user's \"behavior history\" (T<sub>0:t</sub> in the paper).\n\n* **Server-Side (Node.js):** An LLM agent, using the user's behavior history and potentially data from other users, can infer the user's preferences and intentions (the \"belief,\" *b<sub>n</sub>*). This could be implemented using a Node.js library that interacts with the LLM API. The agent can then adjust its recommendations accordingly.\n\n**3. Asynchronous Reflection for Dynamic Game AI:**\n\nImagine a web-based multiplayer game with LLM-powered bots.  Asynchronous reflection can be used to improve the bot's performance over time.\n\n* **Game Client (JavaScript):** Record game states and the bot's actions.\n\n* **Game Server (Node.js):** The LLM agent, using the game history and potentially the outcomes of previous games, can reflect on its strategy (the \"behavior guideline,\" *g<sub>m</sub>*). This process can run asynchronously on the server without affecting the real-time gameplay.  The updated strategy is then sent to the game client.\n\n**4. FSM for Navigation in a Virtual World:**\n\nA virtual world or metaverse application could use an FSM for character navigation, handling basic movement and interactions with the environment.  An LLM could provide higher-level instructions to the FSM, like \"go to the store\" or \"find a specific item.\"  This allows for more complex behavior while still keeping the basic actions responsive.\n\n**Key Libraries and Frameworks:**\n\n* **Redux, MobX:** For state management (System 1).\n* **RxJS:** For managing asynchronous operations (System 2 interactions).\n* **Node.js with LLM API libraries:** For server-side LLM interactions.\n* **TensorFlow.js, WebDNN:** If you need to run smaller, specialized models client-side.\n\nThese examples show how the paper's concepts can be put into practice by JavaScript developers. By combining the strengths of LLMs with efficient JavaScript frameworks and DPT, it's possible to create powerful and engaging multi-agent AI experiences for the web. Remember that experimentation is key. Start with a simple prototype and iteratively refine your implementation based on the specific needs of your project.",
  "pseudocode": "No pseudocode block found.",
  "simpleQuestion": "How can LLMs handle real-time human-AI collaboration?",
  "timestamp": "2025-02-18T06:03:37.613Z"
}