{
  "arxivId": "2412.16533",
  "title": "Self-guided Knowledgeable Network of Thoughts: Amplifying Reasoning with Large Language Models",
  "abstract": "We introduce Knowledgeable Network of Thoughts (kNoT): a prompt scheme that advances the capabilities of large language models (LLMs) beyond existing paradigms like Chain-of-Thought (CoT), Tree of Thoughts (ToT), and Graph of Thoughts (GoT). The key innovation of kNoT is the LLM Workflow Template (LWT), which allows for an executable plan to be specified by LLMs for LLMs. LWT allows these plans to be arbitrary networks, where single-step LLM operations are nodes, and edges correspond to message passing between these steps. Furthermore, LWT supports selection of individual elements through indexing, facilitating kNoT to produce intricate plans where each LLM operation can be limited to elementary operations, greatly enhancing reliability over extended task sequences. We demonstrate that kNoT significantly outperforms the state of the art on six use cases, while reducing the need for extensive prompt engineering. For instance, kNoT finds 92% accuracy for sorting 32 numbers over 12% and 31% for ToT and GoT, while utilizing up to 84.4% and 87.3% less task-specific prompts, respectively.",
  "summary": "This paper introduces kNoT (Knowledgeable Network of Thoughts), a new prompting method for LLMs designed to improve multi-step reasoning.  It uses the LLM to create its own step-by-step plan (encoded in a structured format called LWT) for solving a task, then executes that plan.\n\nKey points for multi-agent systems:  kNoT allows for flexible, network-like execution flows between LLM calls, going beyond simpler chain or tree structures seen in other prompting methods.  This enables more complex interaction patterns analogous to communication within a multi-agent system, where each LLM call can be viewed as an agent performing a sub-task.  The LWT format also supports accessing individual elements from previous steps' outputs, enabling finer-grained control over information flow between these \"agents.\"  This approach aims to reduce the manual prompt engineering often needed for complex tasks and improve performance by breaking them down into smaller, more manageable steps.",
  "takeaways": "This research paper introduces kNoT (Knowledgeable Network of Thoughts), a prompting scheme to enhance the reasoning capabilities of LLMs, particularly relevant for multi-agent systems in web development.  Here's how a JavaScript developer can apply its insights:\n\n**1. Modularized Agent Tasks with LWT:**\n\nkNoT's LLM Workflow Template (LWT) provides a structure for defining complex tasks as a sequence of simpler LLM operations. This directly translates to designing modular agents in JavaScript.  Imagine building a collaborative document editing application with multiple LLM-powered agents:\n\n```javascript\n// Example LWT-inspired agent task definition\nconst agentTasks = [\n  { id: 0, task: \"LLM('Summarize the current paragraph.')\" },\n  { id: 1, task: \"LLM('Suggest improvements for clarity in {(0)}')\" },\n  { id: 2, task: \"LLM('Incorporate feedback from other agents into {(1)}')\" }\n];\n\n// Agent execution loop (simplified)\nagentTasks.forEach(async (task) => {\n  let prompt = task.task;\n  for (const match of prompt.matchAll(/\\{(\\d+)\\}/g)) {\n    prompt = prompt.replace(match[0], await executeTask(match[1]));\n  }\n  const result = await callLLM(prompt);\n  // ... process result and store in shared state\n});\n```\n\nThis shows how LWT-style instructions can be executed, fetching results from previous steps (`{(0)}`, `{(1)}`) and managing dependencies.  You would replace `callLLM` with your LLM interaction logic (e.g., using LangChain or similar) and `executeTask` with a function to retrieve results from a shared state or message queue.\n\n**2. Flexible Agent Interaction Networks:**\n\nUnlike rigid chains or trees, kNoT allows for arbitrary interaction networks between LLM operations.  In JavaScript, this can be implemented using message queues (like Redis, RabbitMQ, or even browser-based solutions) or shared state management libraries (like Redux, MobX, or Context API in React):\n\n```javascript\n// Agent sending a message to another agent\nsendMessage(\"agent2\", { type: \"request\", data: summary });\n\n// Agent2 listening for messages\nonMessage(\"agent2\", async (message) => {\n  if (message.type === \"request\") {\n    const improvements = await callLLM(`Suggest improvements for: ${message.data}`);\n    sendMessage(\"agent1\", { type: \"response\", data: improvements });\n  }\n});\n```\n\nThis allows agents to communicate asynchronously and flexibly, mirroring the network structure of kNoT.\n\n**3. Elementary LLM Operations for Precision:**\n\nkNoT promotes breaking down complex tasks into elementary LLM operations, increasing precision.  This is crucial in JavaScript multi-agent apps. For instance, in a customer support chatbot system, you could have specialized agents:\n\n* **Sentiment Analysis Agent:**  `LLM('Analyze the sentiment of: ${userMessage}')`\n* **Intent Recognition Agent:** `LLM('Identify the user's intent in: ${userMessage}')`\n* **Response Generation Agent:**  `LLM('Generate a helpful response given sentiment: ${sentiment} and intent: ${intent}')`\n\nThis specialized approach enhances accuracy and allows for easier debugging and improvement of individual agent logic.\n\n**4.  Experimentation with JavaScript and Web Technologies:**\n\n* **LangChain:** Provides abstractions for working with LLMs and managing chains/sequences of operations, aligning well with kNoT's principles.\n* **React/Vue/Svelte:**  These frameworks offer state management solutions for building interactive interfaces and managing shared state between agents.\n* **Message Queues (Redis, RabbitMQ, etc.):** Enable asynchronous communication between agents, mirroring kNoT's network structure.\n* **Web Workers:**  Allow running agents in separate threads, preventing blocking of the main UI thread and improving performance.\n\n**Summary:**\n\nkNoT's core concepts – LWT, flexible interaction networks, and elementary operations – are highly applicable to building robust and scalable LLM-based multi-agent web applications with JavaScript.  By adopting these principles, developers can create more sophisticated, efficient, and maintainable agent systems.  The practical JavaScript examples demonstrate how these concepts can be implemented using readily available frameworks and libraries.",
  "pseudocode": "```javascript\n/**\n * Knowledgeable Network of Thoughts (kNoT) Algorithm\n *\n * This algorithm leverages Large Language Models (LLMs) to solve complex reasoning tasks\n * by autonomously generating and executing a structured solution plan.\n *\n * @param {string} taskQuery - The input query for the task.\n * @param {string} context - Description of the task's objective and hints.\n * @param {string} lwtExample - An LWT example for a smaller version of the task.\n * @param {string} knowledgeExtractionPrompt - Prompt for extracting LLM's knowledge.\n * @param {string} lwtTranslationPrompt - Prompt for translating the solution plan to LWT.\n * @param {function} llm - The LLM function to call for inferences.  Takes a string prompt and returns a string output.\n * @returns {string} The final answer to the query.\n */\nasync function knoT(taskQuery, context, lwtExample, knowledgeExtractionPrompt, lwtTranslationPrompt, llm) {\n  // 1. Knowledge Extraction\n  const solutionPlan = await llm(knowledgeExtractionPrompt + taskQuery + context);\n\n  // 2. LWT Translation\n  const lwtScript = await llm(lwtTranslationPrompt + taskQuery + context + lwtExample + solutionPlan);\n\n\n  // 3. Script Execution\n  const results = [];\n  const instructions = lwtScript.split('\\n').filter(line => line.trim() !== ''); // split into individual instructions\n\n  for (const instruction of instructions) {\n    let currentInstruction = instruction;\n    const inputFieldMatches = currentInstruction.matchAll(/\\{(\\d+)(\\[(\\d+)\\])?\\}/g); // Match all input fields\n\n\n    for (const match of inputFieldMatches) {\n        const prevResultIndex = parseInt(match[1]);\n        const elementIndex = match[3] !== undefined ? parseInt(match[3]) : undefined;\n\n        const prevResult = results[prevResultIndex];\n\n        let replacementValue = prevResult;\n\n        if(elementIndex !== undefined && Array.isArray(prevResult)){\n          replacementValue = prevResult[elementIndex];\n        } else if (elementIndex !== undefined) {\n          console.warn(\"Tried to index a non-array value\", prevResult)\n        }\n\n\n\n        currentInstruction = currentInstruction.replace(match[0], replacementValue)\n\n\n    }\n\n    const llmCallMatch = currentInstruction.match(/\\=LLM\\(\"([^\"]+)\"\\)/);\n    if (!llmCallMatch) {\n      throw new Error(\"Invalid LWT instruction format: Missing LLM call\");\n    }\n    const llmPrompt = llmCallMatch[1];\n\n\n    const output = await llm(llmPrompt);\n\n    results.push(JSON.parse(output)); // Assuming the output is a valid JSON string (array or a single value)\n }\n\n  return results[results.length - 1];\n}\n\n```\n\n**Explanation:**\n\nThe kNoT algorithm is designed to solve complex reasoning tasks by breaking them down into a series of simpler steps orchestrated by an LLM.  It proceeds in three phases:\n\n1. **Knowledge Extraction:** An initial prompt is given to the LLM, asking it to create a step-by-step plan for solving the provided `taskQuery` given the `context`.\n\n2. **LWT Translation:** The solution plan (in natural language) is then translated into an executable LWT (LLM Workflow Template) script. This script uses a structured format that includes numbered instructions and references to previous results, allowing the LLM to execute the plan step by step. The LWT script uses placeholder notation like `{(N)}` to represent the entire output of the Nth instruction and `{(N)[M]}` to access individual elements of a list output from a previous instruction.\n\n3. **Script Execution:** The LWT script is executed sequentially. For each instruction in the script, the algorithm:\n   - Identifies any placeholders referencing previous results (`{(N)}` or `{(N)[M]}`).\n   - Substitutes these placeholders with the actual values stored in the `results` array.\n   - Extracts the LLM prompt embedded within the instruction (`LLM(\"...\")`).\n   - Calls the provided `llm` function (representing an LLM API call) with the formatted prompt.\n   - Parses the output from the LLM (assumes it's a JSON string) and stores it in the `results` array.\n\nThe final result of the last LLM call is returned as the answer to the `taskQuery`.\n\nThe core innovation of kNoT lies in its ability to leverage the LLM's own knowledge for planning and to execute that plan using the structured LWT format, enabling more complex and adaptable reasoning processes than traditional prompting techniques. This script execution phase dynamically resolves interdependencies between instructions, effectively creating a \"network of thoughts\" where information flows between different reasoning steps as specified by the LWT script.  This modularity and precise indexing into previous results enables \"elementary operations\" on the inputs, leading to higher accuracy and better handling of complex problems.",
  "simpleQuestion": "Can LLMs self-design better reasoning workflows?",
  "timestamp": "2024-12-24T06:02:01.717Z"
}