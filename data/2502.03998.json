{
  "arxivId": "2502.03998",
  "title": "Online Learning of Counter Categories and Ratings in PvP Games",
  "abstract": "In competitive games, strength ratings like Elo are widely used to quantify player skill and support matchmaking by accounting for skill disparities better than simple win rate statistics. However, scalar ratings cannot handle complex intransitive relationships, such as counter strategies seen in Rock-Paper-Scissors. To address this, recent work introduced Neural Rating Table and Neural Counter Table, which combine scalar ratings with discrete counter categories to model intransitivity. While effective, these methods rely on neural network training and cannot perform real-time updates. In this paper, we propose an online update algorithm that extends Elo principles to incorporate real-time learning of counter categories. Our method dynamically adjusts both ratings and counter relationships after each match, preserving the explainability of scalar ratings while addressing intransitivity. Experiments on zero-sum competitive games demonstrate its practicality, particularly in scenarios without complex team compositions.",
  "summary": "This paper introduces Elo-RCC, an algorithm for calculating ratings in competitive games that accounts for intransitive relationships (like rock-paper-scissors) where one strategy counters another.  Unlike existing methods (NRT, NCT), Elo-RCC updates ratings in real-time, similar to the Elo system.  \n\nFor LLM-based multi-agent systems, Elo-RCC offers a lightweight, real-time way to track agent performance even when complex counter-strategies emerge.  This is relevant for scenarios where agents are developing new tactics and their relative strengths change dynamically.  The tabular representation of counter-relationships in Elo-RCC could also offer interpretability into agent behavior.",
  "takeaways": "This paper introduces Elo-RCC, an online algorithm for learning counter relationships in multi-agent systems, offering a practical alternative to complex neural network-based approaches like NCT. Here's how a JavaScript developer can apply these insights to LLM-based multi-agent web applications:\n\n**1. Dynamic LLM Agent Skill Rating:**\n\n* **Scenario:** Imagine a collaborative writing web app where multiple LLM agents assist users with different writing styles (e.g., creative, technical, persuasive).  Elo-RCC can be used to dynamically rate each LLM agent's effectiveness based on user feedback (e.g., thumbs up/down, edits accepted/rejected).\n* **Implementation:**  Store each LLM agent's Elo rating in a database (e.g., using Node.js and MongoDB). After each user interaction, update the ratings based on the Elo-RCC algorithm.  This allows the system to identify the most effective LLM agents for specific tasks and personalize the user experience.\n* **JavaScript Libraries:**  Math.js for Elo calculations, database drivers for Node.js.\n\n**2. Modeling LLM Agent Strategy Counters:**\n\n* **Scenario:**  In a multi-agent debate application, LLM agents argue different sides of a topic. Elo-RCC can be used to model counter strategies between different argumentation styles (e.g., logical, emotional, ethical).\n* **Implementation:** Represent each argumentation style as a counter category.  After each debate, update the counter table based on which LLM agent \"won\" the argument (determined by user votes or a judge LLM). This allows the system to identify effective counter-strategies and match LLM agents with complementary styles for more engaging debates.\n* **JavaScript Libraries:**  TensorFlow.js or similar libraries for tabular regression to update the counter table, Lodash for array manipulation.\n\n**3. Personalized LLM Agent Matchmaking:**\n\n* **Scenario:**  In a multi-player online game with LLM-powered bots, use Elo-RCC to ensure balanced matches and intriguing gameplay.\n* **Implementation:** Combine Elo ratings and counter category information to match players with opponents of similar skill but potentially counter strategies. This adds an element of strategic depth beyond simple skill-based matchmaking.  The frontend could visualize the counter relationships using libraries like D3.js or Chart.js.\n* **JavaScript Frameworks/Libraries:**  Socket.io for real-time communication, Node.js for server-side logic.\n\n**4. Real-time LLM Agent Strategy Adaptation:**\n\n* **Scenario:** A web application where LLM agents negotiate prices or resources.  Elo-RCC allows agents to adapt their strategies in real-time based on opponent behavior.\n* **Implementation:** Each LLM agent maintains a probability distribution over different negotiation tactics (e.g., aggressive, cooperative, analytical). After each negotiation round, update the probability distribution based on the outcome and the opponent's tactics using the Elo-RCC category refinement process.  This enables dynamic adaptation to exploit opponent weaknesses and learn effective counter-strategies.\n* **JavaScript Libraries:** Web Workers for running the Elo-RCC algorithm in the background without blocking the UI.\n\n**5. Explainable LLM Agent Performance:**\n\n* **Scenario:** In any application using LLM agents, it's crucial to understand why some agents perform better than others.  Elo-RCC offers explainability through its counter table.\n* **Implementation:** Visualize the counter table in the web application's interface, providing insights into which LLM agent strategies are effective against others.  This helps developers understand and improve agent performance, as well as provide users with transparent feedback.\n* **JavaScript Libraries:**  React, Vue.js, or Angular for building interactive UI components to display the counter table and agent ratings.\n\n\nBy integrating Elo-RCC, JavaScript developers can create more engaging and dynamic multi-agent web experiences using LLMs, going beyond basic skill-based interactions to model complex strategic relationships. The simplicity and online nature of the algorithm make it particularly suitable for the fast-paced, interactive environment of the web.",
  "pseudocode": "The paper includes Algorithm 1, which is described as an \"Online Update Algorithm for Elo Residual Counter Category\". Here's the JavaScript equivalent:\n\n```javascript\nfunction eloRCCUpdate(matches, initialRatings, initialCategoryDistributions, initialCounterTable, initialExpectedResidualTable, learningRates, numCategories) {\n  const ratings = {...initialRatings};  // Create a copy to avoid modifying the original\n  const categoryDistributions = initialCategoryDistributions.map(dist => [...dist]); // Deep copy\n  const counterTable = initialCounterTable.map(row => [...row]); // Deep copy\n  const expectedResidualTable = initialExpectedResidualTable.map(row => [...row]); // Deep copy\n  const {etaR, etaT, etaC} = learningRates;\n\n  for (const [playerI, playerJ, outcomeI] of matches) { // Iterate through matches (i, j, outcome of i)\n    // Step 1: Elo Rating Update\n    const ratingDiff = ratings[playerJ] - ratings[playerI];\n    const expectedProbabilityI = 1 / (1 + 10**(ratingDiff / 400));\n    ratings[playerI] += etaR * (outcomeI - expectedProbabilityI);\n    ratings[playerJ] += etaR * ((1 - outcomeI) - (1 - expectedProbabilityI));\n\n\n    // Step 2: Counter Table Update\n    const categoryI = sampleCategory(categoryDistributions[playerI]);\n    const categoryJ = sampleCategory(categoryDistributions[playerJ]);\n    const residualWinValue = outcomeI - expectedProbabilityI;\n\n    counterTable[categoryI][categoryJ] += etaT * (residualWinValue - counterTable[categoryI][categoryJ]);\n    counterTable[categoryJ][categoryI] = -counterTable[categoryI][categoryJ];\n\n\n    // Step 3: Update Expected Residuals\n    expectedResidualTable[playerI][categoryJ] += etaT * (residualWinValue - expectedResidualTable[playerI][categoryJ]);\n    expectedResidualTable[playerJ][categoryI] += etaT * (-residualWinValue - expectedResidualTable[playerJ][categoryI]);\n\n\n    // Step 4: Category Refinement\n    let minDiscrepancyI = Infinity;\n    let bestCategoryI = -1;\n    let minDiscrepancyJ = Infinity;\n    let bestCategoryJ = -1;\n\n    for (let c = 0; c < numCategories; c++) {\n      let discrepancyI = 0;\n      let discrepancyJ = 0;\n      for (let cPrime = 0; cPrime < numCategories; cPrime++) {\n        discrepancyI += Math.abs(counterTable[c][cPrime] - expectedResidualTable[playerI][cPrime]);\n        discrepancyJ += Math.abs(counterTable[c][cPrime] - expectedResidualTable[playerJ][cPrime]);\n      }\n\n      if (discrepancyI < minDiscrepancyI) {\n        minDiscrepancyI = discrepancyI;\n        bestCategoryI = c;\n      }\n      if (discrepancyJ < minDiscrepancyJ) {\n        minDiscrepancyJ = discrepancyJ;\n        bestCategoryJ = c;\n      }\n    }\n\n\n\n    // Update category distributions (Softmax not explicitly implemented due to framework agnosticism)\n    for (let c = 0; c < numCategories; c++) {\n      categoryDistributions[playerI][c] += etaC * ((c === bestCategoryI ? 1 : 0) - categoryDistributions[playerI][c]);\n      categoryDistributions[playerJ][c] += etaC * ((c === bestCategoryJ ? 1 : 0) - categoryDistributions[playerJ][c]);\n\n\n      // Ensure probabilities stay within [0, 1] after update. Softmax application would obviate this.\n      categoryDistributions[playerI][c] = Math.max(0, Math.min(1, categoryDistributions[playerI][c]));\n      categoryDistributions[playerJ][c] = Math.max(0, Math.min(1, categoryDistributions[playerJ][c]));\n\n    }\n    // Renormalize distributions: This should be replaced with proper Softmax logic when integrated into a specific ML framework\n    normalize(categoryDistributions[playerI]);\n    normalize(categoryDistributions[playerJ]);\n  }\n\n  return {ratings, categoryDistributions};\n}\n\n\n// Helper function to sample from a categorical distribution.  Assumes distribution sums to 1\nfunction sampleCategory(distribution) {\n  let rand = Math.random();\n  let cumulative = 0;\n  for (let i = 0; i < distribution.length; i++) {\n    cumulative += distribution[i];\n    if (rand < cumulative) {\n      return i;\n    }\n  }\n  return distribution.length - 1; // Fallback to last category (due to floating point precision)\n}\n\n\n//Helper function to normalize a distribution (sum to 1).\nfunction normalize(dist) {\n  const sum = dist.reduce((a, b) => a + b, 0);\n  if(sum > 0) {\n    for (let i = 0; i < dist.length; i++) {\n      dist[i] /= sum;\n    }\n  }\n}\n\n```\n\n\n\n**Explanation:**\n\nThe Elo-RCC algorithm aims to adapt the Elo rating system to account for \"counter\" relationships between players or strategies (like in Rock-Paper-Scissors).  Standard Elo assumes purely transitive skill (if A > B and B > C, then A > C).  Elo-RCC incorporates \"counter categories\" to handle intransitive scenarios where A might beat B, B beats C, but C beats A.\n\nThe algorithm does this by:\n\n1. **Elo Rating Update:** Updating player ratings based on match outcomes using the standard Elo formula.\n\n2. **Counter Table Update:**  A table (matrix) stores win probabilities based on counter category matchups.  After each match, the algorithm samples counter categories for both players from individual probability distributions, then updates the counter table based on the actual match outcome.  The sampling allows the algorithm to explore different category assignments and refine its understanding over time.\n\n3. **Expected Residual Update:** For each player, the algorithm maintains expected residual win values for every possible counter category.  These values represent the expected advantage or disadvantage of belonging to a particular category.  After each match, these expected residuals are updated based on the opponent's sampled category.\n\n4. **Category Refinement:** After updating the expected residuals, the algorithm determines the most likely \"true\" counter category for each player. It chooses the category that minimizes the difference between its expected residuals and the values from the counter table.  The player's category probability distribution is updated to give higher weight to the most likely categories. This process effectively acts as an expectation-maximization step to refine category beliefs.\n\nThis iterative process allows Elo-RCC to dynamically learn and adapt to counter relationships while maintaining the simplicity and interpretability of scalar Elo ratings. This makes it very suitable for dynamic environments and online updates, which is a crucial advantage over previous Neural methods (NRT/NCT) which were static.",
  "simpleQuestion": "How can Elo ratings handle counter-strategies in real-time?",
  "timestamp": "2025-02-08T06:03:29.587Z"
}