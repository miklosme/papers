{
  "arxivId": "2502.11098",
  "title": "Talk Structurally, Act Hierarchically: A Collaborative Framework for LLM Multi-Agent Systems",
  "abstract": "Recent advancements in LLM-based multi-agent (LLM-MA) systems have shown promise, yet significant challenges remain in managing communication and refinement when agents collaborate on complex tasks. In this paper, we propose Talk Structurally, Act Hierarchically (TalkHier), a novel framework that introduces a structured communication protocol for context-rich exchanges and a hierarchical refinement system to address issues such as incorrect outputs, falsehoods, and biases. TalkHier surpasses various types of SoTA, including inference scaling model (OpenAI-01), open-source multi-agent models (e.g., AgentVerse), and majority voting strategies on current LLM and single-agent baselines (e.g., ReAct, GPT40), across diverse tasks, including open-domain question answering, domain-specific selective questioning, and practical advertisement text generation. These results highlight its potential to set a new standard for LLM-MA systems, paving the way for more effective, adaptable, and collaborative multi-agent frameworks. The code is available at https://github.com/sony/talkhier.",
  "summary": "This paper introduces TalkHier, a new framework for coordinating multiple LLMs to work together on complex tasks.  It addresses the challenges of disorganized communication and inconsistent refinements in current multi-agent LLM systems.\n\nKey points for LLM-based multi-agent systems:\n\n* **Structured Communication:** TalkHier uses a structured protocol with specific fields for messages, background information, and intermediate outputs, making communication between LLMs clearer and more efficient.\n* **Hierarchical Refinement:** Instead of a flat structure where all agents give feedback at once, TalkHier uses a hierarchical approach. This allows for better summarization and balancing of feedback, leading to less bias and more accurate results.\n* **Independent Agent Memory:** Each LLM has its own memory, allowing it to retain and use information from past interactions, enhancing consistency and efficiency.\n* **Superior Performance:** TalkHier outperforms existing methods on several benchmarks, including question answering and ad text generation, showcasing its effectiveness in various tasks.\n* **Generalizability:** The framework is designed to be modular and adaptable, making it potentially applicable to a broader range of tasks beyond the tested benchmarks.",
  "takeaways": "This paper offers valuable insights for JavaScript developers working with LLM-based multi-agent applications, especially in web development. Here are some practical examples illustrating how a developer can apply these concepts:\n\n**1. Structured Communication Protocol:**\n\n* **Scenario:** Imagine building a collaborative writing tool where multiple LLM agents contribute to a document.  Traditionally, you might have free-form text exchanges between agents, leading to confusion and difficulty in parsing instructions.\n* **TalkHier Application:** Implement a structured message format using JSON.  Each message includes:\n    * `message`: The specific instruction for the agent (e.g., \"Summarize the last paragraph,\" \"Write an introduction on X\").\n    * `intermediateOutput`: The result of the previous agent's action.\n    * `background`: Contextual information relevant to the task (e.g., overall document topic, target audience).\n* **JavaScript Implementation:**\n```javascript\n// Agent communication message\nconst message = {\n  message: \"Write a paragraph about climate change.\",\n  intermediateOutput: \"Previous agent's output here\",\n  background: \"This document is a blog post for a general audience.\",\n};\n\n// Sending the message (example using WebSockets)\nwebsocket.send(JSON.stringify(message));\n\n// Receiving and parsing the message\nwebsocket.onmessage = (event) => {\n  const receivedMessage = JSON.parse(event.data);\n  // Process receivedMessage.message, receivedMessage.intermediateOutput, etc.\n};\n\n```\n* **Benefit:** This structured approach using JavaScript objects simplifies communication, enabling agents to effectively understand and act upon instructions, promoting better collaboration.\n\n**2. Hierarchical Refinement:**\n\n* **Scenario:**  Developing a customer service chatbot system with multiple specialized LLM agents. One agent handles initial inquiries, another provides detailed product information, and a third manages escalation to human operators.\n* **TalkHier Application:**  Implement a hierarchical evaluator system. For example, initial agent responses could be evaluated by a \"Fluency Agent\" and a \"Relevance Agent.\"  Their evaluations are then summarized and passed to a \"Supervisor Agent\" which decides whether to revise the response, pass it to the next agent, or escalate to a human.\n* **JavaScript Implementation (Conceptual):**\n```javascript\n// Evaluator agents\nconst fluencyAgent = new LLMAgent(\"fluency_model\");\nconst relevanceAgent = new LLMAgent(\"relevance_model\");\n\n// Supervisor agent\nconst supervisorAgent = new LLMAgent(\"supervisor_model\");\n\n// Evaluation and refinement process\nconst initialResponse = initialAgent.getResponse(userQuery);\nconst fluencyScore = await fluencyAgent.evaluate(initialResponse);\nconst relevanceScore = await relevanceAgent.evaluate(initialResponse);\n\nconst summary = { fluency: fluencyScore, relevance: relevanceScore };\nconst supervisorDecision = await supervisorAgent.decide(initialResponse, summary);\n\n// Handle supervisorDecision (revise, escalate, etc.)\n```\n* **Benefit:** This hierarchy prevents individual evaluator biases from dominating the process and ensures a balanced, well-informed refinement process, leading to more robust chatbot behavior.\n\n**3. Agent-Specific Memory (Using Local Storage/Databases):**\n\n* **Scenario:** An online game where LLM agents interact with players.  Each agent needs to remember its past interactions with a specific player to maintain context and personalize the gaming experience.\n* **TalkHier Application:** Implement agent-specific memory using browser local storage for short-term memory and a database like IndexedDB or a server-side database for long-term memory.\n* **JavaScript Implementation (Conceptual using Local Storage):**\n```javascript\nclass Agent {\n    constructor(agentId) {\n        this.agentId = agentId;\n        this.memory = JSON.parse(localStorage.getItem(`agent_${agentId}_memory`)) || [];\n    }\n\n    remember(interaction) {\n        this.memory.push(interaction);\n        localStorage.setItem(`agent_${agentId}_memory`, JSON.stringify(this.memory));\n    }\n    // ... other agent methods\n}\n```\n* **Benefit:** Allows for personalized and contextually aware agent behavior without the complexity of a shared, global memory space that can become a bottleneck in complex multi-agent systems.\n\n**JavaScript Frameworks and Libraries:**\n\n* **LangChain.js**: For facilitating interactions with LLM providers, managing prompts, and chaining operations together.\n* **WebSockets**: For real-time communication between agents in web applications.\n* **Node.js with Express or similar**: To build server-side logic for managing agents, their memory, and communication.\n* **React, Vue, or Angular**: For creating dynamic front-end interfaces that interact with the multi-agent system.\n\n\nBy incorporating these examples and utilizing appropriate JavaScript technologies, developers can create more sophisticated and effective LLM-based multi-agent applications specifically designed for the unique demands of web development.  This allows for complex interactions, personalized user experiences, and more intelligent web applications.",
  "pseudocode": "```javascript\nfunction hierarchicalRefinement(initialOutput, evaluationCriteria, qualityThreshold, maxIterations) {\n  let currentOutput = initialOutput;\n  let currentIteration = 0;\n\n  // Loop until the quality threshold is met or the maximum number of iterations is reached.\n  while (currentIteration < maxIterations) {\n    currentIteration++;\n\n    // 1. Assign tasks to evaluation team\n    const evaluationTasks = assignEvaluationTasks(evaluationCriteria); \n\n    // 2. Distribute tasks and evaluate the current output\n    const evaluationResults = evaluationTasks.map(task => evaluate(currentOutput, task.criterion));\n\n    // 3. Aggregate and summarize evaluation feedback\n    const summarizedFeedback = summarizeFeedback(evaluationResults);\n\n    // 4. Check if quality threshold is met\n    if (meetsQualityThreshold(summarizedFeedback, qualityThreshold)) {\n      return currentOutput; // Return current text if above threshold\n    }\n\n    // 5. Revise output based on feedback\n    currentOutput = reviseOutput(currentOutput, summarizedFeedback);\n  }\n\n  return currentOutput; // Return the final output after max iterations\n}\n\n\n// Helper functions (placeholders; implementation details omitted in paper)\nfunction assignEvaluationTasks(criteria) { /* ... */ }\nfunction evaluate(output, criterion) { /* ... */ }\nfunction summarizeFeedback(results) { /* ... */ }\nfunction meetsQualityThreshold(feedback, threshold) { /* ... */ }\nfunction reviseOutput(output, feedback) { /* ... */ }\n\n```\n\n**Explanation of the Algorithm and its Purpose:**\n\nThe `hierarchicalRefinement` function implements the core logic of the TalkHier framework's refinement process. Its purpose is to iteratively improve a given text output (e.g., an answer to a question, an advertisement headline) based on feedback from a team of evaluators.\n\nThe algorithm follows these steps:\n\n1. **Task Assignment:** Evaluation tasks are assigned to an evaluation team based on predefined criteria (e.g., \"accuracy,\" \"fluency,\" \"faithfulness\").\n\n2. **Evaluation:** Each evaluator assesses the current text output based on their assigned criterion.  The `evaluate()` helper function represents this step.\n\n3. **Feedback Aggregation:** The evaluation results from individual evaluators are aggregated and summarized into a single feedback object.\n\n4. **Quality Threshold Check:** The algorithm checks if the summarized feedback meets a predefined quality threshold. If the threshold is met, the current output is considered satisfactory, and the algorithm terminates.\n\n5. **Revision:** If the quality threshold is not met, the text output is revised based on the summarized feedback. The `reviseOutput()` helper function handles this revision process.\n\nThis iterative process continues until either the quality threshold is met or a maximum number of iterations is reached, ensuring that the final output is refined and meets the desired quality standards.  This hierarchical structure with a supervising evaluator helps avoid biases and improve consistency compared to simpler feedback mechanisms.",
  "simpleQuestion": "How can LLMs collaborate better on complex tasks?",
  "timestamp": "2025-02-18T06:05:22.511Z"
}