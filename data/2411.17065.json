{
  "arxivId": "2411.17065",
  "title": "Creative Agents: Simulating the Systems Model of Creativity with Generative Agents",
  "abstract": "With the growing popularity of generative AI for images, video, and music, we witnessed models rapidly improve in quality and performance. However, not much attention is paid towards enabling AI's ability to \"be creative\". In this study, we implemented and simulated the systems model of creativity (proposed by Csikszentmihalyi) using virtual agents utilizing large language models (LLMs) and text prompts. For comparison, the simulations were conducted with the \"virtual artists\" being: 1)isolated and 2)placed in a multi-agent system. Both scenarios were compared by analyzing the variations and overall \"creativity\" in the generated artifacts (measured via a user study and LLM). Our results suggest that the generative agents may perform better in the framework of the systems model of creativity.",
  "summary": "This paper explores whether multi-agent systems can enhance the \"creativity\" of generative AI models, specifically in art generation. It simulates Csikszentmihalyi's systems model of creativity using LLMs (Gemini) for text and critique generation and Stable Diffusion for image generation.  Virtual artists receive feedback from virtual critics, influencing their subsequent artwork and the overall domain trends.\n\nKey points for LLM-based multi-agent systems: LLMs can effectively simulate human-like agents in creative domains, allowing for the study of social dynamics' influence on creative output.  Feedback mechanisms between agents drive iterative refinement and potential creative growth, though challenges remain in aligning visual output with descriptive text prompts and preventing LLM outputs from becoming repetitive or nonsensical due to overly abstract prompts. The systems model offers a framework for structuring multi-agent interactions and analyzing the emergence of creativity in computational systems.",
  "takeaways": "This paper explores using LLMs to simulate creative agents within the framework of Csikszentmihalyi's systems model of creativity. Here's how a JavaScript developer can apply these insights to LLM-based multi-agent web applications:\n\n**1. Building Creative Agents:**\n\n* **Personality Representation:** Define each agent's \"core description\" and \"additional text descriptions\" as JavaScript objects. Use these objects to dynamically generate prompts for the LLM (e.g., Gemini, OpenAI) via API calls.  \n* **Agent Reflection:** Implement the \"self-reflection\" mechanism using a function that takes critique as input and updates the agent's \"additional text description\" object.  This could involve sentiment analysis libraries (e.g., Sentiment) to understand the tone of the critique.\n* **Creative Output Generation:** Integrate text-to-image models (e.g., Replicate's Stable Diffusion API, DALL-E) using corresponding JavaScript libraries.  Display the generated images within the web application.\n\n```javascript\n// Example of an Artist Agent\nconst artistAgent = {\n  coreDescription: \"A young aspiring artist passionate about surrealism...\",\n  additionalDescription: \"\",\n  generateArtPrompt: async function(domain) {\n    const prompt = `${domain.description}\\n${this.coreDescription}\\n${this.additionalDescription}\\nDescribe their latest painting.`;\n    const response = await fetch('/api/llm', { \n      method: 'POST',\n      body: JSON.stringify({ prompt })\n    });\n    const artPrompt = await response.json();\n    return artPrompt.generated_text;\n  },\n  reflect: async function(critique) {\n    const prompt = `Reflect on this critique:\\n${critique}\\n${this.coreDescription}\\nWhat actions will you take next?`;\n    // ... (API call and update additionalDescription)\n  }\n};\n```\n\n**2. Implementing the Field (Critics):**\n\n* **Critique Generation:** Create Critic agents similarly, using JavaScript objects and LLM calls. Implement a function that analyzes both text and image (via multimodal models or separate image analysis APIs if necessary) to produce critiques.\n* **Ranking System:** Use a JavaScript array to store and rank the generated artworks.  Implement a sorting function based on \"significance points,\" incorporating the decay factor mentioned in the paper.  Visualization libraries (e.g., Chart.js, D3.js) could display the rankings dynamically.\n\n```javascript\n// Example Critique Function (Critic Agent)\nasync function generateCritique(domain, artistPrompt, imageURL) {\n  const prompt = `${domain.description}\\nCritique this artwork:\\n${artistPrompt}\\nImage: ${imageURL}`;\n  // ... (API call to multimodal LLM)\n}\n\n// Example Ranking Update\nfunction updateRanking(artwork, critique) {\n  const sentiment = analyzeSentiment(critique); // Sentiment analysis\n  if (sentiment > 0) {\n    artwork.significancePoints++; \n  }\n  // ... (Apply decay factor to existing rankings)\n  ranking.sort((a, b) => b.significancePoints - a.significancePoints);\n}\n```\n\n**3. Representing the Domain:**\n\n* **Domain Object:**  Use a JavaScript object to represent the domain, storing its description and current top-ranked artworks.  Update this object based on Critic feedback and artwork ranking.\n\n```javascript\nconst domain = {\n  description: \"The year is 2025.  The art world values...\",\n  topArtworks: [],\n  update: function(newArtworks) {\n    // ... (Update topArtworks and potentially description)\n  }\n};\n```\n\n**4. Simulation Loop:**\n\n* **Asynchronous Operations:**  Use `async/await` to manage the asynchronous nature of LLM API calls.\n* **Frontend Framework Integration:** Integrate this multi-agent system within a frontend framework like React, Vue, or Angular to dynamically update the UI as the simulation progresses.\n\n```javascript\nasync function simulationStep() {\n  for (const artist of artists) {\n   const artPrompt = await artist.generateArtPrompt(domain);\n   const imageURL = await generateImage(artPrompt); // Call to image API\n   // ... (Get critiques and update ranking)\n  }\n //... (Artist reflection and domain update)\n}\n\n\nasync function runSimulation(steps) {\n for (let i = 0; i < steps; i++) {\n   await simulationStep();\n   // ... (Update UI with new artworks and rankings)\n }\n}\n```\n\n**5. User Interaction:**\n\n* **Feedback Mechanisms:** Allow users to provide feedback on generated artifacts, influencing the ranking system or even directly interacting with the agents.\n* **Interactive Visualizations:**  Use JavaScript libraries to visualize the evolution of the domain, the agents' creative output, and the influence of the critiques.\n\nBy implementing these concepts in JavaScript, developers can create dynamic web applications that explore the dynamics of creativity in multi-agent systems, potentially leading to novel forms of artistic co-creation between humans and AI.  Remember that the key is to experiment and iterate, starting with a simplified implementation and gradually increasing complexity as you learn more.",
  "pseudocode": "```javascript\nasync function simulateSystemsModelOfCreativity(artists, field, domain) {\n  // 1. Initialize artists, field, domain (This happens outside the function, assuming you have initialized them with appropriate descriptions)\n\n  for (let t = 0; t < 15; t++) {  // Iterate through time steps\n    for (const artist of artists) { // Each artist creates art\n      const prompt = generateArtPrompt(domain.desc, artist.desc); // Generate prompt for art creation\n      artist.art_prompt = await callLLM(prompt); // Use LLM to generate art description (art prompt)\n      artist.image = await textToImage(artist.art_prompt); // Generate image from the art prompt using a text-to-image model\n    }\n\n    for (const critic of field) { // Each critic critiques the art\n      critic.critiques = []; // Initialize or reset critiques for current time step\n      for (const artist of artists) {\n        const prompt = generateCritiquePrompt(domain.desc, critic.desc, artist.art_prompt, artist.image); // Prompt for critique (including image and its description)\n        const feedback = await callLLM(prompt); // Generate critique using multimodal LLM\n        critic.critiques.push(feedback); // Store the critique\n        artist.update(feedback); // Artist updates based on feedback (add to additional description, etc.)\n      }\n    }\n\n    domain.update(field); // Update domain based on all critiques and potentially rankings\n  }\n}\n\n\n// Helper Functions (These need to be defined separately based on your LLM, text-to-image model and how you want to update artist/domain descriptions)\n\nasync function callLLM(prompt) {\n  // Code to interact with your Large Language Model (e.g. Gemini) and return generated text. \n  // Example using a hypothetical fetch API for an LLM:\n  const response = await fetch('/api/llm', {\n    method: 'POST',\n    headers: {\n      'Content-Type': 'application/json',\n    },\n    body: JSON.stringify({ prompt }),\n  });\n\n  const data = await response.json();\n  return data.generated_text;\n}\n\nasync function textToImage(text) {\n // Code to interact with your Text-to-Image model (e.g., Stable Diffusion) and return generated image.\n //  Example using a hypothetical fetch API:\n  const response = await fetch('/api/text2img', {\n      method: 'POST',\n      headers: { 'Content-Type': 'application/json' },\n      body: JSON.stringify({ text }),\n  });\n\n  const blob = await response.blob(); // Get the image as a blob\n  const imageUrl = URL.createObjectURL(blob); // Create a URL for the blob\n  return imageUrl; \n}\n\nfunction generateArtPrompt(domainDesc, artistDesc) {\n  return `${domainDesc}\\n${artistDesc}\\nThis young art student just finished their latest painting. Provide a brief but detailed description of what is depicted in the canvas.`; \n}\n\nfunction generateCritiquePrompt(domainDesc, criticDesc, artPrompt, image) {\n  return `${domainDesc}\\n${criticDesc}\\nThe student made this painting.  This is how the student described their artwork:\\n${artPrompt}\\n(Image attached: ${image}) \\nWas the student able to convey their intentions?  Do you think this painting is creative? Briefly explain why.`;\n}\n\n\n// Example usage (Simplified):\n\nconst artists = [\n    { desc: \"A young, aspiring artist with no formal training, but lots of enthusiasm.\", art_prompt: \"\", image: \"\", update: (feedback) => { /* Logic to update artist description based on feedback */ } },\n    { desc: \"A student artist trying to find their style.\", art_prompt: \"\", image: \"\", update: (feedback) => { /* ... */ } }\n];\n\nconst field = [{ desc: \"An experienced art critic looking for innovative talent.\", critiques: [] }];\n\nconst domain = { \n    desc: \"A competitive art scene where new talent is constantly emerging.\",\n    update: (field) => { /* Logic to update domain description and rankings based on critiques from the field */ }\n};\n\nsimulateSystemsModelOfCreativity(artists, field, domain)\n  .then(() => {\n    console.log(\"Simulation complete.\");\n    console.log(artists); // Examine the results\n    console.log(domain); // Examine how the domain has changed\n  })\n  .catch(err => console.error(\"Error during simulation: \", err));\n```\n\n**Explanation and Purpose:**\n\nThe algorithm simulates the systems model of creativity proposed by Csikszentmihalyi using a multi-agent approach. It simulates interactions between artists, critics (representing the \"field\"), and the domain (the artistic context) over several time steps. The primary goal is to model how creative output might evolve through these interactions.\n\n1. **Initialization:** Artists, critics, and the domain are initialized with descriptive text. Artists are set up with descriptions, and an empty `art_prompt` and `image` which will be populated during the simulation. Critics are given an empty array for storing `critiques`, and the domain has a `desc` to set the context.\n2. **Art Creation Loop:** At each time step, each artist generates an `art_prompt` (description of their intended art) using an LLM, incorporating the current domain description and their own artist description as context.  Then, a text-to-image model is used to create an `image` based on the `art_prompt`.\n3. **Critique Loop:**  Each critic in the field evaluates each artist's work by generating a `critique` using a multimodal LLM that can process both the image and the artist's description.  The `critiques` are stored.\n4. **Artist Update:**  Each artist updates their internal state (e.g., adding the feedback to their `additional text description`) based on the critiques received. This represents how artists reflect on feedback and adjust their approach.\n5. **Domain Update:** The domain is updated based on all the critiques given, representing how the overall artistic context evolves due to new work and critical evaluations. This might involve a ranking system (not explicitly implemented in the basic pseudocode but referenced in the paper) where artworks gain or lose \"significance points\" based on critiques.\n6. **Iteration:** Steps 2-5 are repeated for a fixed number of time steps, simulating the evolution of creative outputs over time.\n\nThis simulation can be used to explore the dynamics of creativity in a multi-agent environment. By modifying artist descriptions, critic characteristics, or the domain description, you can experiment with different scenarios and study how these factors influence the creative output. It can also provide insights into the role of feedback, social interaction, and context in shaping artistic creations.",
  "simpleQuestion": "Can LLMs boost creativity in multi-agent systems?",
  "timestamp": "2024-11-27T06:04:12.043Z"
}